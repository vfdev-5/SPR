{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "__author__ = 'ZFTurbo: https://kaggle.com/zfturbo'\n",
    "Fork of ZFTurbo 'Mass hashes' code : https://www.kaggle.com/zfturbo/santander-product-recommendation/mass-hashes/code\n",
    "\n",
    "Added personal recommendations based on previous user's choices\n",
    "\n",
    "\"\"\"\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Project\n",
    "from zfturbo_script_mass_hashes_personal_recommendations import read_data, get_profiles, \\\n",
    "            personal_recommendations_to_proba, \\\n",
    "            common_recommendations_to_proba, \\\n",
    "            get_target_labels, predict_score, process_row, \\\n",
    "            ZFTURBO_COMMON_WEIGHT    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train/test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filename = \"../data/train_ver2_201601-201605.csv\"\n",
    "# test_filename = \"../data/test_ver2.csv\"\n",
    "test_filename = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute recommendations from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:--- Run solution ---\n",
      "INFO:root:- READ DATA : months to read ['2016-03', '2016-04']\n",
      "INFO:root:-- Processed 100000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 200000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 300000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 400000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 500000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 600000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 700000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 800000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 900000 lines . Current month : 2016-03\n",
      "INFO:root:-- Processed 1000000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1100000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1200000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1300000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1400000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1500000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1600000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1700000 lines . Current month : 2016-04\n",
      "INFO:root:-- Processed 1800000 lines . Current month : 2016-04\n",
      "DEBUG:root:-- Removed rows : 12\n",
      "DEBUG:root:-- common_recommendations_validation : 980393 \n",
      "DEBUG:root:-- personal_recommendations_validation : 929930 \n",
      "DEBUG:root:-- product_stats_validation : 24 \n",
      "INFO:root:- READ DATA : months to read ['2016-05']\n",
      "INFO:root:-- Processed 100000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 200000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 300000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 400000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 500000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 600000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 700000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 800000 lines . Current month : 2016-05\n",
      "INFO:root:-- Processed 900000 lines . Current month : 2016-05\n",
      "DEBUG:root:-- Removed rows : 5\n",
      "DEBUG:root:-- common_recommendations : 1006680 \n",
      "DEBUG:root:-- personal_recommendations : 934707 \n",
      "DEBUG:root:-- product_stats : 24 \n"
     ]
    }
   ],
   "source": [
    "logging.info('--- Run solution ---')\n",
    "reader = open(train_filename, \"r\")\n",
    "target_labels = get_target_labels(reader.readline())\n",
    "\n",
    "# Read data and create recommendations structures\n",
    "\n",
    "nb_months_validation = 2\n",
    "(personal_recommendations_validation,\n",
    " common_recommendations_validation,\n",
    " product_stats_validation) = read_data(reader, 201603, nb_months_validation,\n",
    "                                       process_row, get_profiles)\n",
    "\n",
    "logging.debug(\"-- common_recommendations_validation : %s \" % len(common_recommendations_validation))\n",
    "logging.debug(\"-- personal_recommendations_validation : %s \" % len(personal_recommendations_validation))\n",
    "logging.debug(\"-- product_stats_validation : %s \" % len(product_stats_validation))\n",
    "\n",
    "personal_recommendations = deepcopy(personal_recommendations_validation)\n",
    "common_recommendations = deepcopy(common_recommendations_validation)\n",
    "product_stats = deepcopy(product_stats_validation)\n",
    "\n",
    "(personal_recommendations,\n",
    " common_recommendations,\n",
    " product_stats,\n",
    " validation_data) = read_data(reader, 201605, 1,\n",
    "                              process_row,\n",
    "                              get_profiles,\n",
    "                              return_raw_data=True,\n",
    "                              personal_recommendations=personal_recommendations,\n",
    "                              common_recommendations=common_recommendations,\n",
    "                              product_stats=product_stats)\n",
    "\n",
    "logging.debug(\"-- common_recommendations : %s \" % len(common_recommendations))\n",
    "logging.debug(\"-- personal_recommendations : %s \" % len(personal_recommendations))\n",
    "logging.debug(\"-- product_stats : %s \" % len(product_stats))\n",
    "\n",
    "reader.close()\n",
    "\n",
    "personal_recommendations_to_proba(personal_recommendations, nb_months_validation)\n",
    "personal_recommendations_to_proba(personal_recommendations_validation, nb_months_validation+1)\n",
    "\n",
    "common_recommendations_to_proba(common_recommendations)\n",
    "common_recommendations_to_proba(common_recommendations_validation)\n",
    "\n",
    "# Sort product stats:\n",
    "product_stats_validation = sorted(product_stats_validation.items(), key=itemgetter(1), reverse=True)\n",
    "product_stats = sorted(product_stats.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search personal recommendations weight to maximize the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search a minimum :\n",
    "# f = lambda x: -predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      x)\n",
    "\n",
    "# ret = optimize.fmin(f, 0.5, full_output=True, xtol=0.001, ftol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print \"Found maximum score : \", ret[1], \" at \", ret[0]\n",
    "# map7 = ret[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- predict_score : personal_recommendations_weight=0.0\n",
      "DEBUG:root:--- predict_score : map7=0.0209900993714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0209900993714\n"
     ]
    }
   ],
   "source": [
    "map7 = predict_score(validation_data,\n",
    "                     process_row,\n",
    "                     get_profiles,\n",
    "                     personal_recommendations_validation,\n",
    "                     common_recommendations_validation,\n",
    "                     product_stats_validation,\n",
    "                     0.0)\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.1)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.2)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.3)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.7)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zfturbo_script_mass_hashes_personal_recommendations import compute_predictions, get_real_values, apk\n",
    "\n",
    "def _predict_score(validation_data, get_profiles_func,\n",
    "                  personal_recommendations,\n",
    "                  common_recommendations,\n",
    "                  product_stats,\n",
    "                  personal_recommendations_weight):\n",
    "    logging.debug(\"-- predict_score : personal_recommendations_weight=%s\" % personal_recommendations_weight)\n",
    "    map7 = 0.0   \n",
    "    count = 25\n",
    "    for i, row in enumerate(validation_data):\n",
    "        predicted = compute_predictions(row, get_profiles_func,\n",
    "                                        personal_recommendations,\n",
    "                                        common_recommendations,\n",
    "                                        product_stats,\n",
    "                                        personal_recommendations_weight)\n",
    "\n",
    "        real = get_real_values(row, personal_recommendations)\n",
    "        score = apk(real, predicted)\n",
    "        if count > 0:\n",
    "            print \"-- i : \", i, row[1], \" score : \", score, \" | predicted : \", predicted, \", real : \", real        \n",
    "        map7 += score\n",
    "        \n",
    "        count -= 1\n",
    "        if count == 0:\n",
    "            break\n",
    "\n",
    "    if len(validation_data) > 0:\n",
    "        map7 /= len(validation_data)\n",
    "\n",
    "    logging.debug(\"--- predict_score : map7=%s\" % map7)\n",
    "    return map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map7 = _predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.0)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ZFTurbo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from common import get_user, apk, get_real_values, get_choices\n",
    "\n",
    "def zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                        best,\n",
    "                        personal_recommendations,\n",
    "                        product_stats):\n",
    "    predicted = []\n",
    "    user = get_user(row)\n",
    "    profiles = get_profiles_func(row)\n",
    "\n",
    "    last_choice = None\n",
    "    if user in personal_recommendations:\n",
    "        last_choice = personal_recommendations[user]['last_choice']\n",
    "\n",
    "    def _get_next_best_prediction(best, profiles, predicted, last_choice):\n",
    "        import heapq\n",
    "        score = [0] * 24\n",
    "        for h in profiles:\n",
    "            if h in best:\n",
    "#                 print \"-- profile : \", h\n",
    "                for i in range(len(best[h])):\n",
    "                    sc = 24 - i + len(h)\n",
    "#                     print \"-- i, sc\", i, sc\n",
    "                    index = best[h][i][0]\n",
    "                    if last_choice is not None:\n",
    "#                         print \"--- \", index, last_choice[index] \n",
    "                        if last_choice[index] == 1:\n",
    "                            continue\n",
    "                    if index not in predicted:\n",
    "                        score[index] += sc\n",
    "        \n",
    "#         print \"\\n -- score : \", score\n",
    "        \n",
    "        final = []\n",
    "        pred = heapq.nlargest(7, range(len(score)), score.__getitem__)\n",
    "#         print \"\\n -- pred : \", pred\n",
    "        for i in range(7):\n",
    "            if score[pred[i]] > 0:\n",
    "                final.append(pred[i])\n",
    "#         print \"\\n -- final : \", final\n",
    "        return final\n",
    "\n",
    "    predicted = _get_next_best_prediction(best, profiles, predicted, last_choice)\n",
    "\n",
    "    # print \"\\n- PREDICTED : \", predicted\n",
    "    # add suggestions from product_stats:\n",
    "    if len(predicted) < 7:\n",
    "        for product in product_stats:\n",
    "            # If user is not new\n",
    "            if last_choice is not None and last_choice[product[0]] == 1:\n",
    "                continue\n",
    "\n",
    "            if product[0] not in predicted:\n",
    "                predicted.append(product[0])\n",
    "                if len(predicted) == 7:\n",
    "                    break\n",
    "\n",
    "    # print \"FINAL PREDICTED : \", predicted\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zfturbo_predict_score(validation_data, get_profiles_func,\n",
    "                  common_recommendations,\n",
    "                  personal_recommendations,\n",
    "                  product_stats):\n",
    "    \n",
    "    logging.debug(\"-- zfturbo_predict_score\")\n",
    "    map7 = 0.0    \n",
    "    count = 25\n",
    "    for i, row in enumerate(validation_data):\n",
    "        predicted = zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                                        common_recommendations,\n",
    "                                        personal_recommendations,\n",
    "                                        product_stats)\n",
    "        real = get_real_values(row, personal_recommendations)\n",
    "        score = apk(real, predicted)\n",
    "        if count > 0:\n",
    "            print \"-- i : \", i, row[1], \" score : \", score, \" | predicted : \", predicted, \", real : \", real\n",
    "        map7 += score\n",
    "    \n",
    "        count-=1\n",
    "        if count == 0:\n",
    "            break\n",
    "        \n",
    "    if len(validation_data) > 0:\n",
    "        map7 /= len(validation_data)\n",
    "\n",
    "    logging.debug(\"--- predict_score : map7=%s\" % map7)\n",
    "    return map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def sort_common_recommendations(common_recommendations):\n",
    "    out = dict()\n",
    "    for b in common_recommendations:\n",
    "        arr = common_recommendations[b]\n",
    "        srtd = sorted(arr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        # remove 'total'\n",
    "        out[b] = [item for item in srtd if item[0] != 'total']\n",
    "    return out\n",
    "best_validation = sort_common_recommendations(common_recommendations_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#best_validation.items()[:100]\n",
    "# print common_recommendations_validation[(3, 'ES', 'H', 2, 'NA', 1530074)]\n",
    "# print best_validation[(3, 'ES', 'H', 2, 'NA', 1530074)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare common prediction methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# zfturbo_compute_predictions(validation_data[20], get_profiles,\n",
    "#                                         best_validation,\n",
    "#                                         product_stats_validation)\n",
    "\n",
    "row = validation_data[115]\n",
    "get_profiles_func = get_profiles\n",
    "\n",
    "\n",
    "predicted = []\n",
    "user = get_user(row)\n",
    "profiles = get_profiles_func(row)\n",
    "\n",
    "last_choice = None\n",
    "if user in personal_recommendations_validation:\n",
    "    last_choice = personal_recommendations_validation[user]['last_choice']\n",
    "\n",
    "def _get_next_best_prediction(best, profiles, predicted, last_choice):\n",
    "    import heapq\n",
    "    score = [0] * 24\n",
    "    for h in profiles:\n",
    "        if h in best:\n",
    "            #print \"-- profile : \", h\n",
    "            for i in range(len(best[h])):\n",
    "                sc = 24 - i + len(h)\n",
    "                #print \"-- i, len(h), sc, index, proba : \", i, len(h), sc, \" | \", best[h][i][0], \" | \", best[h][i][1]\n",
    "                index = best[h][i][0]\n",
    "                if last_choice is not None:\n",
    "                    #print \"--- \", index, last_choice[index] \n",
    "                    if last_choice[index] == 1:\n",
    "                        continue\n",
    "                if index not in predicted:\n",
    "                    score[index] += sc\n",
    "            print \"--> score : \", score\n",
    "\n",
    "    print \"\\n -- score : \", score\n",
    "\n",
    "    final = []\n",
    "    pred = heapq.nlargest(7, range(len(score)), score.__getitem__)\n",
    "    print \"\\n -- pred : \", pred\n",
    "    for i in range(7):\n",
    "        if score[pred[i]] > 0:\n",
    "            final.append(pred[i])\n",
    "    print \"\\n -- final : \", final\n",
    "    return final\n",
    "\n",
    "predicted = _get_next_best_prediction(best_validation, profiles, predicted, last_choice)\n",
    "\n",
    "print \"\\n- PREDICTED : \", predicted\n",
    "# add suggestions from product_stats:\n",
    "if len(predicted) < 7:\n",
    "    for product in product_stats:\n",
    "        # If user is not new\n",
    "        if last_choice is not None and last_choice[product[0]] == 1:\n",
    "            continue\n",
    "\n",
    "        if product[0] not in predicted:\n",
    "            predicted.append(product[0])\n",
    "            if len(predicted) == 7:\n",
    "                break\n",
    "\n",
    "print \"FINAL PREDICTED : \", predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[23, 4, 12, 7, 22, 21, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predicted1 = compute_predictions(row, get_profiles_func,\n",
    "#                                 _personal_recommendations,\n",
    "#                                 _common_recommendations,\n",
    "#                                 _product_stats,\n",
    "#                                 personal_recommendations_weight)\n",
    "\n",
    "\n",
    "row = validation_data[156]\n",
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.5\n",
    "\n",
    "\n",
    "predicted = []\n",
    "user = get_user(row)\n",
    "profiles = get_profiles_func(row)\n",
    "\n",
    "last_choice = None\n",
    "if user in _personal_recommendations:\n",
    "    last_choice = _personal_recommendations[user]['last_choice']\n",
    "\n",
    "target_weights = None\n",
    "total_length = 0.0\n",
    "total_count = 0\n",
    "# compute a total length to of participating profiles to define profile weight\n",
    "for profile in profiles:\n",
    "    if profile in _common_recommendations:\n",
    "        total_length += len(profile)\n",
    "        total_count += 1\n",
    "\n",
    "if total_length > 0:\n",
    "    target_weights = np.zeros(24)\n",
    "\n",
    "zfturbo_common_weight = 1.0\n",
    "mine_common_weight = 1.0 - zfturbo_common_weight\n",
    "    \n",
    "for profile in profiles:\n",
    "    if profile in _common_recommendations:\n",
    "        profile_weight = len(profile) * 1.0 / total_length\n",
    "        # _common_recommendations[profile].items() -> [(target, proba)]\n",
    "        target_probas = sorted(_common_recommendations[profile].items(), key=itemgetter(1), reverse=True)        \n",
    "\n",
    "        target_total_score = (24.0 + len(profile)) * total_count\n",
    "        for i, target_proba in enumerate(target_probas):\n",
    "            target_score = 24 - i + len(profile)\n",
    "            target = target_proba[0]\n",
    "            proba = target_proba[1]\n",
    "            if isinstance(target, int):\n",
    "                p1 =  _common_recommendations[profile][target] * profile_weight * mine_common_weight\n",
    "                p2 = target_score * 1.0 / target_total_score * zfturbo_common_weight \n",
    "                target_weights[target] += p1 + p2 #_common_recommendations[profile][target] * profile_weight\n",
    "        print \"-> target_weights: \", target_weights[2], target_weights[23]\n",
    "\n",
    "        \n",
    "personal_predictions = None\n",
    "if user in _personal_recommendations:\n",
    "    personal_predictions = _personal_recommendations[user]['recommendations']        \n",
    "\n",
    "print \"Common : {}\".format(target_weights)\n",
    "print \"Personal : {}\".format(personal_predictions)\n",
    "        \n",
    "# print \"\\n\\n target_weights : \", target_weights\n",
    "suggestions = (1.0 - personal_recommendations_weight) * target_weights + personal_recommendations_weight * personal_predictions\n",
    "print last_choice\n",
    "if last_choice is not None:\n",
    "    mask = np.abs(last_choice - 1)\n",
    "    suggestions *= mask\n",
    "    \n",
    "print \"\\n\\n Predictions : {}\".format(suggestions)\n",
    "# print \"\\n\\n Common predictions : \", suggestions\n",
    "    \n",
    "print np.argsort(suggestions)[::-1].tolist()[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.0\n",
    "\n",
    "compute_predictions(row, get_profiles_func,\n",
    "                    _personal_recommendations,\n",
    "                    _common_recommendations,\n",
    "                    _product_stats,\n",
    "                    0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map7 = zfturbo_predict_score(validation_data, get_profiles,\n",
    "                  best_validation,\n",
    "                  personal_recommendations_validation,\n",
    "                  product_stats_validation)\n",
    "\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map7 = zfturbo_predict_score(validation_data, get_profiles,\n",
    "                  best_validation,\n",
    "                  personal_recommendations_validation,\n",
    "                  product_stats_validation)\n",
    "\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ZFTURBO_COMMON_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZFTURBO_COMMON_WEIGHT = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def _predict_score(validation_data, get_profiles_func,\n",
    "#                   personal_recommendations,\n",
    "#                   common_recommendations,\n",
    "#                   product_stats,\n",
    "#                   personal_recommendations_weight):\n",
    "\n",
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.0\n",
    "\n",
    "logging.debug(\"-- predict_score : personal_recommendations_weight=%s\" % personal_recommendations_weight)\n",
    "map7_1 = 0.0   \n",
    "map7_2 = 0.0   \n",
    "count = -1\n",
    "\n",
    "for i, row in enumerate(validation_data):\n",
    "\n",
    "    predicted1 = compute_predictions(row, get_profiles_func,\n",
    "                                    _personal_recommendations,\n",
    "                                    _common_recommendations,\n",
    "                                    _product_stats,\n",
    "                                    personal_recommendations_weight)\n",
    "\n",
    "    predicted2 = zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                                        best_validation,\n",
    "                                        _personal_recommendations,\n",
    "                                        _product_stats)\n",
    "    \n",
    "    real = get_real_values(row, _personal_recommendations)\n",
    "    score1 = apk(real, predicted1)\n",
    "    score2 = apk(real, predicted2)\n",
    "    if count > 0 and score1 != score2:\n",
    "        print \"-- i : \", i, row[1]\n",
    "        print \"--- p1 : \", score1, predicted1, real\n",
    "        print \"--- p2 : \", score2, predicted2\n",
    "    map7_1 += score1\n",
    "    map7_2 += score2\n",
    "    \n",
    "    count -= 1\n",
    "    if count == 0:\n",
    "        break\n",
    "\n",
    "if len(validation_data) > 0:\n",
    "    map7_1 /= len(validation_data)\n",
    "    map7_2 /= len(validation_data)\n",
    "\n",
    "print map7_1, map7_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2.33026234774e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[7, 23, 12, 17, 4, 8, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_filename is None:\n",
    "    return\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "writer = open(submission_file, \"w\")\n",
    "reader = open(test_filename, \"r\")\n",
    "\n",
    "# skip header:\n",
    "reader.readline()\n",
    "\n",
    "write_submission(writer, reader, target_labels, get_profiles, personal_recommendations, common_recommendations, product_stats)\n",
    "\n",
    "writer.close()\n",
    "reader.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
