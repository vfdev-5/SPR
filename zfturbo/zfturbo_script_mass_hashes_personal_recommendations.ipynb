{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "__author__ = 'ZFTurbo: https://kaggle.com/zfturbo'\n",
    "\n",
    "\"\"\"\n",
    "Fork of ZFTurbo 'Mass hashes' code : https://www.kaggle.com/zfturbo/santander-product-recommendation/mass-hashes/code\n",
    "\n",
    "Added personal recommendations based on previous user's choices\n",
    "\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# Project\n",
    "from zfturbo_script_mass_hashes_personal_recommendations import read_data, get_profiles, personal_recommendations_to_proba, common_recommendations_to_proba, get_target_labels, predict_score\n",
    "from zfturbo_script_mass_hashes_personal_recommendations import ZFTURBO_COMMON_WEIGHT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train/test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filename = \"../data/train_ver2_201601-201605.csv\"\n",
    "# test_filename = \"../data/test_ver2.csv\"\n",
    "test_filename = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute recommendations from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logging.info('--- Run solution ---')\n",
    "reader = open(train_filename, \"r\")\n",
    "target_labels = get_target_labels(reader.readline())\n",
    "\n",
    "nb_months_validation = 4\n",
    "\n",
    "(personal_recommendations_validation,\n",
    " common_recommendations_validation,\n",
    " product_stats_validation) = read_data(reader, 201601, nb_months_validation, get_profiles)\n",
    "\n",
    "logging.debug(\"-- common_recommendations_validation : %s \" % len(common_recommendations_validation))\n",
    "logging.debug(\"-- personal_recommendations_validation : %s \" % len(personal_recommendations_validation))\n",
    "logging.debug(\"-- product_stats_validation : %s \" % len(product_stats_validation))\n",
    "\n",
    "personal_recommendations = deepcopy(personal_recommendations_validation)\n",
    "common_recommendations = deepcopy(common_recommendations_validation)\n",
    "product_stats = deepcopy(product_stats_validation)\n",
    "\n",
    "(personal_recommendations,\n",
    " common_recommendations,\n",
    " product_stats,\n",
    " validation_data) = read_data(reader, 201605, 1, get_profiles,\n",
    "                              return_raw_data=True,\n",
    "                              personal_recommendations=personal_recommendations,\n",
    "                              common_recommendations=common_recommendations,\n",
    "                              product_stats=product_stats)\n",
    "\n",
    "logging.debug(\"-- common_recommendations : %s \" % len(common_recommendations))\n",
    "logging.debug(\"-- personal_recommendations : %s \" % len(personal_recommendations))\n",
    "logging.debug(\"-- product_stats : %s \" % len(product_stats))\n",
    "\n",
    "reader.close()\n",
    "\n",
    "common_recommendations_to_proba(common_recommendations)\n",
    "common_recommendations_to_proba(common_recommendations_validation)\n",
    "\n",
    "# Sort product stats:\n",
    "product_stats_validation = sorted(product_stats_validation.items(), key=itemgetter(1), reverse=True)\n",
    "product_stats = sorted(product_stats.items(), key=itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#personal_recommendations_raw = deepcopy(personal_recommendations)\n",
    "#personal_recommendations_validation_raw = deepcopy(personal_recommendations_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#personal_recommendations_to_proba(personal_recommendations, nb_months_validation)\n",
    "personal_recommendations_to_proba(personal_recommendations_validation, nb_months_validation+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Hashes num: ', 1055783)\n",
      "('Hashes valid num: ', 1030057)\n",
      "('Valid part: ', 931447)\n"
     ]
    }
   ],
   "source": [
    "print('Hashes num: ', len(common_recommendations))\n",
    "print('Hashes valid num: ', len(common_recommendations_validation))\n",
    "print('Valid part: ', len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search personal recommendations weight to maximize the score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Search a minimum :\n",
    "# f = lambda x: -predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      x)\n",
    "\n",
    "# ret = optimize.fmin(f, 0.5, full_output=True, xtol=0.001, ftol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print \"Found maximum score : \", ret[1], \" at \", ret[0]\n",
    "# map7 = ret[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- predict_score : personal_recommendations_weight=1.0\n",
      "DEBUG:root:--- predict_score : map7=0.0193876135136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0193876135136\n"
     ]
    }
   ],
   "source": [
    "map7 = predict_score(validation_data,\n",
    "                     get_profiles,\n",
    "                     personal_recommendations_validation,\n",
    "                     common_recommendations_validation,\n",
    "                     product_stats_validation,\n",
    "                     1.0)\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- predict_score : personal_recommendations_weight=0.0\n",
      "DEBUG:root:--- predict_score : map7=0.0204108103366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0204108103366\n"
     ]
    }
   ],
   "source": [
    "map7 = predict_score(validation_data,\n",
    "                     get_profiles,\n",
    "                     personal_recommendations_validation,\n",
    "                     common_recommendations_validation,\n",
    "                     product_stats_validation,\n",
    "                     0.0)\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.1)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.2)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# map7 = predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.3)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- predict_score : personal_recommendations_weight=0.7\n",
      "DEBUG:root:--- predict_score : map7=0.0220622619839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0220622619839\n"
     ]
    }
   ],
   "source": [
    "map7 = predict_score(validation_data,\n",
    "                     get_profiles,\n",
    "                     personal_recommendations_validation,\n",
    "                     common_recommendations_validation,\n",
    "                     product_stats_validation,\n",
    "                     0.7)\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from zfturbo_script_mass_hashes_personal_recommendations import compute_predictions, get_real_values, apk\n",
    "\n",
    "def _predict_score(validation_data, get_profiles_func,\n",
    "                  personal_recommendations,\n",
    "                  common_recommendations,\n",
    "                  product_stats,\n",
    "                  personal_recommendations_weight):\n",
    "    logging.debug(\"-- predict_score : personal_recommendations_weight=%s\" % personal_recommendations_weight)\n",
    "    map7 = 0.0   \n",
    "    count = 25\n",
    "    for i, row in enumerate(validation_data):\n",
    "        predicted = compute_predictions(row, get_profiles_func,\n",
    "                                        personal_recommendations,\n",
    "                                        common_recommendations,\n",
    "                                        product_stats,\n",
    "                                        personal_recommendations_weight)\n",
    "\n",
    "        real = get_real_values(row, personal_recommendations)\n",
    "        score = apk(real, predicted)\n",
    "        if count > 0:\n",
    "            print \"-- i : \", i, row[1], \" score : \", score, \" | predicted : \", predicted, \", real : \", real        \n",
    "        map7 += score\n",
    "        \n",
    "        count -= 1\n",
    "        if count == 0:\n",
    "            break\n",
    "\n",
    "    if len(validation_data) > 0:\n",
    "        map7 /= len(validation_data)\n",
    "\n",
    "    logging.debug(\"--- predict_score : map7=%s\" % map7)\n",
    "    return map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- predict_score : personal_recommendations_weight=0.0\n",
      "DEBUG:root:--- predict_score : map7=1.07359839046e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- i :  0 657788  score :  0.0  | predicted :  [23, 7, 4, 12, 22, 21, 17] , real :  []\n",
      "-- i :  1 657795  score :  0.0  | predicted :  [23, 7, 4, 12, 17, 18, 8] , real :  []\n",
      "-- i :  2 657790  score :  0.0  | predicted :  [2, 12, 7, 22, 17, 8, 19] , real :  []\n",
      "-- i :  3 657794  score :  0.0  | predicted :  [11, 12, 23, 4, 22, 21, 7] , real :  []\n",
      "-- i :  4 657797  score :  0.0  | predicted :  [2, 23, 7, 4, 8, 12, 22] , real :  []\n",
      "-- i :  5 657789  score :  0.0  | predicted :  [12, 23, 4, 22, 21, 17, 19] , real :  []\n",
      "-- i :  6 657787  score :  0.0  | predicted :  [7, 23, 12, 17, 4, 18, 22] , real :  []\n",
      "-- i :  7 657777  score :  0.0  | predicted :  [7, 23, 12, 4, 17, 8, 18] , real :  []\n",
      "-- i :  8 657782  score :  0.0  | predicted :  [2, 23, 4, 22, 21, 12, 7] , real :  []\n",
      "-- i :  9 657781  score :  0.0  | predicted :  [2, 12, 23, 7, 4, 13, 19] , real :  []\n",
      "-- i :  10 657780  score :  0.0  | predicted :  [23, 12, 7, 4, 17, 22, 21] , real :  []\n",
      "-- i :  11 657779  score :  0.0  | predicted :  [2, 23, 8, 12, 7, 22, 21] , real :  []\n",
      "-- i :  12 657799  score :  0.0  | predicted :  [2, 7, 23, 4, 12, 17, 22] , real :  []\n",
      "-- i :  13 657774  score :  0.0  | predicted :  [7, 23, 12, 4, 8, 22, 17] , real :  []\n",
      "-- i :  14 657771  score :  0.0  | predicted :  [7, 23, 12, 4, 8, 22, 17] , real :  []\n",
      "-- i :  15 657770  score :  0.0  | predicted :  [23, 7, 12, 4, 17, 22, 18] , real :  []\n",
      "-- i :  16 657769  score :  0.0  | predicted :  [2, 7, 12, 23, 8, 11, 17] , real :  []\n",
      "-- i :  17 657766  score :  0.0  | predicted :  [2, 7, 23, 4, 12, 17, 22] , real :  []\n",
      "-- i :  18 657764  score :  0.0  | predicted :  [23, 4, 12, 22, 21, 17, 8] , real :  []\n",
      "-- i :  19 657760  score :  0.0  | predicted :  [23, 7, 4, 22, 17, 21, 8] , real :  []\n",
      "-- i :  20 657786  score :  1.0  | predicted :  [23, 4, 12, 7, 22, 21, 18] , real :  [23]\n",
      "-- i :  21 657802  score :  0.0  | predicted :  [7, 23, 12, 4, 17, 8, 18] , real :  []\n",
      "-- i :  22 657847  score :  0.0  | predicted :  [2, 23, 7, 4, 12, 22, 21] , real :  []\n",
      "-- i :  23 657806  score :  0.0  | predicted :  [2, 23, 12, 4, 7, 17, 22] , real :  []\n",
      "-- i :  24 657848  score :  0.0  | predicted :  [2, 23, 7, 12, 4, 17, 22] , real :  []\n",
      "1.07359839046e-06\n"
     ]
    }
   ],
   "source": [
    "# map7 = _predict_score(validation_data,\n",
    "#                      get_profiles,\n",
    "#                      personal_recommendations_validation,\n",
    "#                      common_recommendations_validation,\n",
    "#                      product_stats_validation,\n",
    "#                      0.0)\n",
    "# print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ZFTurbo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from common import get_user, apk, get_real_values, get_choices\n",
    "\n",
    "def zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                        best,\n",
    "                        personal_recommendations,\n",
    "                        product_stats):\n",
    "    predicted = []\n",
    "    user = get_user(row)\n",
    "    profiles = get_profiles_func(row)\n",
    "\n",
    "    last_choice = None\n",
    "    if user in personal_recommendations:\n",
    "        last_choice = personal_recommendations[user]['last_choice']\n",
    "\n",
    "    def _get_next_best_prediction(best, profiles, predicted, last_choice):\n",
    "        import heapq\n",
    "        score = [0] * 24\n",
    "        for h in profiles:\n",
    "            if h in best:\n",
    "#                 print \"-- profile : \", h\n",
    "                for i in range(len(best[h])):\n",
    "                    sc = 24 - i + len(h)\n",
    "#                     print \"-- i, sc\", i, sc\n",
    "                    index = best[h][i][0]\n",
    "                    if last_choice is not None:\n",
    "#                         print \"--- \", index, last_choice[index] \n",
    "                        if last_choice[index] == 1:\n",
    "                            continue\n",
    "                    if index not in predicted:\n",
    "                        score[index] += sc\n",
    "        \n",
    "#         print \"\\n -- score : \", score\n",
    "        \n",
    "        final = []\n",
    "        pred = heapq.nlargest(7, range(len(score)), score.__getitem__)\n",
    "#         print \"\\n -- pred : \", pred\n",
    "        for i in range(7):\n",
    "            if score[pred[i]] > 0:\n",
    "                final.append(pred[i])\n",
    "#         print \"\\n -- final : \", final\n",
    "        return final\n",
    "\n",
    "    predicted = _get_next_best_prediction(best, profiles, predicted, last_choice)\n",
    "\n",
    "    # print \"\\n- PREDICTED : \", predicted\n",
    "    # add suggestions from product_stats:\n",
    "    if len(predicted) < 7:\n",
    "        for product in product_stats:\n",
    "            # If user is not new\n",
    "            if last_choice is not None and last_choice[product[0]] == 1:\n",
    "                continue\n",
    "\n",
    "            if product[0] not in predicted:\n",
    "                predicted.append(product[0])\n",
    "                if len(predicted) == 7:\n",
    "                    break\n",
    "\n",
    "    # print \"FINAL PREDICTED : \", predicted\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zfturbo_predict_score(validation_data, get_profiles_func,\n",
    "                  common_recommendations,\n",
    "                  personal_recommendations,\n",
    "                  product_stats):\n",
    "    \n",
    "    logging.debug(\"-- zfturbo_predict_score\")\n",
    "    map7 = 0.0    \n",
    "    count = 25\n",
    "    for i, row in enumerate(validation_data):\n",
    "        predicted = zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                                        common_recommendations,\n",
    "                                        personal_recommendations,\n",
    "                                        product_stats)\n",
    "        real = get_real_values(row, personal_recommendations)\n",
    "        score = apk(real, predicted)\n",
    "        if count > 0:\n",
    "            print \"-- i : \", i, row[1], \" score : \", score, \" | predicted : \", predicted, \", real : \", real\n",
    "        map7 += score\n",
    "    \n",
    "        count-=1\n",
    "        if count == 0:\n",
    "            break\n",
    "        \n",
    "    if len(validation_data) > 0:\n",
    "        map7 /= len(validation_data)\n",
    "\n",
    "    logging.debug(\"--- predict_score : map7=%s\" % map7)\n",
    "    return map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "def sort_common_recommendations(common_recommendations):\n",
    "    out = dict()\n",
    "    for b in common_recommendations:\n",
    "        arr = common_recommendations[b]\n",
    "        srtd = sorted(arr.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        # remove 'total'\n",
    "        out[b] = [item for item in srtd if item[0] != 'total']\n",
    "    return out\n",
    "best_validation = sort_common_recommendations(common_recommendations_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#best_validation.items()[:100]\n",
    "# print common_recommendations_validation[(3, 'ES', 'H', 2, 'NA', 1530074)]\n",
    "# print best_validation[(3, 'ES', 'H', 2, 'NA', 1530074)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare common prediction methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> score :  [0, 0, 33, 0, 0, 0, 22, 0, 24, 0, 19, 23, 28, 20, 16, 18, 17, 26, 25, 21, 0, 29, 0, 32]\n",
      "--> score :  [0, 0, 63, 0, 0, 0, 44, 0, 43, 0, 19, 43, 53, 37, 31, 34, 17, 47, 48, 39, 0, 55, 0, 60]\n",
      "--> score :  [0, 0, 63, 0, 0, 0, 44, 0, 43, 0, 19, 43, 53, 37, 31, 34, 17, 47, 48, 39, 0, 55, 0, 87]\n",
      "--> score :  [0, 0, 93, 0, 0, 0, 67, 0, 43, 0, 19, 43, 81, 37, 31, 34, 17, 47, 48, 39, 0, 81, 0, 114]\n",
      "--> score :  [0, 0, 123, 0, 0, 0, 87, 0, 64, 0, 35, 62, 106, 54, 44, 49, 31, 70, 70, 57, 0, 107, 0, 143]\n",
      "--> score :  [0, 0, 153, 0, 0, 0, 108, 0, 83, 0, 51, 82, 131, 71, 57, 64, 45, 93, 92, 75, 0, 133, 0, 172]\n",
      "--> score :  [0, 0, 183, 0, 0, 0, 129, 0, 106, 0, 51, 102, 158, 89, 57, 80, 60, 112, 114, 92, 0, 158, 0, 201]\n",
      "--> score :  [0, 0, 214, 0, 0, 0, 151, 0, 130, 0, 51, 123, 186, 108, 57, 97, 76, 132, 137, 110, 0, 184, 0, 231]\n",
      "--> score :  [0, 0, 244, 0, 0, 0, 172, 0, 150, 0, 67, 142, 211, 125, 70, 112, 90, 155, 159, 128, 0, 210, 0, 260]\n",
      "--> score :  [0, 0, 274, 0, 0, 0, 191, 0, 170, 0, 67, 163, 236, 143, 70, 128, 90, 177, 182, 145, 0, 236, 0, 288]\n",
      "--> score :  [0, 0, 302, 0, 0, 0, 210, 0, 188, 0, 81, 180, 259, 158, 81, 141, 102, 198, 202, 161, 0, 260, 0, 315]\n",
      "\n",
      " -- score :  [0, 0, 302, 0, 0, 0, 210, 0, 188, 0, 81, 180, 259, 158, 81, 141, 102, 198, 202, 161, 0, 260, 0, 315]\n",
      "\n",
      " -- pred :  [23, 2, 21, 12, 6, 18, 17]\n",
      "\n",
      " -- final :  [23, 2, 21, 12, 6, 18, 17]\n",
      "\n",
      "- PREDICTED :  [23, 2, 21, 12, 6, 18, 17]\n",
      "FINAL PREDICTED :  [23, 2, 21, 12, 6, 18, 17]\n"
     ]
    }
   ],
   "source": [
    "# zfturbo_compute_predictions(validation_data[20], get_profiles,\n",
    "#                                         best_validation,\n",
    "#                                         product_stats_validation)\n",
    "\n",
    "row = validation_data[115]\n",
    "get_profiles_func = get_profiles\n",
    "\n",
    "\n",
    "predicted = []\n",
    "user = get_user(row)\n",
    "profiles = get_profiles_func(row)\n",
    "\n",
    "last_choice = None\n",
    "if user in personal_recommendations_validation:\n",
    "    last_choice = personal_recommendations_validation[user]['last_choice']\n",
    "\n",
    "def _get_next_best_prediction(best, profiles, predicted, last_choice):\n",
    "    import heapq\n",
    "    score = [0] * 24\n",
    "    for h in profiles:\n",
    "        if h in best:\n",
    "            #print \"-- profile : \", h\n",
    "            for i in range(len(best[h])):\n",
    "                sc = 24 - i + len(h)\n",
    "                #print \"-- i, len(h), sc, index, proba : \", i, len(h), sc, \" | \", best[h][i][0], \" | \", best[h][i][1]\n",
    "                index = best[h][i][0]\n",
    "                if last_choice is not None:\n",
    "                    #print \"--- \", index, last_choice[index] \n",
    "                    if last_choice[index] == 1:\n",
    "                        continue\n",
    "                if index not in predicted:\n",
    "                    score[index] += sc\n",
    "            print \"--> score : \", score\n",
    "\n",
    "    print \"\\n -- score : \", score\n",
    "\n",
    "    final = []\n",
    "    pred = heapq.nlargest(7, range(len(score)), score.__getitem__)\n",
    "    print \"\\n -- pred : \", pred\n",
    "    for i in range(7):\n",
    "        if score[pred[i]] > 0:\n",
    "            final.append(pred[i])\n",
    "    print \"\\n -- final : \", final\n",
    "    return final\n",
    "\n",
    "predicted = _get_next_best_prediction(best_validation, profiles, predicted, last_choice)\n",
    "\n",
    "print \"\\n- PREDICTED : \", predicted\n",
    "# add suggestions from product_stats:\n",
    "if len(predicted) < 7:\n",
    "    for product in product_stats:\n",
    "        # If user is not new\n",
    "        if last_choice is not None and last_choice[product[0]] == 1:\n",
    "            continue\n",
    "\n",
    "        if product[0] not in predicted:\n",
    "            predicted.append(product[0])\n",
    "            if len(predicted) == 7:\n",
    "                break\n",
    "\n",
    "print \"FINAL PREDICTED : \", predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[23, 4, 12, 7, 22, 21, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> target_weights:  0.0881542699725 0.0633608815427\n",
      "-> target_weights:  0.176033057851 0.148209366391\n",
      "-> target_weights:  0.26391184573 0.148209366391\n",
      "-> target_weights:  0.351790633609 0.23305785124\n",
      "-> target_weights:  0.439669421488 0.314876033058\n",
      "-> target_weights:  0.527548209366 0.375482093664\n",
      "-> target_weights:  0.615426997245 0.457300275482\n",
      "-> target_weights:  0.703403536835 0.539411712432\n",
      "-> target_weights:  0.791282324713 0.62122989425\n",
      "-> target_weights:  0.879161112592 0.706078379099\n",
      "-> target_weights:  0.966823450255 0.787247210268\n",
      "Common : [ 0.23209938  0.12454266  0.96682345  0.34087672  0.73218888  0.\n",
      "  0.52716609  0.83970751  0.67217123  0.21568915  0.27643486  0.50105496\n",
      "  0.78547562  0.50213594  0.4157704   0.44152924  0.43046807  0.74005916\n",
      "  0.64143593  0.5774822   0.46647942  0.58905308  0.61616902  0.78724721]\n",
      "Personal : [ 0.5  0.5  0.9  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5\n",
      "  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5  0.5]\n",
      "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "\n",
      " Predictions : [ 0.36604969  0.31227133  0.          0.42043836  0.61609444  0.25\n",
      "  0.51358304  0.66985375  0.58608562  0.35784457  0.38821743  0.50052748\n",
      "  0.64273781  0.50106797  0.4578852   0.47076462  0.46523403  0.62002958\n",
      "  0.57071797  0.5387411   0.48323971  0.54452654  0.55808451  0.64362361]\n",
      "[7, 23, 12, 17, 4, 8, 18]\n"
     ]
    }
   ],
   "source": [
    "# predicted1 = compute_predictions(row, get_profiles_func,\n",
    "#                                 _personal_recommendations,\n",
    "#                                 _common_recommendations,\n",
    "#                                 _product_stats,\n",
    "#                                 personal_recommendations_weight)\n",
    "\n",
    "\n",
    "row = validation_data[156]\n",
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.5\n",
    "\n",
    "\n",
    "predicted = []\n",
    "user = get_user(row)\n",
    "profiles = get_profiles_func(row)\n",
    "\n",
    "last_choice = None\n",
    "if user in _personal_recommendations:\n",
    "    last_choice = _personal_recommendations[user]['last_choice']\n",
    "\n",
    "target_weights = None\n",
    "total_length = 0.0\n",
    "total_count = 0\n",
    "# compute a total length to of participating profiles to define profile weight\n",
    "for profile in profiles:\n",
    "    if profile in _common_recommendations:\n",
    "        total_length += len(profile)\n",
    "        total_count += 1\n",
    "\n",
    "if total_length > 0:\n",
    "    target_weights = np.zeros(24)\n",
    "\n",
    "zfturbo_common_weight = 1.0\n",
    "mine_common_weight = 1.0 - zfturbo_common_weight\n",
    "    \n",
    "for profile in profiles:\n",
    "    if profile in _common_recommendations:\n",
    "        profile_weight = len(profile) * 1.0 / total_length\n",
    "        # _common_recommendations[profile].items() -> [(target, proba)]\n",
    "        target_probas = sorted(_common_recommendations[profile].items(), key=itemgetter(1), reverse=True)        \n",
    "\n",
    "        target_total_score = (24.0 + len(profile)) * total_count\n",
    "        for i, target_proba in enumerate(target_probas):\n",
    "            target_score = 24 - i + len(profile)\n",
    "            target = target_proba[0]\n",
    "            proba = target_proba[1]\n",
    "            if isinstance(target, int):\n",
    "                p1 =  _common_recommendations[profile][target] * profile_weight * mine_common_weight\n",
    "                p2 = target_score * 1.0 / target_total_score * zfturbo_common_weight \n",
    "                target_weights[target] += p1 + p2 #_common_recommendations[profile][target] * profile_weight\n",
    "        print \"-> target_weights: \", target_weights[2], target_weights[23]\n",
    "\n",
    "        \n",
    "personal_predictions = None\n",
    "if user in _personal_recommendations:\n",
    "    personal_predictions = _personal_recommendations[user]['recommendations']        \n",
    "\n",
    "print \"Common : {}\".format(target_weights)\n",
    "print \"Personal : {}\".format(personal_predictions)\n",
    "        \n",
    "# print \"\\n\\n target_weights : \", target_weights\n",
    "suggestions = (1.0 - personal_recommendations_weight) * target_weights + personal_recommendations_weight * personal_predictions\n",
    "print last_choice\n",
    "if last_choice is not None:\n",
    "    mask = np.abs(last_choice - 1)\n",
    "    suggestions *= mask\n",
    "    \n",
    "print \"\\n\\n Predictions : {}\".format(suggestions)\n",
    "# print \"\\n\\n Common predictions : \", suggestions\n",
    "    \n",
    "print np.argsort(suggestions)[::-1].tolist()[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 4, 22, 21, 18, 8, 19]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.0\n",
    "\n",
    "compute_predictions(row, get_profiles_func,\n",
    "                    _personal_recommendations,\n",
    "                    _common_recommendations,\n",
    "                    _product_stats,\n",
    "                    0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- zfturbo_predict_score\n",
      "DEBUG:root:--- predict_score : map7=1.07359839046e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- i :  0 657788  score :  0.0  | predicted :  [23, 7, 4, 22, 21, 8, 12] , real :  []\n",
      "-- i :  1 657795  score :  0.0  | predicted :  [23, 7, 4, 12, 17, 18, 22] , real :  []\n",
      "-- i :  2 657790  score :  0.0  | predicted :  [2, 7, 17, 8, 19, 11, 14] , real :  []\n",
      "-- i :  3 657794  score :  0.0  | predicted :  [12, 23, 4, 22, 21, 7, 17] , real :  []\n",
      "-- i :  4 657797  score :  0.0  | predicted :  [2, 23, 7, 12, 4, 8, 17] , real :  []\n",
      "-- i :  5 657789  score :  0.0  | predicted :  [12, 23, 4, 22, 21, 17, 19] , real :  []\n",
      "-- i :  6 657787  score :  0.0  | predicted :  [7, 23, 12, 17, 4, 18, 8] , real :  []\n",
      "-- i :  7 657777  score :  0.0  | predicted :  [7, 12, 23, 17, 4, 8, 18] , real :  []\n",
      "-- i :  8 657782  score :  0.0  | predicted :  [2, 23, 4, 12, 7, 22, 21] , real :  []\n",
      "-- i :  9 657781  score :  0.0  | predicted :  [2, 12, 23, 7, 4, 13, 19] , real :  []\n",
      "-- i :  10 657780  score :  0.0  | predicted :  [23, 12, 4, 7, 17, 8, 22] , real :  []\n",
      "-- i :  11 657779  score :  0.0  | predicted :  [2, 23, 12, 7, 22, 21, 18] , real :  []\n",
      "-- i :  12 657799  score :  0.0  | predicted :  [2, 7, 23, 4, 12, 17, 22] , real :  []\n",
      "-- i :  13 657774  score :  0.0  | predicted :  [7, 12, 23, 4, 8, 17, 22] , real :  []\n",
      "-- i :  14 657771  score :  0.0  | predicted :  [7, 12, 23, 4, 8, 17, 22] , real :  []\n",
      "-- i :  15 657770  score :  0.0  | predicted :  [7, 23, 12, 4, 17, 22, 18] , real :  []\n",
      "-- i :  16 657769  score :  0.0  | predicted :  [2, 7, 12, 23, 4, 17, 18] , real :  []\n",
      "-- i :  17 657766  score :  0.0  | predicted :  [2, 7, 23, 12, 4, 17, 8] , real :  []\n",
      "-- i :  18 657764  score :  0.0  | predicted :  [23, 4, 12, 22, 21, 17, 8] , real :  []\n",
      "-- i :  19 657760  score :  0.0  | predicted :  [23, 7, 4, 22, 17, 21, 8] , real :  []\n",
      "-- i :  20 657786  score :  1.0  | predicted :  [23, 4, 12, 7, 22, 21, 8] , real :  [23]\n",
      "-- i :  21 657802  score :  0.0  | predicted :  [7, 12, 23, 17, 4, 8, 18] , real :  []\n",
      "-- i :  22 657847  score :  0.0  | predicted :  [2, 23, 4, 12, 7, 8, 22] , real :  []\n",
      "-- i :  23 657806  score :  0.0  | predicted :  [2, 23, 12, 4, 7, 17, 8] , real :  []\n",
      "-- i :  24 657848  score :  0.0  | predicted :  [2, 23, 12, 7, 4, 17, 8] , real :  []\n",
      "1.07359839046e-06\n"
     ]
    }
   ],
   "source": [
    "map7 = zfturbo_predict_score(validation_data, get_profiles,\n",
    "                  best_validation,\n",
    "                  personal_recommendations_validation,\n",
    "                  product_stats_validation)\n",
    "\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:-- zfturbo_predict_score\n",
      "DEBUG:root:--- predict_score : map7=0.0214966531593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0214966531593\n"
     ]
    }
   ],
   "source": [
    "map7 = zfturbo_predict_score(validation_data, get_profiles,\n",
    "                  best_validation,\n",
    "                  personal_recommendations_validation,\n",
    "                  product_stats_validation)\n",
    "\n",
    "print map7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ZFTURBO_COMMON_WEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ZFTURBO_COMMON_WEIGHT = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0214970159248 0.0214966531593\n"
     ]
    }
   ],
   "source": [
    "# def _predict_score(validation_data, get_profiles_func,\n",
    "#                   personal_recommendations,\n",
    "#                   common_recommendations,\n",
    "#                   product_stats,\n",
    "#                   personal_recommendations_weight):\n",
    "\n",
    "get_profiles_func = get_profiles\n",
    "_personal_recommendations = personal_recommendations_validation\n",
    "_common_recommendations = common_recommendations_validation\n",
    "_product_stats = product_stats_validation\n",
    "personal_recommendations_weight = 0.0\n",
    "\n",
    "logging.debug(\"-- predict_score : personal_recommendations_weight=%s\" % personal_recommendations_weight)\n",
    "map7_1 = 0.0   \n",
    "map7_2 = 0.0   \n",
    "count = -1\n",
    "\n",
    "for i, row in enumerate(validation_data):\n",
    "\n",
    "    predicted1 = compute_predictions(row, get_profiles_func,\n",
    "                                    _personal_recommendations,\n",
    "                                    _common_recommendations,\n",
    "                                    _product_stats,\n",
    "                                    personal_recommendations_weight)\n",
    "\n",
    "    predicted2 = zfturbo_compute_predictions(row, get_profiles_func,\n",
    "                                        best_validation,\n",
    "                                        _personal_recommendations,\n",
    "                                        _product_stats)\n",
    "    \n",
    "    real = get_real_values(row, _personal_recommendations)\n",
    "    score1 = apk(real, predicted1)\n",
    "    score2 = apk(real, predicted2)\n",
    "    if count > 0 and score1 != score2:\n",
    "        print \"-- i : \", i, row[1]\n",
    "        print \"--- p1 : \", score1, predicted1, real\n",
    "        print \"--- p2 : \", score2, predicted2\n",
    "    map7_1 += score1\n",
    "    map7_2 += score2\n",
    "    \n",
    "    count -= 1\n",
    "    if count == 0:\n",
    "        break\n",
    "\n",
    "if len(validation_data) > 0:\n",
    "    map7_1 /= len(validation_data)\n",
    "    map7_2 /= len(validation_data)\n",
    "\n",
    "print map7_1, map7_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2.33026234774e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[7, 23, 12, 17, 4, 8, 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_filename is None:\n",
    "    return\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "writer = open(submission_file, \"w\")\n",
    "reader = open(test_filename, \"r\")\n",
    "\n",
    "# skip header:\n",
    "reader.readline()\n",
    "\n",
    "write_submission(writer, reader, target_labels, get_profiles, personal_recommendations, common_recommendations, product_stats)\n",
    "\n",
    "writer.close()\n",
    "reader.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
