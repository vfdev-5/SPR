{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPR single model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, average_precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 6)\n",
    "color = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_data import TARGET_LABELS, load_month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load 2015-01 - 2015-05 as training and test on 2015-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.DataFrame()\n",
    "for i in range(5):\n",
    "    df = load_month(i, True)\n",
    "    train = pd.concat([train, df], axis=0)\n",
    "    \n",
    "test = load_month(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250000, 45) (250000, 45)\n"
     ]
    }
   ],
   "source": [
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new columns 'target_value', 'target_value_diff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummies_to_decimal(row):\n",
    "    output = ''\n",
    "    for v in row.values:\n",
    "        output += str(int(v))\n",
    "    return log(int(output,2)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.loc[:, 'target_value'] = train[TARGET_LABELS].apply(dummies_to_decimal, axis=1)\n",
    "test.loc[:, 'target_value'] = test[TARGET_LABELS].apply(dummies_to_decimal, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_cat_data(df):\n",
    "    string_data = df.select_dtypes(include=[\"object\"])\n",
    "    for c in string_data.columns:\n",
    "        le = LabelEncoder()    \n",
    "        le.fit(df[c])\n",
    "        df[c] = le.transform(df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode_cat_data(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training data and targets\n",
    "\n",
    "~~- X_train, X_test : all columns of `train` dataset after train_test_split~~\n",
    "\n",
    "~~- Y_train, Y_test : `TARGET_LABELS` of `test` dataset after train_test_split~~\n",
    "\n",
    "- Get unique clients from `test` dataset\n",
    "- Keep rows for these\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(X):\n",
    "    date_cols = ['fecha_dato', 'fecha_alta']\n",
    "    out = X.drop(date_cols, axis=1)\n",
    "    out['duration'] = (X['fecha_dato'] - X['fecha_alta']).dt.days\n",
    "    cols = out.columns\n",
    "    out = pd.DataFrame(StandardScaler().fit_transform(out), columns=cols)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = transform_data(train)\n",
    "Y = test[TARGET_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1250000, 45) (250000, 24)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1250000, 250000]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c29d87a1c59e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1250000, 250000]"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 100, n_jobs = -1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999696\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, Y_train)\n",
    "score = rf.score(X_train, Y_train)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634559655909\n"
     ]
    }
   ],
   "source": [
    "Y_pred = rf.predict(X_test)\n",
    "print average_precision_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Train on all features and targets from a month as data, take TARGET_LABELS of the next month as Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = transform_data(train_month_1)\n",
    "X_test = transform_data(train_month_2)\n",
    "Y_train = train_month_2[TARGET_LABELS]\n",
    "Y_test = train_month_3[TARGET_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 250, n_jobs = -1, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "rf.fit(X_train, Y_train)\n",
    "score = rf.score(X_train, Y_train)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [628354, 250000]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-a1df513f7a09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     return _average_binary_score(_binary_average_precision, y_true, y_score,\n\u001b[0;32m--> 184\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [628354, 250000]"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "Y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 24) (628354, 24)\n"
     ]
    }
   ],
   "source": [
    "print Y_pred.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(249438, 24) (249438, 24)\n"
     ]
    }
   ],
   "source": [
    "mask1 = train_month_3['ncodpers'].isin(train_month_2['ncodpers'])\n",
    "mask2 = train_month_2['ncodpers'].isin(train_month_3['ncodpers'])\n",
    "Y_test_rd = Y_test[mask1]\n",
    "Y_pred_rd = pd.DataFrame(Y_pred)[mask2]\n",
    "print Y_test_rd.shape, Y_pred_rd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0704053710202\n"
     ]
    }
   ],
   "source": [
    "print average_precision_score(Y_test_rd, Y_pred_rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 0 'ncodpers' (0.204563)\n",
      "2. feature 43 'duration' (0.179916)\n",
      "3. feature 42 'logrenta' (0.163221)\n",
      "4. feature 4 'age' (0.126760)\n",
      "5. feature 15 'nomprov' (0.088124)\n",
      "6. feature 13 'canal_entrada' (0.053968)\n",
      "7. feature 3 'sexo' (0.021667)\n",
      "8. feature 17 'segmento' (0.015290)\n",
      "9. feature 20 'ind_cco_fin_ult1' (0.013514)\n",
      "10. feature 25 'ind_ctop_fin_ult1' (0.011349)\n",
      "11. feature 16 'ind_actividad_cliente' (0.010288)\n",
      "12. feature 9 'tiprel_1mes' (0.010283)\n",
      "13. feature 30 'ind_ecue_fin_ult1' (0.009976)\n",
      "14. feature 41 'ind_recibo_ult1' (0.009972)\n",
      "15. feature 35 'ind_reca_fin_ult1' (0.008522)\n",
      "16. feature 29 'ind_dela_fin_ult1' (0.008381)\n",
      "17. feature 26 'ind_ctpp_fin_ult1' (0.007534)\n",
      "18. feature 36 'ind_tjcr_fin_ult1' (0.007032)\n",
      "19. feature 11 'indext' (0.006979)\n",
      "20. feature 37 'ind_valo_fin_ult1' (0.006365)\n",
      "21. feature 31 'ind_fond_fin_ult1' (0.005264)\n",
      "22. feature 22 'ind_cno_fin_ult1' (0.004967)\n",
      "23. feature 40 'ind_nom_pens_ult1' (0.003446)\n",
      "24. feature 33 'ind_plan_fin_ult1' (0.003365)\n",
      "25. feature 39 'ind_nomina_ult1' (0.003358)\n",
      "26. feature 32 'ind_hip_fin_ult1' (0.002360)\n",
      "27. feature 38 'ind_viv_fin_ult1' (0.002331)\n",
      "28. feature 2 'pais_residencia' (0.001796)\n",
      "29. feature 24 'ind_ctma_fin_ult1' (0.001597)\n",
      "30. feature 14 'indfall' (0.001382)\n",
      "31. feature 28 'ind_deme_fin_ult1' (0.001190)\n",
      "32. feature 34 'ind_pres_fin_ult1' (0.001089)\n",
      "33. feature 10 'indresi' (0.000728)\n",
      "34. feature 27 'ind_deco_fin_ult1' (0.000690)\n",
      "35. feature 23 'ind_ctju_fin_ult1' (0.000628)\n",
      "36. feature 5 'ind_nuevo' (0.000540)\n",
      "37. feature 1 'ind_empleado' (0.000460)\n",
      "38. feature 7 'ult_fec_cli_1t' (0.000355)\n",
      "39. feature 21 'ind_cder_fin_ult1' (0.000339)\n",
      "40. feature 6 'indrel' (0.000258)\n",
      "41. feature 18 'ind_ahor_fin_ult1' (0.000079)\n",
      "42. feature 19 'ind_aval_fin_ult1' (0.000039)\n",
      "43. feature 12 'conyuemp' (0.000029)\n",
      "44. feature 8 'indrel_1mes' (0.000006)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAF6CAYAAADMAYYGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8XGV97/HP3juIEoI1Gu/aQCS/2qOihgqhKEpLrQKV\nVl+1ar0EEEXrwVo5x2trPWpprdiqRUXiraK1onhthVqtl4BUU7Vo9Zc0Yav1UiOJXOTS7J19/lhr\nh8lkzZU8syc7n/frlVf2rHmeeX7PWmtmf/daa2Ym5ubmkCRJUjmTC12AJEnSYmfgkiRJKszAJUmS\nVJiBS5IkqTADlyRJUmEGLkmSpMKWLHQBksZbROwCrgZ21YvmgK9m5llDPt7RwBmZefY+KrH98U8F\nfi0zX1ji8buMuxL4y8x80ijHlbR/MHBJ6mUOeHRm7thHj/cg4D776LH2kpmfAD5R6vG7WAmsXoBx\nJe0HJvzgU0nd1Ee47paZ2xvu+yXgr4HlwBTw5sx8V0RMAG8EjgGWARPAmcD3gQ3AYcBHgPcCb8nM\nB9ePd8L87Yj4E2AtcC/gG5n5jIh4GfA7VJdDTAPPy8wft9X0TOBJmXlqRHwO2AicCKwA3gTcAzgB\nOAT43cz8Vt3u28Aa4K7A+zLzVfXjnQb8cT3m9cAfZeZXWuq7J/At4BHAvYEvZObj6lqfABwMLAVe\nnJkfq/utrOf1i8BPgCdn5o8j4kjg7cDdgVngtZn59xFxb+AtwP2Ag4C/y8zzImIKeDPwq8D/AFuB\ndZl5U/etKmnUvIZLUj8+FxH/FhFfq/+/W/3L/hLg/2bmrwCPBl4cEY+gClr3ysy1mfkgqmD1ksz8\nL6rw8sXMPKN+7Pa/+lpv3x94aB22ng48GHhEZj4c+EdgfYd6Wx/jF+v2TwT+HPhsXe9lwAta2q0E\njgMeDjw5Ih4fEQG8FfjtzHwo8CfAxyLi0Jb6HpaZT6MKlFvqsHV/qpD3qLrfK4BXt4x1PPDEzHwg\n8DPgOfXyvwM+WK+zk4HX1mP9LbC+rvsY4KSIeBJV4Ht0Zh5V37cVeEiHdSJpAXlKUVI/9jqlGBEP\nBFYB76yPaAHckSqAvD0iXhkRz63bPJrq6NCgvpyZ8+HpFOBXgI1VDmISuFMfj/GR+v8tVEHsspbb\nJ7S0uzAzZ4HrI+JDwGOB7wCfyczvAmTm5yLiv6mOhLXXt1tmfi8ingX8fkQ8ADgWOLSlyb9k5s/r\nn78GLI+IuwBHUYfIOpweGRGH1HXeJSJeU/dZCjwUeD0wExFX1fP6SGZ+pY91ImnEPMIlqR8TDcum\ngB2Z+fDMfFhmPozq1Na7I+Jk4FNUAeejwNs6PMZc2/I7tN1/Y9t4f94y1tHsGZg6ubX1Rh2qmsy0\n/DxJdUpvoqHuKarTeu317RYRDweuoDqdehnVkbXWx7m55ef5dTBT/7w7wNVhbf4P47Utcz8OeF1m\nXkcVvP6o7v/BiDinw/wkLSADl6RhJXBLRDwNICLuC3yD6pTcrwMfz8y3A18FTqMKKlAFg/nAsg24\nf32KcqJu18llwJkRsay+/afAuwesuSn0zXtaREzUR5p+F/g48Dmq03crASLiROC+wFUN/Vvn9Ujg\nK5n5V8AX2HP+jTLzBqrrzZ5Zj3U/qtB2R+DLwIvr5XeuH/MJdbD9Z+DKzHw11anbo7qNI2lhGLgk\n9dL4zprM3El1UfiZEfENqkD0isy8kuqI1qMj4t+AfwD+CTi87nol8EsR8eHM/DZwIVXQuAL4YZc6\nLgI+CXw5Iq6mChbPGrD2bu8SOhj417q+v8nMf6nrex5waUT8O/A64JQ6HLX7FrArIr4MvB9YERHf\nBD4LfJ3qlODSHvU+jer6sa8DH6P6+Iyf1MuPrWv4MvCBzPwA1XVs3wS+GRFfobqm61U9xpC0AHyX\noqQDXv0uxbdm5t8vdC2SFqehLpqvD/1fQPUX5i3AmZm5teX+pwDnADuBqzPzefXyjcB1dbNrWt6l\nJEkLyb88JRU17LsUTwMOzszjIuIY4Px6GRFxR6q3Pz8oM2+NiPdHxClUpxTIzBP3Qd2StM/4uiSp\ntGGv4Toe+DRAZl5F9W6hebcCx2Xm/DuDllAdBTsKWBoRl0XEZ+qgJkmStOgNG7gO47ZTg1B9Dswk\nQGbOZeY2gIh4AbA0Mz8D3AS8PjMfC5wNXDzfR5IkaTEb9pTi9VSfLzNvMjPnv9h2/hqvvwCOpPoa\nDoBNwH8CZObmiLiW6qstftBtoJmZ2bklS7q+m1qSJGlcNH78zLCBawPVpz5fEhHHAle33X8hcHNm\ntn6mzjqqr5x4fv29YMuAH/UaaMeOwb4SbMWKZWzb1vSO7X3Xp3T7xTLGONY0ijHGsaZRjDGONY1i\njHGsaRRjjGNNoxhjHGsaxRjjWNMoxhi2pibDBq5LqT4McEN9e139zsSlVJ+nsw74Yv1W6zmqL7e9\niOoTqL9QLzu99aiYJEnSYjVU4Kq/O+zstsWb+njcpw8zniRJ0v7Mi9YlSZIKM3BJkiQVZuCSJEkq\nzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIkFWbgkiRJKszAJUmSVJiB\nS5IkqTADlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ck\nSVJhBi5JkqTCDFySJEmFGbgkSZIKW7LQBexL515wBVNTE5z3nLULXYokSdJuHuGSJEkqzMAlSZJU\nmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIkFWbgkiRJKszAJUmSVJiBS5IkqTAD\nlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ckSVJhSxa6\ngGHNzs4yPb11j2UzMzvZtWuSLVs277F85cojmJqaGmV5kiRJu+23gWt6eivXrV3D4S3LJs+4EIDl\na0/evewaYPrKjaxadeRoC5QkSaoNFbgiYgK4ADgKuAU4MzO3ttz/FOAcYCdwdWY+r1efYRwOrG65\nfVD9/+q2dttvzyCSJEm307DXcJ0GHJyZxwEvBc6fvyMi7gi8GjghMx8J/EJEnNKtjyRJ0mI2bOA6\nHvg0QGZeBRzdct+twHGZeWt9ewnVEa1ufSRJkhatYQPXYcB1LbdnImISIDPnMnMbQES8AFiamZ/p\n1keSJGkxm5ibmxu4U0S8AbgyMy+pb38vM+/fcv8E8BfAkcCTM/PWXn06mZmZnVuyZO93GG7atAki\n9rhe64z6ovn168+6rR1AJqtXt1/ZVfd5zeVVn1f8Rq9SJEmSeploWjjsuxQ3AKcAl0TEscDVbfdf\nCNycmacN0KfRjh03NS7fvv1GlvdZ7PbtN7Jt2w2N983OzjE1NdHx/iYrViwr2n6xjDGONY1ijHGs\naRRjjGNNoxhjHGsaxRjjWNMoxhjHmkYxxjjWNIoxhq2pybCB61LgpIjYUN9eV78zcSmwEVgHfDEi\nPgfMAX/d1GfIsSVJkvYrQwWuzJwDzm5bvKmPx23vI0mStOh50bokSVJhBi5JkqTCDFySJEmFGbgk\nSZIKM3BJkiQVZuCSJEkqzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIk\nFbZkoQvYl9avP2uhS5AkSdqLR7gkSZIKM3BJkiQVZuCSJEkqbFFdw9XL7Ows09Nb91g2M7OTXbsm\n2bJl8+5lK1cewdTU1KjLkyRJi9QBFbimp7dy3do1HN6ybPKMCwFYvvZkAK4Bpq/cyKpVR46+QEmS\ntCgdUIEL4HBgdcvtg+r/W5dtH105kiTpAOA1XJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJklSY\ngUuSJKkwA5ckSVJhBi5JkqTCDFySJEmFGbgkSZIKM3BJkiQVZuCSJEkqzMAlSZJU2JKFLmB/c+4F\nVzA1NcF5z1m70KVIkqT9hEe4JEmSCjNwSZIkFeYpxS5mZ2eZnt66x7KZmZ3s2jXJli2b91i+cuUR\nTE1NjbI8SZK0nzBwdTE9vZXr1q7h8JZlk2dcCMDytSfvXnYNMH3lRlatOnK0BUqSpP2CgauHw4HV\nLbcPqv9f3dZu+2jKkSRJ+yGv4ZIkSSrsgD/CtX79WQtdgiRJWuQO+MA1KAOaJEkalKcUJUmSCjNw\nSZIkFWbgkiRJKszAJUmSVJiBS5IkqbCh3qUYERPABcBRwC3AmZm5ta3NIcDlwOmZualethG4rm5y\nTWaeMWzhkiRJ+4thPxbiNODgzDwuIo4Bzq+XARARa4C3AfdpWXYwQGaeOHy5kiRJ+59hTykeD3wa\nIDOvAo5uu/8OVAHsOy3LjgKWRsRlEfGZOqhJkiQtesMGrsO47dQgwExE7H6szLwyM38ATLS0uQl4\nfWY+FjgbuLi1jyRJ0mI1bOC5HljW+jiZuatHn03AxQCZuRm4FrjXkONLkiTtN4a9hmsDcApwSUQc\nC1zdR591wEOA50fEvakC2496dbrLXQ5hyZKpvZbv2HFo38UuX34oK1Ys67vPoO1b+3TS7b591Wcc\nxxjHmkYxxjjWNIoxxrGmUYwxjjWNYoxxrGkUY4xjTaMYYxxrGsUYw9TUZNjAdSlwUkRsqG+vi4in\nAEsz86KWdnMtP68H3hkRX6iXn97HUTF27Lipcfn27TeyvM9it2+/kW3bbui7z6DtW/s0WbFiWcf7\nOhm0zziOMY41jWKMcaxpFGOMY02jGGMcaxrFGONY0yjGGMeaRjHGONY0ijGGranJUIErM+eorsNq\ntamh3YktP88AzxhmPEmSpP2ZF61LkiQVZuCSJEkqzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxc\nkiRJhRm4JEmSCjNwSZIkFWbgkiRJKszAJUmSVNiwX16tPp17wRVMTU1w3nPWLnQpkiRpgXiES5Ik\nqTADlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ckSVJh\nfrXPPjQ7O8v09NY9ls3M7GTXrkm2bNm8x/KVK49gampqlOVJkqQFYuDah6ant3Ld2jUc3rJs8owL\nAVi+9uTdy64Bpq/cyKpVR462QEmStCAMXPvY4cDqltsH1f+vbmu3fTTlSJKkMeA1XJIkSYUZuCRJ\nkgozcEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ckSVJhBi5JkqTCDFySJEmF+Unzha1ff9ZClyBJ\nkhaYR7gkSZIKM3BJkiQVZuCSJEkqzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmS\nCjNwSZIkFWbgkiRJKszAJUmSVJiBS5IkqbAlw3SKiAngAuAo4BbgzMzc2tbmEOBy4PTM3NRPH0mS\npMVo2CNcpwEHZ+ZxwEuB81vvjIg1wOeBI/rtI0mStFgNG7iOBz4NkJlXAUe33X8HqoD1nQH6SJIk\nLUrDBq7DgOtabs9ExO7HyswrM/MHwES/fSRJkharoa7hAq4HlrXcnszMXQX6cJe7HMKSJVN7Ld+x\n49B+6gRg+fJDWbFiWd99Bm0/32cQ82N00+v+29t+FGOMY02jGGMcaxrFGONY0yjGGMeaRjHGONY0\nijHGsaZRjDGONY1ijGFqajJs4NoAnAJcEhHHAlcX6sOOHTc1Lt++/UaW91cr27ffyLZtN/TdZ9D2\n832AgWvqZMWKZV3vv73tRzHGONY0ijHGsaZRjDGONY1ijHGsaRRjjGNNoxhjHGsaxRjjWNMoxhi2\npibDBq5LgZMiYkN9e11EPAVYmpkXtbSb69ZnyLElSZL2K0MFrsycA85uW7ypod2JPfpIkiQtel60\nLkmSVJiBS5IkqTADlyRJUmEGLkmSpMIMXJIkSYUN+7EQKujcC65gamqC856zdqFLkSRJ+4BHuCRJ\nkgozcEmSJBVm4JIkSSrMa7gW2OzsLNPTW/dYNjOzk127JtmyZfMey1euPIKpqb2/yFuSJI03A9cC\nm57eynVr13B4y7LJMy4EYPnak3cvuwaYvnIjq1YdOdoCJUnS7WbgGgOHA6tbbh9U/7+6rd320ZQj\nSZL2Ma/hkiRJKszAJUmSVJinFMfQ+vVnLXQJkiRpH/IIlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgoz\ncEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ckSVJhBi5JkqTCDFySJEmFGbgkSZIKM3BJkiQVZuCS\nJEkqzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhS1Z6AJ0+517wRVMTU1w3nPWLnQpkiSp\ngUe4JEmSCjNwSZIkFWbgkiRJKszAJUmSVJiBS5IkqTADlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgoz\ncEmSJBVm4JIkSSrMwCVJklSYX169n5mdnWV6eusey2ZmdrJr1yRbtmzeY/nKlUcwNTU1yvIkSVKD\noQJXREwAFwBHAbcAZ2bm1pb7TwVeCewE3pWZF9XLNwLX1c2uycwzbkftB6Tp6a1ct3YNh7csmzzj\nQgCWrz1597JrgOkrN7Jq1ZGjLVCSJO1l2CNcpwEHZ+ZxEXEMcH69jIhYUt9eA9wMbIiIjwHXA2Tm\nibe76gPc4cDqltsH1f+vbmu3fTTlSJKkHoa9hut44NMAmXkVcHTLfQ8ENmfm9Zm5E/gS8Ciqo2FL\nI+KyiPhMHdQkSZIWvWED12HcdmoQYCYiJjvcdwNwZ+DnwOsz87HA2cDFLX0kSZIWrWFPKV4PLGu5\nPZmZu1ruO6zlvmXAz4DNwBaAzNwcEdcC9wJ+0G2gu9zlEJYs2fvC7x07Du272OXLD2XFimV99xm0\n/XyfQYxyjG563T/q9otljHGsaRRjjGNNoxhjHGsaxRjjWNMoxhjHmkYxxjjWNIoxhqmpybCBawNw\nCnBJRBwLXN1y37eBB0TELwA3AY8EXg+sAx4CPD8i7k0VxH7Ua6AdO25qXL59+40s77PY7dtvZNu2\nG/ruM2j7+T5AsZpuzxidrFixrOv9o26/WMYYx5pGMcY41jSKMcaxplGMMY41jWKMcaxpFGOMY02j\nGGPYmpoMG7guBU6KiA317XUR8RRgaWZeFBEvAi4HJoD1mfmjiFgPvDMivgDMAae3HBWTJElatIYK\nXJk5R3UdVqtNLfd/CvhUW58Z4BnDjCdJkrQ/86J1SZKkwgxckiRJhRm4JEmSCjNwSZIkFWbgkiRJ\nKszAJUmSVNiwn8OlMbJ+/VkLXYIkSerCI1ySJEmFGbgkSZIKM3BJkiQVZuCSJEkqzMAlSZJUmIFL\nkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIkFWbgkiRJKszAJUmSVJiBS5IkqTADlyRJ\nUmEGLkmSpMIMXJIkSYUtWegCtDDOveAKpqYmOO85a4u0lyRJt/EIlyRJUmEGLkmSpMI8pXgAmJ2d\nZXp66x7LZmZ2smvXJFu2bN69bOXKI5iamhp1eZIkLXoGrgPA9PRWrlu7hsNblk2ecSEAy9eeDMA1\nwPSVG1m16sjRFyhJ0iJn4DpAHA6sbrl9UP1/67LtoytHkqQDitdwSZIkFWbgkiRJKsxTigeo9evP\nWugSJEk6YBi4VIQflCpJ0m0MXNpLvx8jAfv2oyQMaZKkxcrApb308zES4EdJSJLULwOXGvXzMRJQ\nfZTEQh0RkyRpf2Hg0u22UEfEPAUpSdpfGLi0TwxyRAz2n+vESreXJB0YDFxaEF4nJkk6kBi4tGBK\nXyc26Jd2DzoGsE+O0nlUTJIWPwOXitjXH6w6zBGxQb+0e9AxgIFr2henUocJaIY6SVpYBi7tNwa9\nTqzfPoO2b+0zaPtBQ93KlUfsF9e6SZK6M3DpgDLokbcSX4E0SEgb5sjeQpxKfcunfsjk5CTPe9w9\n92rvqVRJMnBpPzaO3wc5ioD23g5jDHIUbX88lSpJ+zMDl8bGOAaoUVioo2j78lTqvgiB0P1Uaq+j\naE2hrqmPgU7SQjBwqS8HahhaLMZh+5U+lTrokT1JGiUDl6S9jCKg9Rpj0KNoTX26Hdnr94gYDH/t\n2qBjeORNWryGClwRMQFcABwF3AKcmZlbW+4/FXglsBN4V2Ze1KuPJO1r3ULdKK5d2xenUgF27DiU\n7dtv3GNZt1DX1MdAJy2sYY9wnQYcnJnHRcQxwPn1MiJiSX17DXAzsCEiPgYc36mPJC2EQY+i7Yuj\nbt36NAW019QB7RUt/XqFuvY+vd7AAJ1DHex9ZK9b+0FCYGsfabEbNnAdD3waIDOvioijW+57ILA5\nM68HiIgvAicAa7v0kSRRLtR1ewPDvOUtP3c7srcvQmBrn331JgnofGRvHINmyTEMsuNn2MB1GHBd\ny+2ZiJjMzF0N990I3BlY1qXPUK7ps82dB+gzaPv2PiVqGsUY41jTKMYYx5pGMcY41jSKMcaxplGM\n0d7+9nrFENf4deszPb2Vb6xdw31alv1e/f9PX33bsh8AtIS69j4AP2X49q19gIHadxrj4jpoPq1l\n/t3G6Na+3zFa2wN7ffQKNIe6YduP0xijrmkQE3NzcwN3iog3AFdm5iX17e9l5v3rnx8MnJeZJ9e3\nzwe+BBwHfLmpTzczM7NzS5bsndJnZ2fZsmVLX/WuWrVq918G/fQZtP18H6BYTaMYYxxrGsUY41jT\nKMYYx5pGMcY41jSKMcaxplGMMY41jWKM+fYAmzZt6muM1atXD9V+nMYYdU0dTDQuHDJw/Q5wSmae\nHhHHAq9sCVhLgG8BxwA3ARuA36I6pdjYp5tt224YqMAVK5axbdsNA81n0D6l2y+WMcaxplGMMY41\njWKMcaxpFGOMY02jGGMcaxrFGONY0yjGGMeaRjHGkDU1Bq5hTyleCpwUERvq2+si4inA0vodiS8C\nLqdKeesz80cRsVefIceWJEnarwwVuDJzDji7bfGmlvs/BXyqjz6SJEmL3uRCFyBJkrTYGbgkSZIK\nM3BJkiQVZuCSJEkqzMAlSZJUmIFLkiSpMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIkFWbg\nkiRJKszAJUmSVJiBS5IkqTADlyRJUmEGLkmSpMIMXJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJ\nklSYgUuSJKkwA5ckSVJhBi5JkqTCDFySJEmFGbgkSZIKM3BJkiQVZuCSJEkqzMAlSZJUmIFLkiSp\nMAOXJElSYQYuSZKkwgxckiRJhRm4JEmSCjNwSZIkFWbgkiRJKszAJUmSVJiBS5IkqTADlyRJUmEG\nLkmSpMIMXJIkSYUZuCRJkgozcEmSJBVm4JIkSSrMwCVJklSYgUuSJKkwA5ckSVJhBi5JkqTClgzT\nKSLuCLwPuDtwPfDMzLy2rc2zgbOAncBrM/NT9fL/AjbVza7MzJcPWbskSdJ+YajABZwN/Htmvjoi\nngy8Enjh/J0RcQ/gBcDDgUOAL0XE5cD9gY2Z+YTbV7YkSdL+Y9hTiscDn65//kfg19vufwTwpcyc\nyczrgc3AQ4A1wH0j4rMR8cmIWD3k+JIkSfuNnke4IuJ04A+BuXrRBPBj4Lr69g3AYW3dDmu5H+BG\n4M7AD4HXZeaHI+JXqU5LPmLo6iVJkvYDE3Nzc71btYmIDwN/lplfjYjDqI5mPaTl/lOB38zM59e3\nPwK8Bvg2MJOZO+vl38/M++2DeUiSJI2tYU8pbgAeX//8eOCLbff/K3B8RNwhIu4M/BLwTeCPqa/1\nioijgO8POb4kSdJ+Y9gjXHcC3gPcC7gVeGpm/iQi/hDYnJmfjIgzgOdQnYJ8bWZ+tA5f7wMOBWaA\n52fmpuZRJEmSFoehApckSZL65wefSpIkFWbgkiRJKszAJUmSVNiwnzQ/diJiArgAOAq4BTgzM7d2\naHt34KtUH9i6BHh7fdfmut+uLu0PAd5EddH/rcAzMnNbj9p29+/0JoGIOAY4LzMfExEPBT7JbV+B\n9NbM/FCPPr/cax51n0ngHUAAu4DnZuZ/9FHTB4B7UL0JYiXV1zI9taXtEuCd9X13AF4L/Afw7nqc\nb85/TEiX9t8fYt4r6vn8Ql3bMzLzuw19DgIuAo4E/gc4JzO/0c/6odrOjfNo6bfXNo6I84HvZOaF\nfYxxh05z77Cuvgu8jWo/3Ey1HXd2af/lbuupQ03beq3b1m3RsqzfeZ8NvIIO+1W3fbVpjA7z/h7w\nZro8X9ue37N02dYd1hN0ee516LOEztuv0/7R+LrTof0s1f4+B2zKzDNp0LTOMvMTg7SLiKcCf5CZ\nxzX0a9o/Gtt32H6bOs2jx/7RV00RsYru27uppqfSeZ9tav+fwPx+2vG1uWXMjdz2OZbXZOYZndo2\nzamPts8EnkW1Tu9E9TvznvWHlHecd8v2bnx+t43xEuC3qPbzt2Tme/upPSKCHvttW/ujgLfS8Dzq\n0P6h9Pn7u84UF1HtX7PAs2/vm/wW0xGu04CD6yfYS4HzmxrVO9LbgJvqRa8FXpKZj6R6Ap3apf0E\n8FdU7648EbgUeEm3ohrGa2pzLtULx8H1ojXAGzLzxPpfU+ho79N1Hi1OBeYy83iqr2R6XT81ZeZT\n6jn/NrCDlq9yqv0+8NPMfBTwm8BbqLbByzLzBGAyIp7Qof3j6vYPH2LefwG8LzMfDfwJ8KAO8342\ncHO9f5xF9WLSpGn9dJvHXts4Iu4WEf/AYNug2zZvWrfvAP6wXvZD4Pkd2s+v217rqammrn3at8UQ\n835tj/1qr5p6jNG0nro+Xxuen123dYf19Bq6P/ea+lxE5+3X1P6NXebR1P5VVOv3UcAdI+LkhvXV\nvs7m95W+20XEw4DTmzo0PFe7tu8wxp90mUfja9mANfXa3nvV1GOfbdoH+31tJiLmX2/nXwf6CVt7\nreduMvM9mfmYeg4bgRe0hq1O846Iu/Z4fs/XcwKwtn6tfQxwxAC1vwp4Taf9tqF9t9fBpvaD/P7+\nDWBpvX/9Pzr8rhzEYgpcu79uKDOvAo7u0O4vqRLxD+vbv5OZGyLiDsA92fMT8tvbzwFPzsyr6/uW\nADf3qKsZ0aARAAAHyklEQVR9vCb/SfXknbcGODkiPh8RF0XE0j769JoHAJn5MarAAdVfLzv6rGne\nnwJvzsyftC3/e6oXPYApqr8gHp6Z85/R1v4VUK3tJ6m+5HwNcMqA8/5Vqq+L+ieqvzw/22E+/6uu\ngfqvlPvUH9q7h7b184tU66fbPGDvbbyU6hfF3zYV0mEbdJt707q9X72fQ/W5eI/q0H6ybn8ccL9O\n66nDvLv2Ye9tcegQ8563137VoX23ddu+nnbS+/nauu0m6LGtO9T0xG7PvYZ1+zPgvp22X4cxfq/T\nPDq0vxm4a/1X+rJ6XTRpeh721S4illOFzXM69Nlj/4iIu/Zo37Tf3tJpHk3zHrQmYE2P53a39dP0\nWrjXPpiZfb02144ClkbEZRHxmfroTC+dXqu7ioijgV/OzPUNdzfNu+vzu8VjgW9GxEeBj9f/Ommv\nvdd+296+2+tgU/tBfn/fAty5ruXOVGdGbpfFFLjav05opj7kvFtEPAv4SWb+E9WLK5k5FxH3o/pg\n1rsC3+jR/r/r+46jStNv7FRQU/8mmXkp1YvLvKuAc+u/urZSpf6ufbrNo6Hvroh4F/DXwMV91kR9\n+u5EqkPw7e1vysyfR8Qy4EPAy9lzzjdQ7bSd2r+C6gNzXzzIvKleaLdn5klUpyQ7/cXydeCUeh7H\nAnej+uXdNPf59fMm4P3d5tFhH/luZn6F7tu8fRtc1WnuHdbt1oh4ZN3k1Na5dGh/OHBtt/XUMO+u\nfRr2wekh5t1rv9qjfbd12zTv+V+GTc/XDs/P1teMPbZ1l5p6Pvfa1u3FdNl+Hcbo+rrTsF7fXP/8\nLeDuwL+019RpnfXZ7pXAeuBFwM9p3h6794/6tfiiHu3bx3hZr3m0zfsDg9RU6/jc7lDTy+v5NO6z\nXdr39dpMdaT19Zn5WKpT7he3/x7rY079eilVaGx6zKbnUs/XtdrdqP6AfBLVHN4/QO1vpnqOdNre\n7e239Hgetb9G9f37G/gS1SnX71BdMvCmLm37spgC1/VUiXjeZO59nnwdcFJEfA54KPDeiLhHZn4/\nM1dTrdQ39mh/94h4MtX1Yo/PzGu71NTYv4+5fDQzv1b/fGndt6cu82hquw5YDVwU1QfZ9uNJwPsz\ns/HD2+oXlc8C78nMv6O6LmLeMqq/7Lu1H2be1wLz15x8guqJ3uSdwA0R8QWq08+bgO2dHrR1/VA9\n6TrNY9ht3D7G5d3m3rCuTgdeVh99+gnw0x7tf0of66mtph399BlUw77Xdb8aZF9tm/cH62Wdnq+t\n2+4o4L3Aipb799pnO9XUz3Ovpc87qH4Rddx+TWP0et1pab8e+DBwfGb+MtURicZLLKB5nfVqR3Xk\n4AFURwc/ADwwqmt7Onl4P+0banlfr3m0zPujwEMGqAl6vEZ1qAm67LNN7Qd4bd5E/YdIZm6men27\nV485DCyqDyFfnZmf79Kmr/2iwbXAZZk5k9XZhFsi4m599u25vdt0fR1sMsDv7/8DbMjMoH59qI9S\nDm0xBa7dXzdUH8G4ur1BZp6Q1bnrxwBfA54BvCMiHlA3uYHq4rim9l+v2/8GVTJ+dDZcnN1lvK9T\nXaDXfiquyafrw70Av0Z1nr2riPh4p3m0tXt6RLy0vnlL3a7jBZzs+dfMr1Oflmt43HsAlwH/JzPf\nUy/+WkTMH+J9HC1fAdWh/cDzrh9z/mumHkX1l1GTRwCfzepc/4eAH2fmrQ3zaFo/X43quoS95jHM\nNm4YYxfwkYj4lXrZHnPvsK5OofqGh5Oo/mq+vEf7L9FlPXWY9xeAkzv1adHrL95uY+yiw3416L7a\nNO+I+H06PF8btt3TgX/stM92qGkX8NFuz70O8+i2/ZraP7HTPDq0vxNwY73sh1RvfOhrnfXTLjO/\nkpkPzupamN8D/iMzX9Sh+0RmfrVX+w61HEK1TveaR8O8fwQ8sM+a5v1bj+3daf102meb9sG+Xptr\n64A31P3uTRUCf9RjDvP6eh7WHgX8c6c7+90vOvgS1fVr83M4hCqE9aPj9u6g4/OoSbfXgwaHcttZ\ns59RnYKc6tGnq0XzLkWqowInRcSG+va6Pvu9Dnh3RNxKdTi38d08VNdvLaE6dP1d4NKImAM+n5mN\nh2Ub+vfrucDfRMT/AD/mtusUuvkz+pvHJXW7z1PN55ym4NGite7VVKe7mryU6snxyoj447rfOcCb\no3qH4Lfrsbu1fyHwVwPO+8VURwDOpnpyPLVDuwQ+GBEvozpv/+wO7drXz/+mOqR8UYd5tGrfxp22\nedMY3wMu6DD3pnX1BuCfI+IW4CtUR2e6tX8msL7Lemqq6Rt1n+d26HN7531OZt4aEZ32q277atMY\n7fOeorp2b5Dn64up/gjrtK33qonq3ZzdnnvtfV5Y199p+zW1f3eXeTTVdBNwSUTcTHXtSaf9vWlf\neVzDa0K/7Zr0+9rXNMYfAB/uMI+m/WPQ62x6be+mmh5P59fCpvYvp7/XZqiOTr6zPhI/B5zecKam\nk0F+xwSdX8uh+/buOk5mfioiHhkR/0oVAp/X6eh1g2fTeXs32UTn59Eeojo1O8jv79cD74qIL1Lt\nXy/NzF7XbHflV/tIkiQVtphOKUqSJI0lA5ckSVJhBi5JkqTCDFySJEmFGbgkSZIKM3BJkiQVZuCS\nJEkqzMAlSZJU2P8H8yNeFjSF+1EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f6bca90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print(\"Feature ranking:\")\n",
    "features = X_train.columns.values\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d '%s' (%f)\" % (f + 1, indices[f], features[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cv(data, targets, clf, cv=10):\n",
    "    X0 = data\n",
    "    y = targets\n",
    "    X = StandardScaler().fit_transform(X0)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring=make_scorer(mape_error))\n",
    "    print scores      \n",
    "    print scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function average_precision_score in module sklearn.metrics.ranking:\n",
      "\n",
      "average_precision_score(y_true, y_score, average='macro', sample_weight=None)\n",
      "    Compute average precision (AP) from prediction scores\n",
      "    \n",
      "    This score corresponds to the area under the precision-recall curve.\n",
      "    \n",
      "    Note: this implementation is restricted to the binary classification task\n",
      "    or multilabel classification task.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    y_true : array, shape = [n_samples] or [n_samples, n_classes]\n",
      "        True binary labels in binary label indicators.\n",
      "    \n",
      "    y_score : array, shape = [n_samples] or [n_samples, n_classes]\n",
      "        Target scores, can either be probability estimates of the positive\n",
      "        class, confidence values, or non-thresholded measure of decisions\n",
      "        (as returned by \"decision_function\" on some classifiers).\n",
      "    \n",
      "    average : string, [None, 'micro', 'macro' (default), 'samples', 'weighted']\n",
      "        If ``None``, the scores for each class are returned. Otherwise,\n",
      "        this determines the type of averaging performed on the data:\n",
      "    \n",
      "        ``'micro'``:\n",
      "            Calculate metrics globally by considering each element of the label\n",
      "            indicator matrix as a label.\n",
      "        ``'macro'``:\n",
      "            Calculate metrics for each label, and find their unweighted\n",
      "            mean.  This does not take label imbalance into account.\n",
      "        ``'weighted'``:\n",
      "            Calculate metrics for each label, and find their average, weighted\n",
      "            by support (the number of true instances for each label).\n",
      "        ``'samples'``:\n",
      "            Calculate metrics for each instance, and find their average.\n",
      "    \n",
      "    sample_weight : array-like of shape = [n_samples], optional\n",
      "        Sample weights.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    average_precision : float\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] `Wikipedia entry for the Average precision\n",
      "           <https://en.wikipedia.org/wiki/Average_precision>`_\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    roc_auc_score : Area under the ROC curve\n",
      "    \n",
      "    precision_recall_curve :\n",
      "        Compute precision-recall pairs for different probability thresholds\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.metrics import average_precision_score\n",
      "    >>> y_true = np.array([0, 0, 1, 1])\n",
      "    >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "    >>> average_precision_score(y_true, y_scores)  # doctest: +ELLIPSIS\n",
      "    0.79...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(average_precision_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}