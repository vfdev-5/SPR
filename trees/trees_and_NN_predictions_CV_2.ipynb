{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees and NN tryouts on SPR data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data as \n",
    "    month : [ Features | Targets| Difference | Last Choice Targets  ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from dataset2 import load_trainval, FEATURES_NAMES, TARGET_GROUP_DEC_LABELS, TARGET_LABELS_FRQ\n",
    "from utils import to_yearmonth, TARGET_LABELS, TARGET_LABELS2\n",
    "from utils import target_str_to_labels, decimal_to_dummies, targets_str_to_indices, targets_dec_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load file : ../data/train_ver2.csv, yearmonth=201605, n_clients=1500\n",
      "INFO:root:-- Select 1500 clients\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 9\n",
      "INFO:root:-- Process targets for one yearmonth : 201605\n",
      "INFO:root:-- Process features for one yearmonth : 201605\n",
      "INFO:root:-- Process targets for one yearmonth : 201604\n",
      "INFO:root:-- Process features for one yearmonth : 201604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ind_valo_fin_ult1_frq', 'targets_dec_g3_1', 'targets_str_1', 'ind_ctpp_fin_ult1_frq_1', 'ind_ahor_fin_ult1_frq', 'ind_plan_fin_ult1_frq_1', 'ind_nom_pens_ult1_frq', 'ind_pres_fin_ult1_frq_1', 'ind_deme_fin_ult1_frq_1', 'ind_viv_fin_ult1_frq_1', 'ind_aval_fin_ult1_frq_1', 'ind_recibo_ult1_frq_1', 'ind_ctop_fin_ult1_frq', 'ind_ctma_fin_ult1_frq', 'ind_ctju_fin_ult1_frq_1', 'targets_str', 'ind_ctop_fin_ult1_frq_1', 'targets_dec_g0_1', 'ind_cder_fin_ult1_frq', 'ind_deme_fin_ult1_frq', 'targets_dec_g1_1', 'ind_ctma_fin_ult1_frq_1', 'ind_pres_fin_ult1_frq', 'targets_dec_g2_1', 'ind_cder_fin_ult1_frq_1', 'targets_logdec_1', 'ind_ctpp_fin_ult1_frq', 'ind_viv_fin_ult1_frq', 'ind_dela_fin_ult1_frq_1', 'ind_cco_fin_ult1_frq_1', 'ind_recibo_ult1_frq', 'ind_valo_fin_ult1_frq_1', 'ind_cno_fin_ult1_frq_1', 'ind_reca_fin_ult1_frq_1', 'ind_deco_fin_ult1_frq', 'targets_dec_g1', 'targets_dec_g0', 'targets_dec_g3', 'targets_dec_g2', 'ind_hip_fin_ult1_frq', 'ind_fond_fin_ult1_frq_1', 'ind_fond_fin_ult1_frq', 'ind_ecue_fin_ult1_frq', 'ind_tjcr_fin_ult1_frq', 'ind_hip_fin_ult1_frq_1', 'ind_cno_fin_ult1_frq', 'ind_dela_fin_ult1_frq', 'ind_reca_fin_ult1_frq', 'ind_nomina_ult1_frq', 'ind_plan_fin_ult1_frq', 'targets_logdec', 'ind_nomina_ult1_frq_1', 'ind_ecue_fin_ult1_frq_1', 'ind_aval_fin_ult1_frq', 'ind_ctju_fin_ult1_frq', 'ind_nom_pens_ult1_frq_1', 'ind_ahor_fin_ult1_frq_1', 'ind_deco_fin_ult1_frq_1', 'ind_tjcr_fin_ult1_frq_1', 'ind_cco_fin_ult1_frq']\n"
     ]
    }
   ],
   "source": [
    "df = load_trainval(201605, 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 106)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_str</th>\n",
       "      <th>targets_str_1</th>\n",
       "      <th>ind_cco_fin_ult1_frq</th>\n",
       "      <th>ind_cder_fin_ult1_frq</th>\n",
       "      <th>ind_cco_fin_ult1_frq_1</th>\n",
       "      <th>ind_cder_fin_ult1_frq_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310589</th>\n",
       "      <td>16056</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001010001000000000000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310974</th>\n",
       "      <td>16926</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310714</th>\n",
       "      <td>17147</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312384</th>\n",
       "      <td>19775</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001000000000010000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312864</th>\n",
       "      <td>20565</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001000000000000000110000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311971</th>\n",
       "      <td>22398</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001000000000000001000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311705</th>\n",
       "      <td>22955</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306078</th>\n",
       "      <td>25232</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305666</th>\n",
       "      <td>25688</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>001000010000000001100000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.618667</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306262</th>\n",
       "      <td>26781</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.381333</td>\n",
       "      <td>0.998667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ncodpers  fecha_dato targets_str             targets_str_1  \\\n",
       "310589     16056  2016-05-28         NaN  001010001000000000000001   \n",
       "310974     16926  2016-05-28         NaN  000000000000000000000000   \n",
       "310714     17147  2016-05-28         NaN  000000000000000000000000   \n",
       "312384     19775  2016-05-28         NaN  001000000000010000000000   \n",
       "312864     20565  2016-05-28         NaN  001000000000000000110000   \n",
       "311971     22398  2016-05-28         NaN  001000000000000001000000   \n",
       "311705     22955  2016-05-28         NaN  000000000000000000000000   \n",
       "306078     25232  2016-05-28         NaN  001000000000000000000000   \n",
       "305666     25688  2016-05-28         NaN  001000010000000001100000   \n",
       "306262     26781  2016-05-28         NaN  000000000000000000000000   \n",
       "\n",
       "        ind_cco_fin_ult1_frq  ind_cder_fin_ult1_frq  ind_cco_fin_ult1_frq_1  \\\n",
       "310589                   NaN                    NaN                0.618667   \n",
       "310974                   NaN                    NaN                0.381333   \n",
       "310714                   NaN                    NaN                0.381333   \n",
       "312384                   NaN                    NaN                0.618667   \n",
       "312864                   NaN                    NaN                0.618667   \n",
       "311971                   NaN                    NaN                0.618667   \n",
       "311705                   NaN                    NaN                0.381333   \n",
       "306078                   NaN                    NaN                0.618667   \n",
       "305666                   NaN                    NaN                0.618667   \n",
       "306262                   NaN                    NaN                0.381333   \n",
       "\n",
       "        ind_cder_fin_ult1_frq_1  \n",
       "310589                 0.998667  \n",
       "310974                 0.998667  \n",
       "310714                 0.998667  \n",
       "312384                 0.998667  \n",
       "312864                 0.998667  \n",
       "311971                 0.998667  \n",
       "311705                 0.998667  \n",
       "306078                 0.998667  \n",
       "305666                 0.998667  \n",
       "306262                 0.998667  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['ncodpers', 'fecha_dato', 'targets_str', 'targets_str_1', 'ind_cco_fin_ult1_frq', 'ind_cder_fin_ult1_frq', 'ind_cco_fin_ult1_frq_1', 'ind_cder_fin_ult1_frq_1']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111 ['fecha_dato' 'ncodpers' 'ind_empleado' 'pais_residencia' 'sexo' 'age'\n",
      " 'fecha_alta' 'ind_nuevo' 'antiguedad' 'indrel' 'ult_fec_cli_1t'\n",
      " 'indrel_1mes' 'tiprel_1mes' 'indresi' 'indext' 'conyuemp' 'canal_entrada'\n",
      " 'indfall' 'nomprov' 'ind_actividad_cliente' 'renta' 'segmento'\n",
      " 'ind_ahor_fin_ult1' 'ind_aval_fin_ult1' 'ind_cco_fin_ult1'\n",
      " 'ind_cder_fin_ult1' 'ind_cno_fin_ult1' 'ind_ctju_fin_ult1'\n",
      " 'ind_ctma_fin_ult1' 'ind_ctop_fin_ult1' 'ind_ctpp_fin_ult1'\n",
      " 'ind_deco_fin_ult1' 'ind_deme_fin_ult1' 'ind_dela_fin_ult1'\n",
      " 'ind_ecue_fin_ult1' 'ind_fond_fin_ult1' 'ind_hip_fin_ult1'\n",
      " 'ind_plan_fin_ult1' 'ind_pres_fin_ult1' 'ind_reca_fin_ult1'\n",
      " 'ind_tjcr_fin_ult1' 'ind_valo_fin_ult1' 'ind_viv_fin_ult1'\n",
      " 'ind_nomina_ult1' 'ind_nom_pens_ult1' 'ind_recibo_ult1' 'targets_str'\n",
      " 'targets_logdec' 'targets_dec_g0' 'targets_dec_g1' 'targets_dec_g2'\n",
      " 'targets_dec_g3' 'ind_ahor_fin_ult1_frq' 'ind_aval_fin_ult1_frq'\n",
      " 'ind_cco_fin_ult1_frq' 'ind_cder_fin_ult1_frq' 'ind_cno_fin_ult1_frq'\n",
      " 'ind_ctju_fin_ult1_frq' 'ind_ctma_fin_ult1_frq' 'ind_ctop_fin_ult1_frq'\n",
      " 'ind_ctpp_fin_ult1_frq' 'ind_deco_fin_ult1_frq' 'ind_deme_fin_ult1_frq'\n",
      " 'ind_dela_fin_ult1_frq' 'ind_ecue_fin_ult1_frq' 'ind_fond_fin_ult1_frq'\n",
      " 'ind_hip_fin_ult1_frq' 'ind_plan_fin_ult1_frq' 'ind_pres_fin_ult1_frq'\n",
      " 'ind_reca_fin_ult1_frq' 'ind_tjcr_fin_ult1_frq' 'ind_valo_fin_ult1_frq'\n",
      " 'ind_viv_fin_ult1_frq' 'ind_nomina_ult1_frq' 'ind_nom_pens_ult1_frq'\n",
      " 'ind_recibo_ult1_frq' 'targets_str_1' 'targets_logdec_1'\n",
      " 'targets_dec_g0_1' 'targets_dec_g1_1' 'targets_dec_g2_1'\n",
      " 'targets_dec_g3_1' 'ind_ahor_fin_ult1_frq_1' 'ind_aval_fin_ult1_frq_1'\n",
      " 'ind_cco_fin_ult1_frq_1' 'ind_cder_fin_ult1_frq_1'\n",
      " 'ind_cno_fin_ult1_frq_1' 'ind_ctju_fin_ult1_frq_1'\n",
      " 'ind_ctma_fin_ult1_frq_1' 'ind_ctop_fin_ult1_frq_1'\n",
      " 'ind_ctpp_fin_ult1_frq_1' 'ind_deco_fin_ult1_frq_1'\n",
      " 'ind_deme_fin_ult1_frq_1' 'ind_dela_fin_ult1_frq_1'\n",
      " 'ind_ecue_fin_ult1_frq_1' 'ind_fond_fin_ult1_frq_1'\n",
      " 'ind_hip_fin_ult1_frq_1' 'ind_plan_fin_ult1_frq_1'\n",
      " 'ind_pres_fin_ult1_frq_1' 'ind_reca_fin_ult1_frq_1'\n",
      " 'ind_tjcr_fin_ult1_frq_1' 'ind_valo_fin_ult1_frq_1'\n",
      " 'ind_viv_fin_ult1_frq_1' 'ind_nomina_ult1_frq_1' 'ind_nom_pens_ult1_frq_1'\n",
      " 'ind_recibo_ult1_frq_1' 'targets_diff_1' 'targets_dec_g0_diff_1'\n",
      " 'targets_dec_g1_diff_1' 'targets_dec_g2_diff_1' 'targets_dec_g3_diff_1']\n"
     ]
    }
   ],
   "source": [
    "print len(df.columns), df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load file : ../data/train_ver2.csv, yearmonth=201605, n_clients=5500\n",
      "INFO:root:-- Select 5500 clients\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 9\n",
      "INFO:root:- Process targets for one yearmonth : 201605\n",
      "INFO:root:- Add a supplementary data : 201505\n",
      "INFO:root:- Number of lines with unknown data : 3597\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:- Compute missing clients : 1802/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 13.2841827869\n",
      "INFO:root:- Compute missing clients : 1564/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 30.4563500881\n",
      "INFO:root:- Compute missing clients : 945/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 38.723692894\n",
      "INFO:root:- Compute missing clients : 155/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 4.82230901718\n",
      "INFO:root:- Compute missing clients : 63/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 1.42462992668\n",
      "INFO:root:- Compute missing clients : 41/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 1.32581996918\n",
      "INFO:root:- Compute missing clients : 23/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 1.52650403976\n",
      "INFO:root:- Compute missing clients : 1/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.296236038208\n",
      "INFO:root:- Compute missing clients : 0/5500\n",
      "INFO:root:- Add a supplementary data : 201604\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:- Compute missing clients : 24/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 1.92688894272\n",
      "INFO:root:- Compute missing clients : 10/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.657173871994\n",
      "INFO:root:- Compute missing clients : 9/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.458240032196\n",
      "INFO:root:- Compute missing clients : 9/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.497607946396\n",
      "INFO:root:- Compute missing clients : 9/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.469041824341\n",
      "INFO:root:- Compute missing clients : 9/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 0.952314853668\n",
      "INFO:root:- Compute missing clients : 5/5500\n",
      "INFO:root:- Match and add\n",
      "INFO:root:-- Match and add elapsed time: 1.01642608643\n",
      "INFO:root:- Compute missing clients : 0/5500\n"
     ]
    }
   ],
   "source": [
    "X_train = load_X(201605, [201505, 201604], 150000)\n",
    "# X, X_ym = load_X(201605, [201505, 201604], 1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
       "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
       "       'conyuemp', 'canal_entrada', 'indfall', 'nomprov',\n",
       "       'ind_actividad_cliente', 'renta', 'segmento', 'ind_ahor_fin_ult1',\n",
       "       'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1',\n",
       "       'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
       "       'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1',\n",
       "       'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1',\n",
       "       'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1',\n",
       "       'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1',\n",
       "       'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1',\n",
       "       'ind_nom_pens_ult1', 'ind_recibo_ult1', 'targets_str',\n",
       "       'targets_logdec', 'targets_dec_g0', 'targets_dec_g1',\n",
       "       'targets_dec_g2', 'targets_dec_g3', 'ind_ahor_fin_ult1_frq',\n",
       "       'ind_aval_fin_ult1_frq', 'ind_cco_fin_ult1_frq',\n",
       "       'ind_cder_fin_ult1_frq', 'ind_cno_fin_ult1_frq',\n",
       "       'ind_ctju_fin_ult1_frq', 'ind_ctma_fin_ult1_frq',\n",
       "       'ind_ctop_fin_ult1_frq', 'ind_ctpp_fin_ult1_frq',\n",
       "       'ind_deco_fin_ult1_frq', 'ind_deme_fin_ult1_frq',\n",
       "       'ind_dela_fin_ult1_frq', 'ind_ecue_fin_ult1_frq',\n",
       "       'ind_fond_fin_ult1_frq', 'ind_hip_fin_ult1_frq',\n",
       "       'ind_plan_fin_ult1_frq', 'ind_pres_fin_ult1_frq',\n",
       "       'ind_reca_fin_ult1_frq', 'ind_tjcr_fin_ult1_frq',\n",
       "       'ind_valo_fin_ult1_frq', 'ind_viv_fin_ult1_frq',\n",
       "       'ind_nomina_ult1_frq', 'ind_nom_pens_ult1_frq',\n",
       "       'ind_recibo_ult1_frq', 'targets_diff_1', 'targets_dec_g0_diff_1',\n",
       "       'targets_dec_g1_diff_1', 'targets_dec_g2_diff_1',\n",
       "       'targets_dec_g3_diff_1', 'targets_dec_g3_1', 'targets_str_1',\n",
       "       'ind_ctpp_fin_ult1_frq_1', 'ind_plan_fin_ult1_frq_1',\n",
       "       'ind_ctju_fin_ult1_frq_1', 'targets_logdec_1',\n",
       "       'ind_viv_fin_ult1_frq_1', 'ind_pres_fin_ult1_frq_1',\n",
       "       'ind_recibo_ult1_frq_1', 'ind_ctop_fin_ult1_frq_1',\n",
       "       'targets_dec_g0_1', 'targets_dec_g1_1', 'ind_ctma_fin_ult1_frq_1',\n",
       "       'targets_dec_g2_1', 'ind_cder_fin_ult1_frq_1',\n",
       "       'ind_dela_fin_ult1_frq_1', 'ind_cco_fin_ult1_frq_1',\n",
       "       'ind_valo_fin_ult1_frq_1', 'ind_cno_fin_ult1_frq_1',\n",
       "       'ind_reca_fin_ult1_frq_1', 'ind_aval_fin_ult1_frq_1',\n",
       "       'ind_fond_fin_ult1_frq_1', 'ind_hip_fin_ult1_frq_1',\n",
       "       'ind_deco_fin_ult1_frq_1', 'ind_nomina_ult1_frq_1',\n",
       "       'ind_ecue_fin_ult1_frq_1', 'ind_deme_fin_ult1_frq_1',\n",
       "       'ind_nom_pens_ult1_frq_1', 'ind_tjcr_fin_ult1_frq_1',\n",
       "       'ind_ahor_fin_ult1_frq_1', 'targets_diff_2',\n",
       "       'targets_dec_g0_diff_2', 'targets_dec_g1_diff_2',\n",
       "       'targets_dec_g2_diff_2', 'targets_dec_g3_diff_2', 'targets_str_2',\n",
       "       'targets_logdec_2', 'targets_dec_g3_2', 'ind_ctpp_fin_ult1_frq_2',\n",
       "       'ind_plan_fin_ult1_frq_2', 'ind_viv_fin_ult1_frq_2',\n",
       "       'ind_deme_fin_ult1_frq_2', 'ind_pres_fin_ult1_frq_2',\n",
       "       'ind_recibo_ult1_frq_2', 'ind_aval_fin_ult1_frq_2',\n",
       "       'targets_dec_g0_2', 'ind_ctop_fin_ult1_frq_2',\n",
       "       'ind_ctma_fin_ult1_frq_2', 'targets_dec_g1_2',\n",
       "       'ind_nom_pens_ult1_frq_2', 'ind_cder_fin_ult1_frq_2',\n",
       "       'targets_dec_g2_2', 'ind_dela_fin_ult1_frq_2',\n",
       "       'ind_valo_fin_ult1_frq_2', 'ind_cco_fin_ult1_frq_2',\n",
       "       'ind_reca_fin_ult1_frq_2', 'ind_cno_fin_ult1_frq_2',\n",
       "       'ind_fond_fin_ult1_frq_2', 'ind_hip_fin_ult1_frq_2',\n",
       "       'ind_deco_fin_ult1_frq_2', 'ind_nomina_ult1_frq_2',\n",
       "       'ind_ecue_fin_ult1_frq_2', 'ind_tjcr_fin_ult1_frq_2',\n",
       "       'ind_ctju_fin_ult1_frq_2', 'ind_ahor_fin_ult1_frq_2'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets_str</th>\n",
       "      <th>targets_str_1</th>\n",
       "      <th>targets_str_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310903</th>\n",
       "      <td>001000000000000000100000</td>\n",
       "      <td>001000000000000000100000</td>\n",
       "      <td>001000000000000000100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310729</th>\n",
       "      <td>001000000000000001000001</td>\n",
       "      <td>001000000000000001000001</td>\n",
       "      <td>001000000000000001000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310670</th>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>001100011000000000000000</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309359</th>\n",
       "      <td>000010000000100001100111</td>\n",
       "      <td>000010000000100001000111</td>\n",
       "      <td>000010000000100001100111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309440</th>\n",
       "      <td>001000000000000100010000</td>\n",
       "      <td>001000000000000100010000</td>\n",
       "      <td>001000000000000100010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     targets_str             targets_str_1  \\\n",
       "310903  001000000000000000100000  001000000000000000100000   \n",
       "310729  001000000000000001000001  001000000000000001000001   \n",
       "310670  000000000000000000000000  001100011000000000000000   \n",
       "309359  000010000000100001100111  000010000000100001000111   \n",
       "309440  001000000000000100010000  001000000000000100010000   \n",
       "\n",
       "                   targets_str_2  \n",
       "310903  001000000000000000100000  \n",
       "310729  001000000000000001000001  \n",
       "310670  000000000000000000000000  \n",
       "309359  000010000000100001100111  \n",
       "309440  001000000000000100010000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['targets_str', 'targets_str_1', 'targets_str_2']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310503</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>15936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309780</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>18987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309739</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>19021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311087</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>19299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312469</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>20842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha_dato  ncodpers\n",
       "310503  2016-05-28     15936\n",
       "309780  2016-05-28     18987\n",
       "309739  2016-05-28     19021\n",
       "311087  2016-05-28     19299\n",
       "312469  2016-05-28     20842"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['fecha_dato', 'ncodpers']].sort_values(['fecha_dato', 'ncodpers']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>628533</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418150</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>18987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418144</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>19021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418393</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>19299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418996</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>20842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fecha_dato  ncodpers\n",
       "628533  2015-05-28     15936\n",
       "418150  2015-05-28     18987\n",
       "418144  2015-05-28     19021\n",
       "418393  2015-05-28     19299\n",
       "418996  2015-05-28     20842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ym[['fecha_dato', 'ncodpers']].sort_values(['fecha_dato', 'ncodpers']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X['ncodpers'] == X_ym['ncodpers']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'fecha_dato', u'ncodpers', u'ind_empleado', u'pais_residencia',\n",
       "       u'sexo', u'age', u'fecha_alta', u'ind_nuevo', u'antiguedad', u'indrel',\n",
       "       u'ult_fec_cli_1t', u'indrel_1mes', u'tiprel_1mes', u'indresi',\n",
       "       u'indext', u'conyuemp', u'canal_entrada', u'indfall', u'nomprov',\n",
       "       u'ind_actividad_cliente', u'renta', u'segmento', u'ind_ahor_fin_ult1',\n",
       "       u'ind_aval_fin_ult1', u'ind_cco_fin_ult1', u'ind_cder_fin_ult1',\n",
       "       u'ind_cno_fin_ult1', u'ind_ctju_fin_ult1', u'ind_ctma_fin_ult1',\n",
       "       u'ind_ctop_fin_ult1', u'ind_ctpp_fin_ult1', u'ind_deco_fin_ult1',\n",
       "       u'ind_deme_fin_ult1', u'ind_dela_fin_ult1', u'ind_ecue_fin_ult1',\n",
       "       u'ind_fond_fin_ult1', u'ind_hip_fin_ult1', u'ind_plan_fin_ult1',\n",
       "       u'ind_pres_fin_ult1', u'ind_reca_fin_ult1', u'ind_tjcr_fin_ult1',\n",
       "       u'ind_valo_fin_ult1', u'ind_viv_fin_ult1', u'ind_nomina_ult1',\n",
       "       u'ind_nom_pens_ult1', u'ind_recibo_ult1', u'targets_str',\n",
       "       u'targets_logdec', u'targets_dec_g0', u'targets_dec_g1',\n",
       "       u'targets_dec_g2', u'targets_dec_g3', u'ind_ahor_fin_ult1_frq',\n",
       "       u'ind_aval_fin_ult1_frq', u'ind_cco_fin_ult1_frq',\n",
       "       u'ind_cder_fin_ult1_frq', u'ind_cno_fin_ult1_frq',\n",
       "       u'ind_ctju_fin_ult1_frq', u'ind_ctma_fin_ult1_frq',\n",
       "       u'ind_ctop_fin_ult1_frq', u'ind_ctpp_fin_ult1_frq',\n",
       "       u'ind_deco_fin_ult1_frq', u'ind_deme_fin_ult1_frq',\n",
       "       u'ind_dela_fin_ult1_frq', u'ind_ecue_fin_ult1_frq',\n",
       "       u'ind_fond_fin_ult1_frq', u'ind_hip_fin_ult1_frq',\n",
       "       u'ind_plan_fin_ult1_frq', u'ind_pres_fin_ult1_frq',\n",
       "       u'ind_reca_fin_ult1_frq', u'ind_tjcr_fin_ult1_frq',\n",
       "       u'ind_valo_fin_ult1_frq', u'ind_viv_fin_ult1_frq',\n",
       "       u'ind_nomina_ult1_frq', u'ind_nom_pens_ult1_frq',\n",
       "       u'ind_recibo_ult1_frq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'age', u'antiguedad', u'canal_entrada', u'conyuemp', u'fecha_alta',\n",
       "       u'fecha_dato', u'ind_actividad_cliente', u'ind_ahor_fin_ult1',\n",
       "       u'ind_aval_fin_ult1', u'ind_cco_fin_ult1', u'ind_cder_fin_ult1',\n",
       "       u'ind_cno_fin_ult1', u'ind_ctju_fin_ult1', u'ind_ctma_fin_ult1',\n",
       "       u'ind_ctop_fin_ult1', u'ind_ctpp_fin_ult1', u'ind_deco_fin_ult1',\n",
       "       u'ind_dela_fin_ult1', u'ind_deme_fin_ult1', u'ind_ecue_fin_ult1',\n",
       "       u'ind_empleado', u'ind_fond_fin_ult1', u'ind_hip_fin_ult1',\n",
       "       u'ind_nom_pens_ult1', u'ind_nomina_ult1', u'ind_nuevo',\n",
       "       u'ind_plan_fin_ult1', u'ind_pres_fin_ult1', u'ind_reca_fin_ult1',\n",
       "       u'ind_recibo_ult1', u'ind_tjcr_fin_ult1', u'ind_valo_fin_ult1',\n",
       "       u'ind_viv_fin_ult1', u'indext', u'indfall', u'indrel', u'indrel_1mes',\n",
       "       u'indresi', u'ncodpers', u'nomprov', u'pais_residencia', u'renta',\n",
       "       u'segmento', u'sexo', u'tiprel_1mes', u'ult_fec_cli_1t',\n",
       "       u'targets_str_1', u'targets_logdec_1', u'targets_dec_g0_1',\n",
       "       u'targets_dec_g1_1', u'targets_dec_g2_1', u'targets_dec_g3_1',\n",
       "       u'ind_ahor_fin_ult1_frq_1', u'ind_aval_fin_ult1_frq_1',\n",
       "       u'ind_cco_fin_ult1_frq_1', u'ind_cder_fin_ult1_frq_1',\n",
       "       u'ind_cno_fin_ult1_frq_1', u'ind_ctju_fin_ult1_frq_1',\n",
       "       u'ind_ctma_fin_ult1_frq_1', u'ind_ctop_fin_ult1_frq_1',\n",
       "       u'ind_ctpp_fin_ult1_frq_1', u'ind_deco_fin_ult1_frq_1',\n",
       "       u'ind_deme_fin_ult1_frq_1', u'ind_dela_fin_ult1_frq_1',\n",
       "       u'ind_ecue_fin_ult1_frq_1', u'ind_fond_fin_ult1_frq_1',\n",
       "       u'ind_hip_fin_ult1_frq_1', u'ind_plan_fin_ult1_frq_1',\n",
       "       u'ind_pres_fin_ult1_frq_1', u'ind_reca_fin_ult1_frq_1',\n",
       "       u'ind_tjcr_fin_ult1_frq_1', u'ind_valo_fin_ult1_frq_1',\n",
       "       u'ind_viv_fin_ult1_frq_1', u'ind_nomina_ult1_frq_1',\n",
       "       u'ind_nom_pens_ult1_frq_1', u'ind_recibo_ult1_frq_1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ym.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ym.index = X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import dummies_to_decimal\n",
    "from dataset2 import TARGET_GROUP_DEC_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_index=1\n",
    "\n",
    "def compute_diffs(df1, df2, label_index):\n",
    "    compute_targets_diff(df1, df2, label_index)\n",
    "    compute_targets_group_diff(df1, df2, label_index)\n",
    "\n",
    "    \n",
    "def compute_targets_diff(df1, df2, label_index):\n",
    "    field_name = 'targets_diff_%i' % label_index\n",
    "    df1.loc[:, field_name] = df1[TARGET_LABELS].apply(dummies_to_decimal, axis=1) - df2[TARGET_LABELS].apply(dummies_to_decimal, axis=1)\n",
    "\n",
    "    \n",
    "def compute_targets_group_diff(df1, df2, label_index):\n",
    "    for label1 in TARGET_GROUP_DEC_LABELS:\n",
    "        if label_index > 0:\n",
    "            label2 = label1 + '_%i' % label_index\n",
    "        field_name = label1 + '_diff_%i' % label_index\n",
    "        df1.loc[:, field_name] = df1[label1] - df2[label2]\n",
    "    \n",
    "\n",
    "X_ = X.copy()\n",
    "compute_diffs(X_, X_ym, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = list(set(X_ym.columns) - set(FEATURES_NAMES + ['fecha_alta', 'fecha_dato', 'ncodpers'] + TARGET_LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in cols:\n",
    "    X_.loc[:, c] = X_ym.loc[:, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n",
       "       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n",
       "       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n",
       "       'conyuemp', 'canal_entrada', 'indfall', 'nomprov',\n",
       "       'ind_actividad_cliente', 'renta', 'segmento', 'ind_ahor_fin_ult1',\n",
       "       'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1',\n",
       "       'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1',\n",
       "       'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1',\n",
       "       'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1',\n",
       "       'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1',\n",
       "       'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1',\n",
       "       'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1',\n",
       "       'ind_nom_pens_ult1', 'ind_recibo_ult1', 'targets_str',\n",
       "       'targets_logdec', 'targets_dec_g0', 'targets_dec_g1',\n",
       "       'targets_dec_g2', 'targets_dec_g3', 'ind_ahor_fin_ult1_frq',\n",
       "       'ind_aval_fin_ult1_frq', 'ind_cco_fin_ult1_frq',\n",
       "       'ind_cder_fin_ult1_frq', 'ind_cno_fin_ult1_frq',\n",
       "       'ind_ctju_fin_ult1_frq', 'ind_ctma_fin_ult1_frq',\n",
       "       'ind_ctop_fin_ult1_frq', 'ind_ctpp_fin_ult1_frq',\n",
       "       'ind_deco_fin_ult1_frq', 'ind_deme_fin_ult1_frq',\n",
       "       'ind_dela_fin_ult1_frq', 'ind_ecue_fin_ult1_frq',\n",
       "       'ind_fond_fin_ult1_frq', 'ind_hip_fin_ult1_frq',\n",
       "       'ind_plan_fin_ult1_frq', 'ind_pres_fin_ult1_frq',\n",
       "       'ind_reca_fin_ult1_frq', 'ind_tjcr_fin_ult1_frq',\n",
       "       'ind_valo_fin_ult1_frq', 'ind_viv_fin_ult1_frq',\n",
       "       'ind_nomina_ult1_frq', 'ind_nom_pens_ult1_frq',\n",
       "       'ind_recibo_ult1_frq', 'targets_diff_1', 'targets_dec_g0_diff_1',\n",
       "       'targets_dec_g1_diff_1', 'targets_dec_g2_diff_1',\n",
       "       'targets_dec_g3_diff_1', 'targets_dec_g3_1', 'targets_str_1',\n",
       "       'ind_ctpp_fin_ult1_frq_1', 'ind_plan_fin_ult1_frq_1',\n",
       "       'ind_ctju_fin_ult1_frq_1', 'targets_logdec_1',\n",
       "       'ind_viv_fin_ult1_frq_1', 'ind_pres_fin_ult1_frq_1',\n",
       "       'ind_recibo_ult1_frq_1', 'ind_ctop_fin_ult1_frq_1',\n",
       "       'targets_dec_g0_1', 'targets_dec_g1_1', 'ind_ctma_fin_ult1_frq_1',\n",
       "       'targets_dec_g2_1', 'ind_cder_fin_ult1_frq_1',\n",
       "       'ind_dela_fin_ult1_frq_1', 'ind_cco_fin_ult1_frq_1',\n",
       "       'ind_valo_fin_ult1_frq_1', 'ind_cno_fin_ult1_frq_1',\n",
       "       'ind_reca_fin_ult1_frq_1', 'ind_aval_fin_ult1_frq_1',\n",
       "       'ind_fond_fin_ult1_frq_1', 'ind_hip_fin_ult1_frq_1',\n",
       "       'ind_deco_fin_ult1_frq_1', 'ind_nomina_ult1_frq_1',\n",
       "       'ind_ecue_fin_ult1_frq_1', 'ind_deme_fin_ult1_frq_1',\n",
       "       'ind_nom_pens_ult1_frq_1', 'ind_tjcr_fin_ult1_frq_1',\n",
       "       'ind_ahor_fin_ult1_frq_1'], dtype=object)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>targets_str_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310503</th>\n",
       "      <td>15936</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309780</th>\n",
       "      <td>18987</td>\n",
       "      <td>001010000001110001110111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309739</th>\n",
       "      <td>19021</td>\n",
       "      <td>000000000000000000100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311087</th>\n",
       "      <td>19299</td>\n",
       "      <td>000010000001100001010001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312469</th>\n",
       "      <td>20842</td>\n",
       "      <td>001000000000100000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ncodpers             targets_str_1\n",
       "310503     15936  001000000000000000000000\n",
       "309780     18987  001010000001110001110111\n",
       "309739     19021  000000000000000000100000\n",
       "311087     19299  000010000001100001010001\n",
       "312469     20842  001000000000100000000000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ym[['ncodpers', 'targets_str_1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset2 import TARGET_GROUP_DEC_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[['targets_str', 'targets_logdec'] + TARGET_GROUP_DEC_LABELS + FEATURES_NAMES].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train[['fecha_dato', 'ncodpers',]].sort_values(['fecha_dato', 'ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X_train\n",
    "from dataset2 import TARGET_GROUP_DEC_LABELS, FEATURES_NAMES\n",
    "from dataset2 import TRAIN_FILE_PATH, load_data2, minimal_clean_data_inplace, preprocess_data_inplace, process_features, process_targets\n",
    "\n",
    "supp_yearmonths_list = [201505, 201604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_clients = X['ncodpers'].unique()\n",
    "# for ym in supp_yearmonths_list:\n",
    "ym = supp_yearmonths_list[0]\n",
    "fname = TEST_FILE_PATH if ym == 201606 else TRAIN_FILE_PATH\n",
    "X_ym = load_data2(fname, [ym])\n",
    "minimal_clean_data_inplace(X_ym)\n",
    "preprocess_data_inplace(X_ym)\n",
    "# process_targets(X_ym)\n",
    "process_features(X_ym)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clients = X_ym['ncodpers'].unique()\n",
    "common_clients = np.array(list(set(ref_clients) & set(clients)))\n",
    "missing_clients = np.array(list(set(ref_clients) - set(clients)))\n",
    "print common_clients.shape, missing_clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X[X['ncodpers'].isin(missing_clients)].shape\n",
    "X[X['ncodpers'].isin(missing_clients)].sort_values(['ncodpers']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_ym[X_ym['ncodpers'].isin(missing_clients)].shape\n",
    "X_ym[X_ym['ncodpers'].isin(missing_clients)].sort_values(['ncodpers']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features_to_str(features):\n",
    "    return '_'.join([str(int(f)) for f in features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to search for a feature profiles of missing clients in the supplementary month and create a new account in the supplementary month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import _to_ym_dec, _to_nb_months\n",
    "\n",
    "ref_ym = 201605\n",
    "delta_months = _to_nb_months(_to_ym_dec(ref_ym) - _to_ym_dec(ym))\n",
    "print delta_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ym_ = X_ym.copy()\n",
    "\n",
    "\n",
    "def update_seniority(row):\n",
    "    row['antiguedad'] -= delta_months\n",
    "    return row\n",
    "\n",
    "\n",
    "fg = match_features_groups[0]\n",
    "print \"- Compute missing clients : \"\n",
    "clients = X_ym_['ncodpers'].unique()\n",
    "common_clients = np.array(list(set(ref_clients) & set(clients)))\n",
    "missing_clients = np.array(list(set(ref_clients) - set(clients)))\n",
    "print common_clients.shape, missing_clients.shape\n",
    "print \"- Feature group : \", fg\n",
    "missing_clients_mask = X['ncodpers'].isin(missing_clients)\n",
    "x_features_str = X[missing_clients_mask][fg].apply(update_seniority, axis=1).apply(features_to_str, axis=1)\n",
    "x_ym_features_str = X_ym_[fg].apply(features_to_str, axis=1)\n",
    "print \"- Match and add\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_x_ym_features_str = x_ym_features_str[x_ym_features_str.isin(x_features_str)]\n",
    "common_x_ym_features_str = common_x_ym_features_str.sort_values()\n",
    "common_x_features_str = x_features_str[x_features_str.isin(common_x_ym_features_str)].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print common_x_ym_features_str.shape, common_x_features_str.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = common_x_features_str.groupby(common_x_features_str)\n",
    "gb_ym = common_x_ym_features_str.groupby(common_x_ym_features_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_x_ym_indices = gb_ym.apply(lambda x: x.index)\n",
    "common_x_ym_indices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_index_map = gb.transform(lambda x: common_x_ym_indices[x])\n",
    "print feature_index_map.shape\n",
    "feature_index_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(X.columns) - set(FEATURES_NAMES) - set(TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supp_data_df = X.loc[common_x_features_str.index, ['ncodpers', 'fecha_alta', 'fecha_dato'] + FEATURES_NAMES].copy()\n",
    "supp_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supp_data_df.loc[:, 'fecha_dato'] = X_ym['fecha_dato'].unique()[0]\n",
    "supp_data_df.loc[:, 'antiguedad'] -= delta_months\n",
    "supp_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "for t in TARGET_LABELS:\n",
    "    supp_data_df[t] = 0\n",
    "\n",
    "tic = time()\n",
    "for index, value in feature_index_map.iteritems():\n",
    "    targets = X_ym.loc[value, TARGET_LABELS].mean().apply(lambda x: int(np.ceil(x)))\n",
    "    supp_data_df.loc[index, TARGET_LABELS] = targets\n",
    "print time() - tic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# supp_data_df[supp_data_df['ncodpers']==1284468].head()\n",
    "supp_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ym_ = pd.concat([X_ym_, supp_data_df], ignore_index=True)\n",
    "X_ym_[X_ym_['ncodpers']==1284468]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(X_ym_['ncodpers'].value_counts() > 1).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "# def _match_replace_clients(ref_data, out_data):\n",
    "#     _X, _x_features_str = ref_data\n",
    "#     _X_ym_, _x_ym_features_str = out_data\n",
    "    \n",
    "#     _x_ym_features_str = _x_ym_features_str.drop_duplicates()\n",
    "    \n",
    "#     _X_sorted = _x_features_str.sort_values()\n",
    "#     _X_ym_sorted = _x_ym_features_str.sort_values()\n",
    "    \n",
    "#     print _X_sorted.shape, _X_ym_sorted.shape\n",
    "    \n",
    "#     tic = time()\n",
    "#     for index in _X_sorted.index:\n",
    "#         m = _X_ym_sorted.eq(_X_sorted[index])\n",
    "#         if m.any():\n",
    "#             _X_ym_sorted_m = _X_ym_sorted[m]\n",
    "#             # Choose randomly an index from matches and assign ncodpers to this line\n",
    "#             ll = len(_X_ym_sorted_m.index)\n",
    "#             ii = _X_ym_sorted_m.index[np.random.randint(ll)]\n",
    "#             logging.debug(\"Match found : %i <-> %i | Replace ncodpers : %i <-> %i\" % (index, _X_ym_sorted_m.index[0], _X_ym_.loc[ii, 'ncodpers'], _X.loc[index, 'ncodpers']))\n",
    "#             _X_ym_.loc[ii, 'ncodpers'] = _X.loc[index, 'ncodpers']\n",
    "\n",
    "#     print time() - tic\n",
    "    \n",
    "    \n",
    "def match_add_clients(ref_data, out_data):\n",
    "\n",
    "    _X, x_features_str = ref_data\n",
    "    _X_ym_, x_ym_features_str = out_data\n",
    "    \n",
    "    tic = time()\n",
    " \n",
    "    common_x_ym_features_str = x_ym_features_str[x_ym_features_str.isin(x_features_str)]\n",
    "    common_x_ym_features_str = common_x_ym_features_str.sort_values()\n",
    "    common_x_features_str = x_features_str[x_features_str.isin(common_x_ym_features_str)].sort_values()\n",
    "    gb = common_x_features_str.groupby(common_x_features_str)\n",
    "    gb_ym = common_x_ym_features_str.groupby(common_x_ym_features_str)\n",
    "    \n",
    "    common_x_ym_indices = gb_ym.apply(lambda x: x.index)\n",
    "    feature_index_map = gb.transform(lambda x: common_x_ym_indices[x])\n",
    "\n",
    "    supp_data_df = _X.loc[common_x_features_str.index, ['ncodpers', 'fecha_alta', 'fecha_dato'] + FEATURES_NAMES].copy()\n",
    "    supp_data_df.loc[:, 'fecha_dato'] = _X_ym_['fecha_dato'].unique()[0]\n",
    "    supp_data_df.loc[:, 'antiguedad'] -= delta_months\n",
    "\n",
    "    for t in TARGET_LABELS:\n",
    "        supp_data_df[t] = 0\n",
    "    \n",
    "    for index, value in feature_index_map.iteritems():\n",
    "        targets = _X_ym_.loc[value, TARGET_LABELS].mean().apply(lambda x: int(np.ceil(x)))\n",
    "        supp_data_df.loc[index, TARGET_LABELS] = targets\n",
    "    \n",
    "    _X_ym_ = pd.concat([_X_ym_, supp_data_df], ignore_index=True)\n",
    "    print time() - tic\n",
    "    \n",
    "    assert not (_X_ym_['ncodpers'].value_counts() > 1).any(), \"Something is wrong : {}\".format(_X_ym_['ncodpers'].value_counts() > 1)\n",
    "    return _X_ym_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i,f in enumerate(FEATURES_NAMES):\n",
    "    print i, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NP_FEATURES_NAMES = np.array(FEATURES_NAMES)\n",
    "NP_FEATURES_NAMES[[1, 2, 3, 6, 7, 8, 15]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NP_FEATURES_NAMES = np.array(FEATURES_NAMES)\n",
    "match_features_groups = [\n",
    "    FEATURES_NAMES,\n",
    "    NP_FEATURES_NAMES[[0, 1, 2, 3, 4, 5, 6, 7, 8, 15, 16, 17, 18]],  # [u'ind_empleado', u'pais_residencia', u'sexo', u'age',  u'ind_nuevo', u'antiguedad', u'indrel', u'ult_fec_cli_1t', u'indrel_1mes', u'nomprov', u'ind_actividad_cliente', u'renta', u'segmento']\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 4, 6, 7, 8, 15, 16, 17, 18]],  # [u'pais_residencia', u'sexo', u'age',  u'ind_nuevo', u'indrel', u'ult_fec_cli_1t', u'indrel_1mes', u'nomprov', u'ind_actividad_cliente', u'renta', u'segmento']\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 4, 6, 7, 8, 15, 16, 18]],  # [u'pais_residencia', u'sexo', u'age', u'ind_nuevo', u'indrel', uult_fec_cli_1t', u'indrel_1mes', u'nomprov', u'ind_actividad_cliente', u'segmento']\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 6, 7, 8, 15, 16, 18]],  # [u'pais_residencia', u'sexo', u'age', u'indrel', uult_fec_cli_1t', u'indrel_1mes', u'nomprov', u'ind_actividad_cliente', u'segmento']\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 6, 7, 8, 15]],  # [u'pais_residencia', u'sexo', u'age', u'indrel', u'ult_fec_cli_1t', u'indrel_1mes', u'nomprov']\n",
    "    ## Last try\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 6, 15]],  # [u'pais_residencia', u'sexo', u'age', u'indrel', u'nomprov', u'segmento']\n",
    "    NP_FEATURES_NAMES[[1, 2, 3, 15]],  # [u'pais_residencia', u'sexo', u'age', u'nomprov', u'segmento']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "X_ym_ = X_ym.copy()\n",
    "\n",
    "def update_seniority(row):\n",
    "    row['antiguedad'] -= delta_months\n",
    "    return row\n",
    "\n",
    "\n",
    "for fg in match_features_groups:\n",
    "    print \"- Compute missing clients : \"\n",
    "    clients = X_ym_['ncodpers'].unique()\n",
    "    common_clients = np.array(list(set(ref_clients) & set(clients)))\n",
    "    missing_clients = np.array(list(set(ref_clients) - set(clients)))\n",
    "    print common_clients.shape, missing_clients.shape\n",
    "    print \"- Feature group : \", fg\n",
    "    missing_clients_mask = X['ncodpers'].isin(missing_clients)\n",
    "    if TARGET_LABELS[5] in fg:\n",
    "        x_features_str = X[missing_clients_mask][fg].apply(update_seniority, axis=1).apply(features_to_str, axis=1)\n",
    "    else:\n",
    "        x_features_str = X[missing_clients_mask][fg].apply(features_to_str, axis=1)\n",
    "    x_ym_features_str = X_ym_[fg].apply(features_to_str, axis=1)\n",
    "    print \"- Match and add\"\n",
    "    X_ym_ = match_add_clients((X[missing_clients_mask], x_features_str), (X_ym_, x_ym_features_str))\n",
    "    \n",
    "    print X_ym_['ncodpers'].isin(missing_clients).sum(), X['ncodpers'].isin(missing_clients).sum()\n",
    "    if X_ym_['ncodpers'].isin(missing_clients).sum() == X['ncodpers'].isin(missing_clients).sum():\n",
    "        break\n",
    "        \n",
    "\n",
    "print \"Compute missing clients : \"\n",
    "clients = X_ym_['ncodpers'].unique()\n",
    "common_clients = np.array(list(set(ref_clients) & set(clients)))\n",
    "missing_clients = np.array(list(set(ref_clients) - set(clients)))\n",
    "print common_clients.shape, missing_clients.shape\n",
    "        \n",
    "# logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If remains missing clients, setup them with zero targets \n",
    "if missing_clients.shape[0] > 0:\n",
    "    print \"There are still missing clients\"\n",
    "    missing_clients_mask = X['ncodpers'].isin(missing_clients)\n",
    "    supp_data_df = X.loc[missing_clients_mask, ['ncodpers', 'fecha_alta', 'fecha_dato'] + FEATURES_NAMES].copy()\n",
    "    supp_data_df.loc[:, 'fecha_dato'] = X_ym_['fecha_dato'].unique()[0]\n",
    "    supp_data_df.loc[:, 'antiguedad'] -= delta_months\n",
    "\n",
    "    for t in TARGET_LABELS:\n",
    "        supp_data_df[t] = 0\n",
    "        \n",
    "    X_ym_ = pd.concat([X_ym_, supp_data_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Compute missing clients : \"\n",
    "clients = X_ym_['ncodpers'].unique()\n",
    "common_clients = np.array(list(set(ref_clients) & set(clients)))\n",
    "missing_clients = np.array(list(set(ref_clients) - set(clients)))\n",
    "print common_clients.shape, missing_clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train_df[['fecha_dato', 'ncodpers'] + TARGET_LABELS_FRQ.tolist()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_clients(df1, mask1, mask2, df2=None):\n",
    "    active_clients1 = df1[mask1]['ncodpers'].unique()\n",
    "    if df2 is not None:\n",
    "        active_clients2 = df2[mask2]['ncodpers'].unique()\n",
    "    else:\n",
    "        active_clients2 = df1[mask2]['ncodpers'].unique()\n",
    "    active_clients = list(set(active_clients1) & set(active_clients2)) \n",
    "    \n",
    "    if df2 is not None:\n",
    "        return df1['ncodpers'].isin(active_clients), df2['ncodpers'].isin(active_clients)\n",
    "    return df1['ncodpers'].isin(active_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "# months = list(set(train_df['fecha_dato'].unique()) | set(val_df['fecha_dato'].unique()))\n",
    "months = train_df['fecha_dato'].unique()\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "\n",
    "        \n",
    "train_months = train_df['fecha_dato'].unique()\n",
    "# val_months = val_df['fecha_dato'].unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_added_products, remove_last_choice, apk, map7_score\n",
    "from visualization import visualize_train_test, visualize_folds, compare_two_datasets, compare_folds, compare_folds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_features = ['targets_diff', 'targets_logdiff', 'targets_logcount2_diff', 'targets_logcount2', 'targets_logcount1', 'targets_logDec']\n",
    "TARGET_LABELS_FRQ_PREV = [c + '_prev' for c in TARGET_LABELS_FRQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(current_month, df1, next_year_month, df2, months_ym_map):\n",
    "    month_mask = df1['fecha_dato'] == months_ym_map[current_month]\n",
    "    next_year_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month]\n",
    "    next_year_prev_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month - 1]\n",
    "    \n",
    "    # get common clients from df1 at this month and df2 at next year month\n",
    "    common_clients_mask1, common_clients_mask2 = get_common_clients(df1, month_mask, next_year_month_mask, df2)\n",
    "    common_clients_mask2, common_clients_mask3 = get_common_clients(df2, common_clients_mask2 & next_year_month_mask, next_year_prev_month_mask, df2)\n",
    "        \n",
    "    c1 = df1[common_clients_mask1 & month_mask]['ncodpers'].values\n",
    "    c2 = df2[common_clients_mask2 & next_year_month_mask]['ncodpers'].values\n",
    "    c3 = df2[common_clients_mask3 & next_year_prev_month_mask]['ncodpers'].values\n",
    "    assert (c1 == c2).all() and (c2 == c3).all(), \"Problem with common clients\" \n",
    "    \n",
    "    X = df1[common_clients_mask1 & month_mask][['ncodpers', 'fecha_dato'] + target_features + features + TARGET_LABELS_FRQ.tolist()]            \n",
    "   \n",
    "    if TARGET_LABELS[0] in df2.columns and TARGET_LABELS_DIFF[0] in df2.columns and not df2[next_year_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        Y = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str', 'lc_targets_str', 'targets_diff'] + TARGET_LABELS + TARGET_LABELS_DIFF.tolist()]    \n",
    "        assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        Y.index = X.index                \n",
    "    else:\n",
    "        Y = None\n",
    "        \n",
    "    if TARGET_LABELS_FRQ[0] in df2.columns and not df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        # Add TARGET_LABELS_FRQ from previous month to X:\n",
    "        target_labels_frq = df2[common_clients_mask3 & next_year_prev_month_mask][['ncodpers'] + TARGET_LABELS_FRQ.tolist()]\n",
    "        assert (X['ncodpers'].values == target_labels_frq['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        target_labels_frq = target_labels_frq[TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.columns = TARGET_LABELS_FRQ_PREV\n",
    "        target_labels_frq.index = X.index\n",
    "        X = pd.concat([X, target_labels_frq], axis=1)        \n",
    "\n",
    "    \n",
    "    if LC_TARGET_LABELS[0] in df2.columns:\n",
    "        clients_last_choice = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str'] + LC_TARGET_LABELS.tolist()]\n",
    "    else:\n",
    "        clients_last_choice = None\n",
    "        \n",
    "    return X, Y, clients_last_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df if months_ym_map[current_month] in train_months else val_df\n",
    "#df1 = train_df\n",
    "df2 = train_df if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = train_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"WTF\"\n",
    "assert (X['ncodpers'].values == clients_last_choice['ncodpers'].values).all(), \"WTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print Y.shape\n",
    "Y[Y['targets_diff'] > 0][['fecha_dato', 'ncodpers', 'targets_str', 'lc_targets_str'] + TARGET_LABELS_DIFF.tolist() ].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clients_last_choice.shape\n",
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another train/predict + CV implementation\n",
    "\n",
    "### Input\n",
    "\n",
    "- `X` : `[nb_samples, nb_features]` shaped pd.DataFrame\n",
    "    - `features_masks_list` : `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "    \n",
    "- `Y` : `[nb_samples, nb_labels]` shaped pd.DataFrame\n",
    "    - `labels_masks_list` : `{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "\n",
    "- `samples_masks_list` : `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "\n",
    "\n",
    "- Set of models `models` : list of functions to create a model, e.g. `[create_RF, create_NN, create_GBT]`\n",
    "\n",
    "\n",
    "### Training phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Merge\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = Y['targets_diff'] > 0\n",
    "targets_index_counts = np.zeros((len(TARGET_LABELS)))\n",
    "for i, c in enumerate(TARGET_LABELS):\n",
    "    s = (Y[mask][c] > 0).sum()\n",
    "    targets_index_counts[i] = s\n",
    "\n",
    "targets_index_counts = pd.Series(targets_index_counts)\n",
    "targets_index_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_masks_list = [\n",
    "#     lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  (x['targets_diff'] > 0) | (y['targets_diff'] > 0), \n",
    "    lambda x, y:  (y['targets_diff'] > 0), \n",
    "]\n",
    "\n",
    "features_masks_dict = {\n",
    "    'fm_all': features + target_features + TARGET_LABELS_FRQ.tolist() + TARGET_LABELS_FRQ_PREV,\n",
    "#     'fm0': features + TARGET_LABELS_FRQ.tolist(),\n",
    "#     'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm1': TARGET_LABELS_FRQ_PREV,\n",
    "#     'fm2': target_features,\n",
    "#     'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "#     'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "#     'fm6': TARGET_LABELS_FRQ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "def create_RF(input_shape, output_shape):        \n",
    "    # https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "    return RandomForestClassifier(n_estimators=100, \n",
    "#                                   min_samples_split=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "#                                   oob_score=True,\n",
    "#                                   bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "                                 )\n",
    "\n",
    "def create_ET(input_shape, output_shape):\n",
    "    return ExtraTreesClassifier(n_estimators=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "                                  oob_score=True,\n",
    "                                  bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "\n",
    "                               )\n",
    "\n",
    "def create_GB(input_shape, output_shape):\n",
    "    return GradientBoostingClassifier(n_estimators=75)\n",
    "\n",
    "\n",
    "def create_NN0(input_shape, output_shape):\n",
    "        \n",
    "    assert len(input_shape) == 2, \"Input shape should be 2D\"\n",
    "    assert len(output_shape) == 2, \"Input shape should be 2D\"\n",
    "    n_features = input_shape[1]\n",
    "    output_dim = output_shape[1]\n",
    "    \n",
    "    def create_model(input_dim=n_features, output_dim=output_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(30, init='uniform', input_shape=(input_dim,), activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "#         model.add(Dense(output_dim, activation='sigmoid'))\n",
    "        model.add(Dense(output_dim, activation='softmax'))\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    return KerasClassifier(build_fn=create_model, nb_epoch=200, batch_size=2000, verbose=0)\n",
    "    \n",
    "\n",
    "models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "    'gb': create_GB,\n",
    "#     'nn0': create_NN0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print mask.sum()\n",
    "print targets_index_counts[targets_index_counts > 100].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NP_TARGET_LABELS = np.array(TARGET_LABELS)\n",
    "target_labels = NP_TARGET_LABELS\n",
    "\n",
    "common_groups = [\n",
    "    [2, 4, 7, 8, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23],\n",
    "#     [2, 4],    \n",
    "#     [2, 6, 7, 8],\n",
    "#     [2, 18, 23, 12], \n",
    "#     [21, 22],\n",
    "#     [2, 12, 18],\n",
    "#     [2, 12, 23],\n",
    "#     [2, 18, 23],\n",
    "#     [18, 23, 21, 22],\n",
    "#     [21, 23, 22, 4],\n",
    "#     [3, 4], \n",
    "#     [22, 7, 8, 23],\n",
    "#     [0, 1, 14, 15, 17]\n",
    "]\n",
    "\n",
    "common_groups += [[i] for i in [2, 4, 7, 8, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]]\n",
    "\n",
    "\n",
    "\n",
    "def flatten(array):\n",
    "    out = []\n",
    "    for item in array:\n",
    "        out += item\n",
    "    return out\n",
    "\n",
    "others = list(set(range(24)) - set(flatten(common_groups)))\n",
    "\n",
    "# for i, a in enumerate(zip(TARGET_LABELS2, TARGET_LABELS)):\n",
    "#     print i, a\n",
    "    \n",
    "s = set({})\n",
    "labels_masks_dict = {}\n",
    "for i, g in enumerate(common_groups):\n",
    "    print 'lm_%i' % i, \" <=> \", g, \"<==>\", TARGET_LABELS2[g]\n",
    "    labels_masks_dict['lm_%i' % i] = target_labels[g]\n",
    "    s |= set(g)\n",
    "    \n",
    "# print 'lm_others', \"<=>\", others, \"<==>\", TARGET_LABELS2[others]\n",
    "# labels_masks_dict['lm_others'] = target_labels[others]\n",
    "# s |= set(others)\n",
    "\n",
    "# assert len(s) == len(target_labels), \"Sum is not equal 24, s=%i\" % s\n",
    "print labels_masks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# {model_name: [(samples_mask_code, features_mask_name, labels_mask_name), ...]}\n",
    "models_pipelines = {\n",
    "    'gb' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) == 1],    \n",
    "    'rf' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "    'et' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "}\n",
    "models_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import train_all, predict_all, probas_to_indices, score_estimators\n",
    "from utils import map7_score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = 140000\n",
    "# ll = 1100\n",
    "\n",
    "mask = (X.index.isin((X.index[:ll//3]))) | (X.index.isin((X.index[2*ll//3:])))\n",
    "\n",
    "X1 = X[mask]\n",
    "Y1 = Y[mask]\n",
    "clc1 = clients_last_choice[mask]\n",
    "print X1.shape, Y1.shape, clc1.shape\n",
    "\n",
    "mask = X.index.isin(X.index[ll//3:2*ll//3])\n",
    "X2 = X[mask]\n",
    "Y2 = Y[mask]\n",
    "clc2 = clients_last_choice[mask]\n",
    "print X2.shape, Y2.shape, clc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = Y1[labels_masks_dict['lm_0']].apply(dummies_to_decimal, axis=1)\n",
    "# res = pd.get_dummies(res)\n",
    "# res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import dummies_to_decimal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def prepare_to_fit(X_train, Y_train):    \n",
    "    x_train = X_train.values\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    y_train = Y_train.apply(dummies_to_decimal, axis=1)\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_train = y_train.values    \n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def prepare_to_test(X_val, Y_val=None):\n",
    "    x_val = X_val.values\n",
    "    x_val = StandardScaler().fit_transform(x_val)\n",
    "    if Y_val is not None:\n",
    "        y_val = Y_val.apply(dummies_to_decimal, axis=1)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_val = y_val.values \n",
    "    else:\n",
    "        y_val = None\n",
    "    return x_val, y_val\n",
    "\n",
    "\n",
    "def probas_to_labels_probas(y_probas, class_indices, labels):\n",
    "    l = len(labels)\n",
    "    out = np.zeros((len(y_probas), l))\n",
    "    i = 0\n",
    "    for probas in y_probas:\n",
    "        if np.sum(probas) > 0:\n",
    "            pr = np.zeros((l,))\n",
    "            for index, p in zip(class_indices, probas):\n",
    "                dummies_str = decimal_to_dummies(index, l)\n",
    "                pr += p * np.array([float(v) for v in dummies_str])\n",
    "            out[i, :] = pr    \n",
    "        i += 1\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_kwargs = {\n",
    "    'samples_masks_list': samples_masks_list, \n",
    "    'features_masks_dict': features_masks_dict, \n",
    "    'labels_masks_dict': labels_masks_dict, \n",
    "    'models_dict': models_dict,\n",
    "    'labels': target_labels,\n",
    "    'transform_proba_func': probas_to_indices,\n",
    "#     'prepare_to_fit_func': prepare_to_fit,\n",
    "#     'prepare_to_test_func': prepare_to_test,   \n",
    "#     'probas_to_labels_probas_func': probas_to_labels_probas,\n",
    "    'threshold': 0.15,\n",
    "    'n_highest': 7,\n",
    "    'mode': 'sum',\n",
    "    'verbose': True,\n",
    "    'models_pipelines': models_pipelines,\n",
    "    'return_probas': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X1, Y1, **_kwargs)\n",
    "\n",
    "#print estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracies = defaultdict(list)\n",
    "for e in estimators:\n",
    "    accuracies[e[0][2]].append(e[2])\n",
    "\n",
    "mean_accuracy = {}\n",
    "for key in accuracies:\n",
    "    accuracy_list = accuracies[key]\n",
    "    mean_accuracy[key] = sum(accuracy_list)/len(accuracy_list)\n",
    "    \n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = score_estimators(estimators, X2, Y2, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "#print y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_preds[:5]\n",
    "Y_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_masks_dict['lm_0'], common_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val = targets_str_to_indices(Y2[target_labels].values)\n",
    "# y_val = targets_str_to_indices(Y2[labels_masks_dict['lm_0']].values, index_map=common_groups[0])\n",
    "#print y_val[:100]\n",
    "#print y_preds[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.unique(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"- Compute max map7 score\")\n",
    "map7_score(y_val, y_val, clc2[LC_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_val)\n",
    "logging.info(\"- Compute map7 score\")\n",
    "map7_score(y_val, y_preds, clc2[LC_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On columns lm_0=['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1','ind_ctju_fin_ult1']\n",
    "\n",
    "- Feature mask: all : 'fm6', 'fm4', 'fm5', 'fm2', 'fm3', 'fm0', 'fm1'\n",
    "- threshold = 0.0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "et | 0.007074370518592629 | 0.0075787893947 | lm_0 | all \n",
    "\n",
    "\n",
    "\n",
    "- Feature mask: fm0, fm1, fm3, fm4, fm5\n",
    "- threshold = 0.0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "rf + et + gb | 0.006920126730031681 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.0068805235951309 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.006936801734200433 | 0.0075787893947 | lm_0 | all \n",
    "gb | 0.0068805235951309 | 0.0075787893947 | lm_0 | all\n",
    "\n",
    "\n",
    "- Feature mask: fm0, fm1\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "rf + et + gb | 0.004627313656828414 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.004664832416208104 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.004952476238119059 | 0.0075787893947 | lm_0 | all \n",
    "gb | 0.004489744872436218 | 0.0075787893947 | lm_0 | all\n",
    "\n",
    "- Features mask: fm0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | --- | ---\n",
    "rf + et + gb | 0.0021010505252626313 | 0.0075787893947 | lm_0 | all\n",
    "rf + et | 0.001950975487743872 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.001550775387693847 | 0.0075787893947 | lm_0 | all\n",
    "gb | 0.0013006503251625813 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.0017008504252126063 | 0.0075787893947 | lm_0 | all\n",
    "et |  0.0014007003501750874 | 0.0075787893947 | lm_0 | x>0 or y>0\n",
    "rf |  0.0008254127063531766 | 0.0075787893947 | lm_0 | .\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "0.021295269099703414 (GB on 'all')\n",
    "\n",
    "0.021271936353906683 (RF tunning)\n",
    "\n",
    "0.021668245671284416 (RF tunning)\n",
    "\n",
    "0.02136609107928888\n",
    "\n",
    "0.0211362663776694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print labels_masks_dict[estimators[0][0][1]]\n",
    "# print estimators[0][1].classes_\n",
    "# print estimators[0][1].n_classes_\n",
    "# print estimators[0][1].n_features_\n",
    "# print estimators[0][1].n_outputs_\n",
    "# print estimators[0][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import targets_to_labels, targets_indices_to_labels, remove_last_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "limit = 25\n",
    "count = 0\n",
    "\n",
    "not_predicted_predicted = defaultdict(int)\n",
    "for last_choice, targets, products, proba in zip(clc2[LC_TARGET_LABELS].values, y_val, y_preds, Y_probas.values):\n",
    "    added_products = remove_last_choice(targets, last_choice)\n",
    "    predictions = remove_last_choice(products, last_choice)\n",
    "#     print \"---\", count, last_choice\n",
    "#     print targets, '->', added_products\n",
    "#     print products, '->', predictions\n",
    "#     if count == 3:\n",
    "#         break\n",
    "    \n",
    "    if len(added_products) == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(set(added_products) & set(predictions)) > 0:\n",
    "#         print \"Predicted : \", added_products, predictions\n",
    "#         print set(added_products) & set(predictions)\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    if count < limit:\n",
    "        print \"--- Count = \", count\n",
    "        print targets_indices_to_labels(added_products, TARGET_LABELS2)#, targets_indices_to_labels(targets, TARGET_LABELS2)\n",
    "        print targets_indices_to_labels(predictions, TARGET_LABELS2)#, targets_indices_to_labels(products, TARGET_LABELS2)#, proba\n",
    "    \n",
    "    for p in added_products:\n",
    "        not_predicted_predicted[TARGET_LABELS2[p]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print not_predicted_predicted, y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_probas[:10, target_groups[0]]\n",
    "#print Y[np.array(TARGET_LABELS)[target_groups[0]]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KFold Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import cross_val_score0, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unitary run\n",
    "nb_folds = 5\n",
    "results = cross_val_score((X, Y, clients_last_choice[LC_TARGET_LABELS].values), nb_folds=nb_folds, **_kwargs)\n",
    "\n",
    "print \"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), np.median(results), results.max(), results.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# CV on various combinations :\n",
    "\n",
    "_samples_masks_list = [\n",
    "    'all',\n",
    "#     lambda x, y:  ~(x['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  x['targets_diff'] > 0, \n",
    "#     lambda x, y:  x['targets_diff'] < 0, \n",
    "    lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0])), \n",
    "    lambda x, y:  (x['targets_diff'] > 0) | (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  (x['targets_diff'] < 0) | (y['targets_diff'] < 0), \n",
    "#     lambda x, y:  (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  y['targets_diff'] < 0, \n",
    "]\n",
    "\n",
    "_features_masks_dict = {\n",
    "    'fm0': features + target_features + TARGET_LABELS_FRQ.tolist() + TARGET_LABELS_FRQ_PREV,\n",
    "    'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "    'fm2': target_features,\n",
    "    'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "    'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "    'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "    'fm6': TARGET_LABELS_FRQ,\n",
    "}\n",
    "\n",
    "_models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "    'gb': create_GB,\n",
    "}\n",
    "\n",
    "_labels_masks_dict = {\n",
    "    'lm_0': labels_masks_dict['lm_0']\n",
    "}\n",
    "\n",
    "nb_folds = 5\n",
    "\n",
    "def BruteForceSearchCV():\n",
    "    \n",
    "    def get_models_combinations(items):\n",
    "        combins = list(combinations(items, 1))\n",
    "        combins += list(combinations(items, len(items)))\n",
    "        return combins\n",
    "    \n",
    "    def get_combinations(items):\n",
    "        combins = list(combinations(items, 1))\n",
    "        for i in range(2, len(items)+1):\n",
    "            combins += list(combinations(items, i))\n",
    "        return combins\n",
    "    \n",
    "    def get_items(items):\n",
    "        out = [[items[0],], ]\n",
    "        for i in items[1:]:\n",
    "            tmp = list(out[-1])\n",
    "            tmp.append(i)\n",
    "            out.append(tmp)        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    _labels_masks_combinations = get_items(sorted(_labels_masks_dict.keys()))\n",
    "    _features_masks_combinations = get_items(sorted(_features_masks_dict.keys()))\n",
    "    _models_combinations = get_models_combinations(_models_dict.keys())\n",
    "\n",
    "    # Very big loop:\n",
    "    for lm_keys in _labels_masks_combinations:\n",
    "        __labels_masks_dict = {}\n",
    "        for lm_key in lm_keys:\n",
    "            __labels_masks_dict[lm_key] = _labels_masks_dict[lm_key]\n",
    "\n",
    "        for i, sm in enumerate(_samples_masks_list):\n",
    "            __samples_masks_list = [sm]\n",
    "              \n",
    "            for fm_keys in _features_masks_combinations:\n",
    "                __features_masks_dict = {}\n",
    "                for fm_key in fm_keys:\n",
    "                    __features_masks_dict[fm_key] = _features_masks_dict[fm_key]\n",
    "                    \n",
    "                for m_keys in _models_combinations:\n",
    "                    __models_dict = {}\n",
    "                    for m_key in m_keys:\n",
    "                        __models_dict[m_key] = _models_dict[m_key]\n",
    "                    \n",
    "                    print \"\\n\\n---------------------------------------------------------------\" \n",
    "                    print \"--- PROCESS : \", __labels_masks_dict.keys(), i, __features_masks_dict.keys(), __models_dict.keys()\n",
    "                    print \"---------------------------------------------------------------\\n\" \n",
    "                    \n",
    "                    __kwargs = {\n",
    "                        'samples_masks_list': __samples_masks_list, \n",
    "                        'features_masks_dict': __features_masks_dict, \n",
    "                        'labels_masks_dict': __labels_masks_dict, \n",
    "                        'models_dict': __models_dict,\n",
    "                        'labels': target_labels,\n",
    "                        'transform_proba_func': probas_to_indices,\n",
    "                        'prepare_to_fit_func': prepare_to_fit,\n",
    "                        'prepare_to_test_func': prepare_to_test,   \n",
    "                        'probas_to_labels_probas_func': probas_to_labels_probas,\n",
    "                        'threshold': 0.0,\n",
    "                        'n_highest': 7,\n",
    "                        'mode': 'sum',\n",
    "                        'verbose': False,\n",
    "                        'return_probas': True\n",
    "                    }\n",
    "                    #  DEBUG : results = cross_val_score((X1, Y1, clc1[LC_TARGET_LABELS].values), nb_folds=nb_folds, **__kwargs)\n",
    "                    results = cross_val_score((X, Y, clients_last_choice[LC_TARGET_LABELS].values), nb_folds=nb_folds, **__kwargs)\n",
    "                    print \"=> CV : \", results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "BruteForceSearchCV()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 201505 -> 201605 \n",
    "\n",
    "Cross-Validation \n",
    " 5 | 0.014585 | 0.018385 | 0.019147 | 0.022227 | 0.00294 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cross-validation across several months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_folds = 3\n",
    "yms = [201504, 201505]\n",
    "#yms = [201505]\n",
    "\n",
    "for ym in yms:\n",
    "    logging.info(\"\\n-------------------------\")\n",
    "    logging.info(\"- Process month : %s\" % ym)\n",
    "    logging.info(\"-------------------------\\n\")\n",
    "    \n",
    "    ym1 = ym + 100    \n",
    "    df1 = train_df if months_ym_map[ym] in train_months else val_df\n",
    "    df2 = train_df if months_ym_map[ym1] in train_months else val_df\n",
    "    X, Y, clients_last_choice = get_XY(ym, df1, ym1, df2) \n",
    "    results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                                profiles=profiles,\n",
    "                                nb_folds=nb_folds)\n",
    "    print \"Cross-Validation \\n %i | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), results.max(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df\n",
    "#df1 = val_df\n",
    "df2 = train_df #if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = val_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X, Y, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check score on the data 2016/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"- Compute map7 score\")\n",
    "print map7_score(y_val, y_preds, clients_last_choice[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "print map7_score(y_val, y_val, clients_last_choice[LC_TARGET_LABELS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for 2016/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df, test_df = load_train_test([201506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "months = list(set(full_train_df['fecha_dato'].unique()) | set(test_df['fecha_dato'].unique()))\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "    \n",
    "full_train_months = full_train_df['fecha_dato'].unique()\n",
    "test_months = test_df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201506\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = full_train_df\n",
    "df2 = test_df\n",
    "X, _, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(predicted_added_products, clients, clc, target_labels):\n",
    "    added_products_col = []\n",
    "    count = 0 \n",
    "    for products, last_choice in zip(predicted_added_products, clc):\n",
    "        predictions = remove_last_choice(products, last_choice)\n",
    "        added_products_col.append(' '.join([target_labels[i] for i in predictions]))\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            logging.info(\"Elapsed : %i\", count)\n",
    "            \n",
    "    out = pd.DataFrame(data={'ncodpers': clients, 'added_products': added_products_col}, columns=['ncodpers', 'added_products'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)\n",
    "\n",
    "logging.info(\"- Get submission dataframe:\")\n",
    "clients = X['ncodpers'].values\n",
    "#submission = get_submission(y_preds, clients, clients_last_choice[LC_TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = get_submission(y_preds, clients, clients_last_choice[LC_TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_estimators = []\n",
    "for e in estimators:\n",
    "    # estimators = [([features_mask_name, labels_mask_name, model_name], estimator_object, accuracy), ...]\n",
    "    features_mask_name, labels_mask_name, model_name = e[0]\n",
    "#     print features_mask_name, labels_mask_name, model_name\n",
    "    if set(features_masks_dict[features_mask_name]).issubset(test_df.columns):\n",
    "#         print \"Append the estimator\"\n",
    "        selected_estimators.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_clients = set(submission['ncodpers'].unique())\n",
    "test_clients = set(test_df['ncodpers'].unique())\n",
    "if submission_clients != test_clients:\n",
    "    missing_clients = list(test_clients - submission_clients)\n",
    "    missing_clients_mask = test_df['ncodpers'].isin(missing_clients)\n",
    "    \n",
    "    X1 = test_df[missing_clients_mask]\n",
    "        \n",
    "    y_preds, Y_probas = predict_all(selected_estimators, X1, **_kwargs)    \n",
    "    submission2 = get_submission(y_preds, missing_clients, X1[LC_TARGET_LABELS].values, TARGET_LABELS)\n",
    "    \n",
    "#     submission = pd.concat([submission, submission2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2 = get_submission(y_preds, missing_clients, X1[LC_TARGET_LABELS].values, TARGET_LABELS)\n",
    "#submission = pd.concat([submission, submission2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submission2.shape\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission DataFrame and write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "\n",
    "submission.to_csv(submission_file, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/submission_2016-11-17-16-37.csv', 'r') as r:\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
