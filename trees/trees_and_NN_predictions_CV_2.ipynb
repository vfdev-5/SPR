{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees and NN tryouts on SPR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from dataset2 import load_trainval\n",
    "from dataset2 import FEATURES_NAMES, TARGET_GROUP_DEC_LABELS, TARGET_LABELS_FRQ, ADDED_TARGET_LABELS, LAST_TARGET_LABELS\n",
    "from dataset2 import PROCESSED_TARGETS, TARGET_GROUPS_DEC, TARGET_GROUPS, DIFF_TARGETS\n",
    "from utils import to_yearmonth, TARGET_LABELS, TARGET_LABELS2\n",
    "from utils import target_str_to_labels, decimal_to_dummies, targets_str_to_indices, targets_dec_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load file : ../data/train_ver2.csv, yearmonth=201605, n_clients=250000\n",
      "INFO:root:-- Select 250000 clients\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:- Add a supplementary data : 201603\n",
      "INFO:root:-- Select max clients\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:-- Compute missing clients : 1216/250000\n",
      "INFO:root:--- Setup them with zero targets\n",
      "INFO:root:- Add a supplementary data : 201601\n",
      "INFO:root:-- Select max clients\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:-- Compute missing clients : 4288/250000\n",
      "INFO:root:--- Setup them with zero targets\n",
      "INFO:root:- Add a supplementary data : 201505\n",
      "INFO:root:-- Select max clients\n",
      "INFO:root:- Number of lines with unknown data : 3597\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:-- Compute missing clients : 82539/250000\n",
      "INFO:root:--- Setup them with zero targets\n",
      "INFO:root:Store computed data as file : ../data/generated/trainval_201605__250000.csv\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_trainval(201605, 250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 157) (250000, 76)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fecha_alta', 'fecha_dato', 'ncodpers'}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X.columns) - \\\n",
    "set(FEATURES_NAMES + \n",
    "    PROCESSED_TARGETS(1) + \n",
    "    PROCESSED_TARGETS(2) + \n",
    "    PROCESSED_TARGETS(3) + \n",
    "    PROCESSED_TARGETS(4) + \n",
    "    DIFF_TARGETS(1, 2) + \n",
    "    DIFF_TARGETS(1, 3) + \n",
    "    DIFF_TARGETS(1, 4) \n",
    "   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'added_targets_dec', 'added_targets_str', 'last_targets_str', 'targets_str'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(Y.columns) - set(TARGET_LABELS + LAST_TARGET_LABELS.tolist() + ADDED_TARGET_LABELS.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().any().all(), Y.isnull().any().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diff_targets_dec_12',\n",
       " 'diff_targets_dec_g0_12',\n",
       " 'diff_targets_dec_g1_12',\n",
       " 'diff_targets_dec_g2_12',\n",
       " 'diff_targets_dec_g3_12']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIFF_TARGETS(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 2, 4, 5])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['added_targets_dec'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ind_empleado',\n",
       " u'pais_residencia',\n",
       " u'sexo',\n",
       " u'age',\n",
       " u'ind_nuevo',\n",
       " u'antiguedad',\n",
       " u'indrel',\n",
       " u'ult_fec_cli_1t',\n",
       " u'indrel_1mes',\n",
       " u'tiprel_1mes',\n",
       " u'indresi',\n",
       " u'indext',\n",
       " u'conyuemp',\n",
       " u'canal_entrada',\n",
       " u'indfall',\n",
       " u'nomprov',\n",
       " u'ind_actividad_cliente',\n",
       " u'renta',\n",
       " u'segmento']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FEATURES_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>targets_str_1</th>\n",
       "      <th>targets_str_2</th>\n",
       "      <th>diff_targets_dec_12</th>\n",
       "      <th>targets_logdec_1</th>\n",
       "      <th>targets_logdec_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310484</th>\n",
       "      <td>15893</td>\n",
       "      <td>000000000000000000010000</td>\n",
       "      <td>000000000000000000010000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>2.833213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310472</th>\n",
       "      <td>15907</td>\n",
       "      <td>001000010000010101110001</td>\n",
       "      <td>001000010000010101110001</td>\n",
       "      <td>0</td>\n",
       "      <td>14.587507</td>\n",
       "      <td>14.587507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310468</th>\n",
       "      <td>15913</td>\n",
       "      <td>001000000000000100110001</td>\n",
       "      <td>001000000000000100110001</td>\n",
       "      <td>0</td>\n",
       "      <td>14.556237</td>\n",
       "      <td>14.556237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310466</th>\n",
       "      <td>15915</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310516</th>\n",
       "      <td>15922</td>\n",
       "      <td>001000010000000000001001</td>\n",
       "      <td>001000010000000000001001</td>\n",
       "      <td>0</td>\n",
       "      <td>14.586867</td>\n",
       "      <td>14.586867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310513</th>\n",
       "      <td>15925</td>\n",
       "      <td>001000010000000000100001</td>\n",
       "      <td>001000010000000000100000</td>\n",
       "      <td>1</td>\n",
       "      <td>14.586878</td>\n",
       "      <td>14.586878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310511</th>\n",
       "      <td>15927</td>\n",
       "      <td>001000001000000100000001</td>\n",
       "      <td>001000001000000100000001</td>\n",
       "      <td>0</td>\n",
       "      <td>14.571716</td>\n",
       "      <td>14.571716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310508</th>\n",
       "      <td>15930</td>\n",
       "      <td>001000000000010100010000</td>\n",
       "      <td>001000000000010100010000</td>\n",
       "      <td>0</td>\n",
       "      <td>14.556709</td>\n",
       "      <td>14.556709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310503</th>\n",
       "      <td>15936</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>000000000000000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310498</th>\n",
       "      <td>15941</td>\n",
       "      <td>000000010000000000000000</td>\n",
       "      <td>000000010000000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.090370</td>\n",
       "      <td>11.090370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ncodpers             targets_str_1             targets_str_2  \\\n",
       "310484     15893  000000000000000000010000  000000000000000000010000   \n",
       "310472     15907  001000010000010101110001  001000010000010101110001   \n",
       "310468     15913  001000000000000100110001  001000000000000100110001   \n",
       "310466     15915  000000000000000000000000  000000000000000000000000   \n",
       "310516     15922  001000010000000000001001  001000010000000000001001   \n",
       "310513     15925  001000010000000000100001  001000010000000000100000   \n",
       "310511     15927  001000001000000100000001  001000001000000100000001   \n",
       "310508     15930  001000000000010100010000  001000000000010100010000   \n",
       "310503     15936  000000000000000000000000  000000000000000000000000   \n",
       "310498     15941  000000010000000000000000  000000010000000000000000   \n",
       "\n",
       "        diff_targets_dec_12  targets_logdec_1  targets_logdec_2  \n",
       "310484                    0          2.833213          2.833213  \n",
       "310472                    0         14.587507         14.587507  \n",
       "310468                    0         14.556237         14.556237  \n",
       "310466                    0          0.000000          0.000000  \n",
       "310516                    0         14.586867         14.586867  \n",
       "310513                    1         14.586878         14.586878  \n",
       "310511                    0         14.571716         14.571716  \n",
       "310508                    0         14.556709         14.556709  \n",
       "310503                    0          0.000000          0.000000  \n",
       "310498                    0         11.090370         11.090370  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['ncodpers', 'targets_str_1', 'targets_str_2', 'diff_targets_dec_12', 'targets_logdec_1', 'targets_logdec_2']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_str_1</th>\n",
       "      <th>targets_str_2</th>\n",
       "      <th>targets_str_3</th>\n",
       "      <th>targets_str_4</th>\n",
       "      <th>diff_targets_dec_12</th>\n",
       "      <th>diff_targets_dec_g0_12</th>\n",
       "      <th>diff_targets_dec_g1_12</th>\n",
       "      <th>diff_targets_dec_g2_12</th>\n",
       "      <th>diff_targets_dec_g3_12</th>\n",
       "      <th>diff_targets_dec_13</th>\n",
       "      <th>diff_targets_dec_g0_13</th>\n",
       "      <th>diff_targets_dec_g1_13</th>\n",
       "      <th>diff_targets_dec_g2_13</th>\n",
       "      <th>diff_targets_dec_g3_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310460</th>\n",
       "      <td>15952</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000000000001000000</td>\n",
       "      <td>001000000000000001000001</td>\n",
       "      <td>001000000001000001000001</td>\n",
       "      <td>001000000001000001000001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-4097</td>\n",
       "      <td>-1</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310551</th>\n",
       "      <td>16201</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001010000000101001000001</td>\n",
       "      <td>001010000000101001000111</td>\n",
       "      <td>001010000000101001000001</td>\n",
       "      <td>001010000000101001100001</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310212</th>\n",
       "      <td>16506</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010000000001001000001</td>\n",
       "      <td>000010000000001001000111</td>\n",
       "      <td>000010000000001001000111</td>\n",
       "      <td>000010000000001001000111</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310368</th>\n",
       "      <td>16525</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001010000000110100100111</td>\n",
       "      <td>001010000000110100100111</td>\n",
       "      <td>001010001000110100100111</td>\n",
       "      <td>001010000000110100100111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-32768</td>\n",
       "      <td>0</td>\n",
       "      <td>-16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311082</th>\n",
       "      <td>16988</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010001000000001000011</td>\n",
       "      <td>000010001000000001100011</td>\n",
       "      <td>000010001000000001000001</td>\n",
       "      <td>000010001000010001000001</td>\n",
       "      <td>-32</td>\n",
       "      <td>-8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310986</th>\n",
       "      <td>17059</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>001000000000000000000001</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311010</th>\n",
       "      <td>17118</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010000000100001000000</td>\n",
       "      <td>000010000000100001000110</td>\n",
       "      <td>000010000000110001010000</td>\n",
       "      <td>000010000000110000010000</td>\n",
       "      <td>-6</td>\n",
       "      <td>-6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1040</td>\n",
       "      <td>0</td>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310726</th>\n",
       "      <td>17230</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010000010000000000</td>\n",
       "      <td>001000010000010000000000</td>\n",
       "      <td>001000010000010000000000</td>\n",
       "      <td>001000010000010000000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310686</th>\n",
       "      <td>17299</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000001001100001110001</td>\n",
       "      <td>001000001001100001110001</td>\n",
       "      <td>001000001001100001010001</td>\n",
       "      <td>001000001001100001010001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310744</th>\n",
       "      <td>17345</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>001000000000000000000001</td>\n",
       "      <td>001000000000000000000001</td>\n",
       "      <td>001000000000000000000001</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ncodpers  fecha_dato             targets_str_1  \\\n",
       "310460     15952  2016-05-28  001000000000000001000000   \n",
       "310551     16201  2016-05-28  001010000000101001000001   \n",
       "310212     16506  2016-05-28  000010000000001001000001   \n",
       "310368     16525  2016-05-28  001010000000110100100111   \n",
       "311082     16988  2016-05-28  000010001000000001000011   \n",
       "310986     17059  2016-05-28  001000000000000000000000   \n",
       "311010     17118  2016-05-28  000010000000100001000000   \n",
       "310726     17230  2016-05-28  001000010000010000000000   \n",
       "310686     17299  2016-05-28  001000001001100001110001   \n",
       "310744     17345  2016-05-28  001000000000000000000000   \n",
       "\n",
       "                   targets_str_2             targets_str_3  \\\n",
       "310460  001000000000000001000001  001000000001000001000001   \n",
       "310551  001010000000101001000111  001010000000101001000001   \n",
       "310212  000010000000001001000111  000010000000001001000111   \n",
       "310368  001010000000110100100111  001010001000110100100111   \n",
       "311082  000010001000000001100011  000010001000000001000001   \n",
       "310986  001000000000000000000000  001000000000000000000001   \n",
       "311010  000010000000100001000110  000010000000110001010000   \n",
       "310726  001000010000010000000000  001000010000010000000000   \n",
       "310686  001000001001100001110001  001000001001100001010001   \n",
       "310744  001000000000000000000001  001000000000000000000001   \n",
       "\n",
       "                   targets_str_4  diff_targets_dec_12  diff_targets_dec_g0_12  \\\n",
       "310460  001000000001000001000001                   -1                      -1   \n",
       "310551  001010000000101001100001                   -6                      -6   \n",
       "310212  000010000000001001000111                   -6                      -6   \n",
       "310368  001010000000110100100111                    0                       0   \n",
       "311082  000010001000010001000001                  -32                      -8   \n",
       "310986  001000000000000000000000                    0                       0   \n",
       "311010  000010000000110000010000                   -6                      -6   \n",
       "310726  001000010000010000000000                    0                       0   \n",
       "310686  001000001001100001010001                    0                       0   \n",
       "310744  001000000000000000000001                   -1                      -1   \n",
       "\n",
       "        diff_targets_dec_g1_12  diff_targets_dec_g2_12  \\\n",
       "310460                       0                       0   \n",
       "310551                       0                       0   \n",
       "310212                       0                       0   \n",
       "310368                       0                       0   \n",
       "311082                       0                       0   \n",
       "310986                       0                       0   \n",
       "311010                       0                       0   \n",
       "310726                       0                       0   \n",
       "310686                       0                       0   \n",
       "310744                       0                       0   \n",
       "\n",
       "        diff_targets_dec_g3_12  diff_targets_dec_13  diff_targets_dec_g0_13  \\\n",
       "310460                       0                -4097                      -1   \n",
       "310551                       0                    0                       0   \n",
       "310212                       0                   -6                      -6   \n",
       "310368                       0               -32768                       0   \n",
       "311082                       0                    2                       2   \n",
       "310986                       0                   -1                      -1   \n",
       "311010                       0                -1040                       0   \n",
       "310726                       0                    0                       0   \n",
       "310686                       0                   32                       8   \n",
       "310744                       0                   -1                      -1   \n",
       "\n",
       "        diff_targets_dec_g1_13  diff_targets_dec_g2_13  diff_targets_dec_g3_13  \n",
       "310460                      -8                       0                       0  \n",
       "310551                       0                       0                       0  \n",
       "310212                       0                       0                       0  \n",
       "310368                     -16                       0                       0  \n",
       "311082                       0                       0                       0  \n",
       "310986                       0                       0                       0  \n",
       "311010                      -5                       0                       0  \n",
       "310726                       0                       0                       0  \n",
       "310686                       0                       0                       0  \n",
       "310744                       0                       0                       0  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = Y['added_targets_dec'] > 0\n",
    "X[mask][['ncodpers', 'fecha_dato', 'targets_str_1', 'targets_str_2', 'targets_str_3', 'targets_str_4'] + DIFF_TARGETS(1, 2) + DIFF_TARGETS(1, 3)].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>diff_targets_dec_12</th>\n",
       "      <th>diff_targets_dec_g0_12</th>\n",
       "      <th>diff_targets_dec_g0_13</th>\n",
       "      <th>diff_targets_dec_g0_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>309475</th>\n",
       "      <td>18233</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313346</th>\n",
       "      <td>41308</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294756</th>\n",
       "      <td>49016</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301572</th>\n",
       "      <td>73875</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259149</th>\n",
       "      <td>148514</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255115</th>\n",
       "      <td>154814</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238643</th>\n",
       "      <td>165568</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ncodpers  fecha_dato  diff_targets_dec_12  diff_targets_dec_g0_12  \\\n",
       "309475     18233  2016-05-28                    0                       0   \n",
       "313346     41308  2016-05-28                    0                       0   \n",
       "294756     49016  2016-05-28                    0                       0   \n",
       "301572     73875  2016-05-28                    0                       0   \n",
       "259149    148514  2016-05-28                    0                       0   \n",
       "255115    154814  2016-05-28                    0                       0   \n",
       "238643    165568  2016-05-28                    0                       0   \n",
       "\n",
       "        diff_targets_dec_g0_13  diff_targets_dec_g0_14  \n",
       "309475                       0                       0  \n",
       "313346                       0                       0  \n",
       "294756                       0                       0  \n",
       "301572                       0                       0  \n",
       "259149                       0                       0  \n",
       "255115                       0                       0  \n",
       "238643                       0                       0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['ncodpers', 'fecha_dato', 'diff_targets_dec_12', 'diff_targets_dec_g0_12', 'diff_targets_dec_g0_13', 'diff_targets_dec_g0_14']].head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_added_products, remove_last_choice, apk, map7_score\n",
    "from visualization import visualize_train_test, visualize_folds, compare_two_datasets, compare_folds, compare_folds2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another train/predict + CV implementation\n",
    "\n",
    "### Input\n",
    "\n",
    "- `X` : `[nb_samples, nb_features]` shaped pd.DataFrame\n",
    "    - `features_masks_list` : `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "    \n",
    "- `Y` : `[nb_samples, nb_labels]` shaped pd.DataFrame\n",
    "    - `labels_masks_list` : `{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "\n",
    "- `samples_masks_list` : `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "\n",
    "\n",
    "- Set of models `models` : list of functions to create a model, e.g. `[create_RF, create_NN, create_GBT]`\n",
    "\n",
    "\n",
    "### Training phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Merge\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1455fbc4d0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg0AAAFoCAYAAADUycjgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRQwNkiSpyH8DbLQnWaGtjREAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1455aa85d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mask = Y['added_targets_dec'] > 0\n",
    "targets_index_counts = np.zeros((len(TARGET_LABELS)))\n",
    "for i, c in enumerate(TARGET_LABELS):\n",
    "    s = (Y[mask][c] > 0).sum()\n",
    "    targets_index_counts[i] = s\n",
    "\n",
    "targets_index_counts = pd.Series(targets_index_counts)\n",
    "targets_index_counts.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'ncodpers', u'fecha_dato', u'fecha_alta', u'ind_empleado',\n",
       "       u'pais_residencia', u'sexo', u'age', u'ind_nuevo', u'antiguedad',\n",
       "       u'indrel',\n",
       "       ...\n",
       "       u'diff_targets_dec_13', u'diff_targets_dec_g0_13',\n",
       "       u'diff_targets_dec_g1_13', u'diff_targets_dec_g2_13',\n",
       "       u'diff_targets_dec_g3_13', u'diff_targets_dec_14',\n",
       "       u'diff_targets_dec_g0_14', u'diff_targets_dec_g1_14',\n",
       "       u'diff_targets_dec_g2_14', u'diff_targets_dec_g3_14'],\n",
       "      dtype='object', length=157)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_masks_list = [\n",
    "#     lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  (x['targets_diff'] > 0) | (y['targets_diff'] > 0), \n",
    "    lambda x, y:  (y['added_targets_dec'] > 0), \n",
    "]\n",
    "\n",
    "features_masks_dict = {\n",
    "    'fm_all': FEATURES_NAMES + FEATURES_NAMES + \n",
    "                PROCESSED_TARGETS(1) + \n",
    "                PROCESSED_TARGETS(2) + \n",
    "                PROCESSED_TARGETS(3) + \n",
    "                PROCESSED_TARGETS(4) + \n",
    "                DIFF_TARGETS(1, 2) + \n",
    "                DIFF_TARGETS(1, 3) + \n",
    "                DIFF_TARGETS(1, 4),\n",
    "#     'fm0': features + TARGET_LABELS_FRQ.tolist(),\n",
    "#     'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm1': TARGET_LABELS_FRQ_PREV,\n",
    "#     'fm2': target_features,\n",
    "#     'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "#     'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "#     'fm6': TARGET_LABELS_FRQ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "def create_RF(input_shape, output_shape):        \n",
    "    # https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "    return RandomForestClassifier(n_estimators=100, \n",
    "#                                   min_samples_split=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "#                                   oob_score=True,\n",
    "#                                   bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "                                 )\n",
    "\n",
    "def create_ET(input_shape, output_shape):\n",
    "    return ExtraTreesClassifier(n_estimators=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "                                  oob_score=True,\n",
    "                                  bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "\n",
    "                               )\n",
    "\n",
    "def create_GB(input_shape, output_shape):\n",
    "    return GradientBoostingClassifier(n_estimators=75)\n",
    "\n",
    "\n",
    "def create_NN0(input_shape, output_shape):\n",
    "        \n",
    "    assert len(input_shape) == 2, \"Input shape should be 2D\"\n",
    "    assert len(output_shape) == 2, \"Input shape should be 2D\"\n",
    "    n_features = input_shape[1]\n",
    "    output_dim = output_shape[1]\n",
    "    \n",
    "    def create_model(input_dim=n_features, output_dim=output_dim):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(30, init='uniform', input_shape=(input_dim,), activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "#         model.add(Dense(output_dim, activation='sigmoid'))\n",
    "        model.add(Dense(output_dim, activation='softmax'))\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    return KerasClassifier(build_fn=create_model, nb_epoch=200, batch_size=2000, verbose=0)\n",
    "    \n",
    "\n",
    "models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "    'gb': create_GB,\n",
    "#     'nn0': create_NN0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_0  <=>  [2, 4, 7, 8, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23] <==> ['Current Accounts' 'Payroll Account' 'particular Account'\n",
      " 'particular Plus Account' 'Long-term deposits' 'e-account' 'Funds'\n",
      " 'Pensions (plan fin)' 'Taxes' 'Credit Card' 'Securities' 'Payroll'\n",
      " 'Pensions' 'Direct Debit']\n",
      "lm_1  <=>  [2] <==> ['Current Accounts']\n",
      "lm_2  <=>  [4] <==> ['Payroll Account']\n",
      "lm_3  <=>  [7] <==> ['particular Account']\n",
      "lm_4  <=>  [8] <==> ['particular Plus Account']\n",
      "lm_5  <=>  [11] <==> ['Long-term deposits']\n",
      "lm_6  <=>  [12] <==> ['e-account']\n",
      "lm_7  <=>  [13] <==> ['Funds']\n",
      "lm_8  <=>  [15] <==> ['Pensions (plan fin)']\n",
      "lm_9  <=>  [17] <==> ['Taxes']\n",
      "lm_10  <=>  [18] <==> ['Credit Card']\n",
      "lm_11  <=>  [19] <==> ['Securities']\n",
      "lm_12  <=>  [21] <==> ['Payroll']\n",
      "lm_13  <=>  [22] <==> ['Pensions']\n",
      "lm_14  <=>  [23] <==> ['Direct Debit']\n",
      "{'lm_12': array(['ind_nomina_ult1'], \n",
      "      dtype='|S17'), 'lm_13': array(['ind_nom_pens_ult1'], \n",
      "      dtype='|S17'), 'lm_10': array(['ind_tjcr_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_11': array(['ind_valo_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_14': array(['ind_recibo_ult1'], \n",
      "      dtype='|S17'), 'lm_8': array(['ind_plan_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_9': array(['ind_reca_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_0': array(['ind_cco_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctop_fin_ult1',\n",
      "       'ind_ctpp_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1',\n",
      "       'ind_fond_fin_ult1', 'ind_plan_fin_ult1', 'ind_reca_fin_ult1',\n",
      "       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_nomina_ult1',\n",
      "       'ind_nom_pens_ult1', 'ind_recibo_ult1'], \n",
      "      dtype='|S17'), 'lm_1': array(['ind_cco_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_2': array(['ind_cno_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_3': array(['ind_ctop_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_4': array(['ind_ctpp_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_5': array(['ind_dela_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_6': array(['ind_ecue_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_7': array(['ind_fond_fin_ult1'], \n",
      "      dtype='|S17')}\n"
     ]
    }
   ],
   "source": [
    "NP_TARGET_LABELS = np.array(TARGET_LABELS)\n",
    "target_labels = NP_TARGET_LABELS\n",
    "\n",
    "common_groups = [\n",
    "    [2, 4, 7, 8, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23],\n",
    "#     [2, 4],    \n",
    "#     [2, 6, 7, 8],\n",
    "#     [2, 18, 23, 12], \n",
    "#     [21, 22],\n",
    "#     [2, 12, 18],\n",
    "#     [2, 12, 23],\n",
    "#     [2, 18, 23],\n",
    "#     [18, 23, 21, 22],\n",
    "#     [21, 23, 22, 4],\n",
    "#     [3, 4], \n",
    "#     [22, 7, 8, 23],\n",
    "#     [0, 1, 14, 15, 17]\n",
    "]\n",
    "\n",
    "common_groups += [[i] for i in [2, 4, 7, 8, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23]]\n",
    "\n",
    "\n",
    "\n",
    "def flatten(array):\n",
    "    out = []\n",
    "    for item in array:\n",
    "        out += item\n",
    "    return out\n",
    "\n",
    "others = list(set(range(24)) - set(flatten(common_groups)))\n",
    "\n",
    "# for i, a in enumerate(zip(TARGET_LABELS2, TARGET_LABELS)):\n",
    "#     print i, a\n",
    "    \n",
    "s = set({})\n",
    "labels_masks_dict = {}\n",
    "for i, g in enumerate(common_groups):\n",
    "    print 'lm_%i' % i, \" <=> \", g, \"<==>\", TARGET_LABELS2[g]\n",
    "    labels_masks_dict['lm_%i' % i] = target_labels[g]\n",
    "    s |= set(g)\n",
    "    \n",
    "# print 'lm_others', \"<=>\", others, \"<==>\", TARGET_LABELS2[others]\n",
    "# labels_masks_dict['lm_others'] = target_labels[others]\n",
    "# s |= set(others)\n",
    "\n",
    "# assert len(s) == len(target_labels), \"Sum is not equal 24, s=%i\" % s\n",
    "print labels_masks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et': [(None, None, 'lm_0')],\n",
       " 'gb': [(None, None, 'lm_12'),\n",
       "  (None, None, 'lm_13'),\n",
       "  (None, None, 'lm_10'),\n",
       "  (None, None, 'lm_11'),\n",
       "  (None, None, 'lm_14'),\n",
       "  (None, None, 'lm_8'),\n",
       "  (None, None, 'lm_9'),\n",
       "  (None, None, 'lm_1'),\n",
       "  (None, None, 'lm_2'),\n",
       "  (None, None, 'lm_3'),\n",
       "  (None, None, 'lm_4'),\n",
       "  (None, None, 'lm_5'),\n",
       "  (None, None, 'lm_6'),\n",
       "  (None, None, 'lm_7')],\n",
       " 'rf': [(None, None, 'lm_0')]}"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {model_name: [(samples_mask_code, features_mask_name, labels_mask_name), ...]}\n",
    "models_pipelines = {\n",
    "    'gb' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) == 1],    \n",
    "    'rf' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "    'et' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "}\n",
    "models_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import train_all, predict_all, probas_to_indices, score_estimators\n",
    "from utils import map7_score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203333, 157) (203333, 76)\n",
      "(46667, 157) (46667, 76)\n"
     ]
    }
   ],
   "source": [
    "ll = 140000\n",
    "# ll = 1100\n",
    "\n",
    "mask = (X.index.isin((X.index[:ll//3]))) | (X.index.isin((X.index[2*ll//3:])))\n",
    "\n",
    "X1 = X[mask]\n",
    "Y1 = Y[mask]\n",
    "print X1.shape, Y1.shape\n",
    "\n",
    "mask = X.index.isin(X.index[ll//3:2*ll//3])\n",
    "X2 = X[mask]\n",
    "Y2 = Y[mask]\n",
    "print X2.shape, Y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# res = Y1[labels_masks_dict['lm_0']].apply(dummies_to_decimal, axis=1)\n",
    "# res = pd.get_dummies(res)\n",
    "# res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import dummies_to_decimal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def prepare_to_fit(X_train, Y_train):    \n",
    "    x_train = X_train.values\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    y_train = Y_train.apply(dummies_to_decimal, axis=1)\n",
    "    y_train = pd.get_dummies(y_train)\n",
    "    y_train = y_train.values    \n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def prepare_to_test(X_val, Y_val=None):\n",
    "    x_val = X_val.values\n",
    "    x_val = StandardScaler().fit_transform(x_val)\n",
    "    if Y_val is not None:\n",
    "        y_val = Y_val.apply(dummies_to_decimal, axis=1)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_val = y_val.values \n",
    "    else:\n",
    "        y_val = None\n",
    "    return x_val, y_val\n",
    "\n",
    "\n",
    "def probas_to_labels_probas(y_probas, class_indices, labels):\n",
    "    l = len(labels)\n",
    "    out = np.zeros((len(y_probas), l))\n",
    "    i = 0\n",
    "    for probas in y_probas:\n",
    "        if np.sum(probas) > 0:\n",
    "            pr = np.zeros((l,))\n",
    "            for index, p in zip(class_indices, probas):\n",
    "                dummies_str = decimal_to_dummies(index, l)\n",
    "                pr += p * np.array([float(v) for v in dummies_str])\n",
    "            out[i, :] = pr    \n",
    "        i += 1\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_kwargs = {\n",
    "    'samples_masks_list': samples_masks_list, \n",
    "    'features_masks_dict': features_masks_dict, \n",
    "    'labels_masks_dict': labels_masks_dict, \n",
    "    'models_dict': models_dict,\n",
    "    'labels': target_labels,\n",
    "    'transform_proba_func': probas_to_indices,\n",
    "#     'prepare_to_fit_func': prepare_to_fit,\n",
    "#     'prepare_to_test_func': prepare_to_test,   \n",
    "#     'probas_to_labels_probas_func': probas_to_labels_probas,\n",
    "    'threshold': 0.15,\n",
    "    'n_highest': 7,\n",
    "    'mode': 'sum',\n",
    "    'verbose': False,\n",
    "    'models_pipelines': models_pipelines,\n",
    "    'return_probas': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.909359\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.908050\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.947480\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.997709\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.880399\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999673\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.991819\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.995092\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995419\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.913940\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.952880\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.996401\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.996891\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993292\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.960733\n",
      "INFO:root:-- Process : sample_mask=6112/203333, features_mask=fm_all, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.998691\n"
     ]
    }
   ],
   "source": [
    "estimators = train_all(X1, Y1, **_kwargs)\n",
    "\n",
    "#print estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et': 0.99509162303664922,\n",
       " 'gb': 0.96052262528047871,\n",
       " 'rf': 0.99541884816753923}"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = defaultdict(list)\n",
    "for e in estimators:\n",
    "    accuracies[e[0][2]].append(e[2])\n",
    "\n",
    "mean_accuracy = {}\n",
    "for key in accuracies:\n",
    "    accuracy_list = accuracies[key]\n",
    "    mean_accuracy[key] = sum(accuracy_list)/len(accuracy_list)\n",
    "    \n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_12 -> 0.98594295755\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_13 -> 0.975485889387\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_10 -> 0.976728737652\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_11 -> 0.986028671224\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_14 -> 0.963785972957\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_8 -> 0.999978571582\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_9 -> 0.999464289541\n",
      "INFO:root:-- Score : model=et, features_mask=fm_all, labels_mask=lm_0 -> 0.501510703495\n",
      "INFO:root:-- Score : model=rf, features_mask=fm_all, labels_mask=lm_0 -> 0.0476996592881\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_1 -> 0.632609767073\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_2 -> 0.996550024643\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_3 -> 0.791608631367\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_4 -> 0.997792872908\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_5 -> 0.997385732959\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_6 -> 0.996100027857\n",
      "INFO:root:-- Score : model=gb, features_mask=fm_all, labels_mask=lm_7 -> 0.999507146378\n"
     ]
    }
   ],
   "source": [
    "_ = score_estimators(estimators, X2, Y2, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predict all --\n"
     ]
    }
   ],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "#print y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2] [19, 17, 2, 23, 7, 18] [2, 23] [2] [17, 2, 23, 7]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>ind_cder_fin_ult1</th>\n",
       "      <th>ind_cno_fin_ult1</th>\n",
       "      <th>ind_ctju_fin_ult1</th>\n",
       "      <th>ind_ctma_fin_ult1</th>\n",
       "      <th>ind_ctop_fin_ult1</th>\n",
       "      <th>ind_ctpp_fin_ult1</th>\n",
       "      <th>ind_deco_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447231</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.909359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447222</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.904450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.990510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.98233</td>\n",
       "      <td>0.995419</td>\n",
       "      <td>2.98822</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.990510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446623</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.904450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446621</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.909359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.904450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.995092</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.98233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.990510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ind_ahor_fin_ult1  ind_aval_fin_ult1  ind_cco_fin_ult1  \\\n",
       "447231                0.0                0.0          1.909359   \n",
       "447222                0.0                0.0          2.904450   \n",
       "446623                0.0                0.0          2.904450   \n",
       "446621                0.0                0.0          1.909359   \n",
       "446015                0.0                0.0          2.904450   \n",
       "\n",
       "        ind_cder_fin_ult1  ind_cno_fin_ult1  ind_ctju_fin_ult1  \\\n",
       "447231                0.0               0.0                0.0   \n",
       "447222                0.0               0.0                0.0   \n",
       "446623                0.0               0.0                0.0   \n",
       "446621                0.0               0.0                0.0   \n",
       "446015                0.0               0.0                0.0   \n",
       "\n",
       "        ind_ctma_fin_ult1  ind_ctop_fin_ult1  ind_ctpp_fin_ult1  \\\n",
       "447231                0.0           0.000000                0.0   \n",
       "447222                0.0           1.990510                0.0   \n",
       "446623                0.0           0.000000                0.0   \n",
       "446621                0.0           0.000000                0.0   \n",
       "446015                0.0           0.995092                0.0   \n",
       "\n",
       "        ind_deco_fin_ult1       ...         ind_hip_fin_ult1  \\\n",
       "447231                0.0       ...                      0.0   \n",
       "447222                0.0       ...                      0.0   \n",
       "446623                0.0       ...                      0.0   \n",
       "446621                0.0       ...                      0.0   \n",
       "446015                0.0       ...                      0.0   \n",
       "\n",
       "        ind_plan_fin_ult1  ind_pres_fin_ult1  ind_reca_fin_ult1  \\\n",
       "447231                0.0                0.0            0.00000   \n",
       "447222                0.0                0.0            2.98233   \n",
       "446623                0.0                0.0            0.00000   \n",
       "446621                0.0                0.0            0.00000   \n",
       "446015                0.0                0.0            2.98233   \n",
       "\n",
       "        ind_tjcr_fin_ult1  ind_valo_fin_ult1  ind_viv_fin_ult1  \\\n",
       "447231           0.000000            0.00000               0.0   \n",
       "447222           0.995419            2.98822               0.0   \n",
       "446623           0.000000            0.00000               0.0   \n",
       "446621           0.000000            0.00000               0.0   \n",
       "446015           0.000000            0.00000               0.0   \n",
       "\n",
       "        ind_nomina_ult1  ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "447231              0.0                0.0         0.000000  \n",
       "447222              0.0                0.0         1.990510  \n",
       "446623              0.0                0.0         0.995419  \n",
       "446621              0.0                0.0         0.000000  \n",
       "446015              0.0                0.0         1.990510  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_preds[:5]\n",
    "Y_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_masks_dict['lm_0'], common_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_val = targets_str_to_indices(Y2[target_labels].values)\n",
    "# y_val = targets_str_to_indices(Y2[labels_masks_dict['lm_0']].values, index_map=common_groups[0])\n",
    "#print y_val[:100]\n",
    "#print y_preds[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.unique(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Compute max map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0295069320933\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0221204967584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022120496758356492"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "map7_score(y_val, y_val, Y2[LAST_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_val)\n",
    "logging.info(\"- Compute map7 score\")\n",
    "map7_score(y_val, y_preds, Y2[LAST_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On columns lm_0=['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1','ind_ctju_fin_ult1']\n",
    "\n",
    "- Feature mask: all : 'fm6', 'fm4', 'fm5', 'fm2', 'fm3', 'fm0', 'fm1'\n",
    "- threshold = 0.0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "et | 0.007074370518592629 | 0.0075787893947 | lm_0 | all \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print labels_masks_dict[estimators[0][0][1]]\n",
    "# print estimators[0][1].classes_\n",
    "# print estimators[0][1].n_classes_\n",
    "# print estimators[0][1].n_features_\n",
    "# print estimators[0][1].n_outputs_\n",
    "# print estimators[0][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import targets_to_labels, targets_indices_to_labels, remove_last_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Count =  1\n",
      "['particular Account']\n",
      "['Credit Card', 'Payroll', 'Pensions']\n",
      "--- Count =  2\n",
      "['particular Account', 'Home Account']\n",
      "['Current Accounts', 'Direct Debit']\n",
      "--- Count =  3\n",
      "['Credit Card']\n",
      "[]\n",
      "--- Count =  4\n",
      "['Credit Card']\n",
      "['Direct Debit']\n",
      "--- Count =  5\n",
      "['Payroll', 'Pensions']\n",
      "['Credit Card']\n",
      "--- Count =  6\n",
      "['e-account']\n",
      "['Current Accounts']\n",
      "--- Count =  7\n",
      "['Long-term deposits']\n",
      "['Direct Debit', 'Credit Card']\n",
      "--- Count =  8\n",
      "['e-account']\n",
      "['Direct Debit']\n",
      "--- Count =  9\n",
      "['Payroll', 'Pensions']\n",
      "[]\n",
      "--- Count =  10\n",
      "['particular Account']\n",
      "['Payroll', 'Pensions']\n",
      "--- Count =  11\n",
      "['Credit Card']\n",
      "['Direct Debit']\n",
      "--- Count =  12\n",
      "['Credit Card']\n",
      "['Direct Debit']\n",
      "--- Count =  13\n",
      "['Taxes']\n",
      "[]\n",
      "--- Count =  14\n",
      "['Taxes']\n",
      "['Credit Card', 'Current Accounts']\n",
      "--- Count =  15\n",
      "['Credit Card']\n",
      "[]\n",
      "--- Count =  16\n",
      "['e-account']\n",
      "['Direct Debit']\n",
      "--- Count =  17\n",
      "['Payroll', 'Pensions']\n",
      "['Current Accounts']\n",
      "--- Count =  18\n",
      "['Current Accounts']\n",
      "['Payroll Account', 'Payroll', 'Direct Debit']\n",
      "--- Count =  19\n",
      "['e-account']\n",
      "['Current Accounts', 'Pensions']\n",
      "--- Count =  20\n",
      "['Payroll Account', 'Payroll', 'Pensions']\n",
      "['Direct Debit']\n",
      "--- Count =  21\n",
      "['particular Plus Account']\n",
      "['Credit Card']\n",
      "--- Count =  22\n",
      "['particular Plus Account']\n",
      "['Credit Card']\n",
      "--- Count =  23\n",
      "['particular Account']\n",
      "['Direct Debit', 'Payroll', 'Pensions']\n",
      "--- Count =  24\n",
      "['e-account']\n",
      "['Current Accounts']\n"
     ]
    }
   ],
   "source": [
    "limit = 25\n",
    "count = 0\n",
    "\n",
    "not_predicted_predicted = defaultdict(int)\n",
    "for last_choice, targets, products, proba in zip(Y2[LAST_TARGET_LABELS].values, y_val, y_preds, Y_probas.values):\n",
    "    added_products = remove_last_choice(targets, last_choice)\n",
    "    predictions = remove_last_choice(products, last_choice)\n",
    "#     print \"---\", count, last_choice\n",
    "#     print targets, '->', added_products\n",
    "#     print products, '->', predictions\n",
    "#     if count == 3:\n",
    "#         break\n",
    "    \n",
    "    if len(added_products) == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(set(added_products) & set(predictions)) > 0:\n",
    "#         print \"Predicted : \", added_products, predictions\n",
    "#         print set(added_products) & set(predictions)\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    if count < limit:\n",
    "        print \"--- Count = \", count\n",
    "        print targets_indices_to_labels(added_products, TARGET_LABELS2)#, targets_indices_to_labels(targets, TARGET_LABELS2)\n",
    "        print targets_indices_to_labels(predictions, TARGET_LABELS2)#, targets_indices_to_labels(products, TARGET_LABELS2)#, proba\n",
    "    \n",
    "    for p in added_products:\n",
    "        not_predicted_predicted[TARGET_LABELS2[p]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'Securities': 9, 'Direct Debit': 8, 'particular Account': 17, 'particular Plus Account': 12, 'e-account': 61, 'Payroll': 55, 'Pensions': 59, 'Taxes': 8, 'Payroll Account': 33, 'Long-term deposits': 3, 'Credit Card': 68, 'Mas particular Account': 5, 'Funds': 3, 'Home Account': 1, 'Current Accounts': 5, 'Junior Account': 2}) 46667\n"
     ]
    }
   ],
   "source": [
    "print not_predicted_predicted, y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_probas[:10, target_groups[0]]\n",
    "#print Y[np.array(TARGET_LABELS)[target_groups[0]]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KFold Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import cross_val_score0, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Cross validation : \n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 1 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.905977\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.903836\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.949153\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.997859\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.876717\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.990366\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.994826\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994648\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.905085\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.949688\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.997681\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.997859\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.995004\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.960036\n",
      "INFO:root:-- Process : sample_mask=5605/200000, features_mask=fm_all, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.998573\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0281131666667\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 2 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.908480\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.906675\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.945383\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.997212\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.880597\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999672\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.991635\n",
      "INFO:root:-- Process : sample_mask=6097/200000, features_mask=fm_all, labels_mask=lm_0\n"
     ]
    }
   ],
   "source": [
    "# Unitary run\n",
    "nb_folds = 5\n",
    "results = cross_val_score((X, Y, Y[LAST_TARGET_LABELS].values), nb_folds=nb_folds, **_kwargs)\n",
    "\n",
    "print \"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), np.median(results), results.max(), results.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 201505 -> 201605 \n",
    "\n",
    "Cross-Validation \n",
    " 5 | 0.014585 | 0.018385 | 0.019147 | 0.022227 | 0.00294 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cross-validation across several months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_folds = 3\n",
    "yms = [201504, 201505]\n",
    "#yms = [201505]\n",
    "\n",
    "for ym in yms:\n",
    "    logging.info(\"\\n-------------------------\")\n",
    "    logging.info(\"- Process month : %s\" % ym)\n",
    "    logging.info(\"-------------------------\\n\")\n",
    "    \n",
    "    ym1 = ym + 100    \n",
    "    df1 = train_df if months_ym_map[ym] in train_months else val_df\n",
    "    df2 = train_df if months_ym_map[ym1] in train_months else val_df\n",
    "    X, Y, clients_last_choice = get_XY(ym, df1, ym1, df2) \n",
    "    results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                                profiles=profiles,\n",
    "                                nb_folds=nb_folds)\n",
    "    print \"Cross-Validation \\n %i | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), results.max(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df\n",
    "#df1 = val_df\n",
    "df2 = train_df #if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = val_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X, Y, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check score on the data 2016/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"- Compute map7 score\")\n",
    "print map7_score(y_val, y_preds, clients_last_choice[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "print map7_score(y_val, y_val, clients_last_choice[LC_TARGET_LABELS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for 2016/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df, test_df = load_train_test([201506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "months = list(set(full_train_df['fecha_dato'].unique()) | set(test_df['fecha_dato'].unique()))\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "    \n",
    "full_train_months = full_train_df['fecha_dato'].unique()\n",
    "test_months = test_df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201506\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = full_train_df\n",
    "df2 = test_df\n",
    "X, _, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(predicted_added_products, clients, clc, target_labels):\n",
    "    added_products_col = []\n",
    "    count = 0 \n",
    "    for products, last_choice in zip(predicted_added_products, clc):\n",
    "        predictions = remove_last_choice(products, last_choice)\n",
    "        added_products_col.append(' '.join([target_labels[i] for i in predictions]))\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            logging.info(\"Elapsed : %i\", count)\n",
    "            \n",
    "    out = pd.DataFrame(data={'ncodpers': clients, 'added_products': added_products_col}, columns=['ncodpers', 'added_products'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)\n",
    "\n",
    "logging.info(\"- Get submission dataframe:\")\n",
    "clients = X['ncodpers'].values\n",
    "#submission = get_submission(y_preds, clients, clients_last_choice[LC_TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = get_submission(y_preds, clients, clients_last_choice[LC_TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "selected_estimators = []\n",
    "for e in estimators:\n",
    "    # estimators = [([features_mask_name, labels_mask_name, model_name], estimator_object, accuracy), ...]\n",
    "    features_mask_name, labels_mask_name, model_name = e[0]\n",
    "#     print features_mask_name, labels_mask_name, model_name\n",
    "    if set(features_masks_dict[features_mask_name]).issubset(test_df.columns):\n",
    "#         print \"Append the estimator\"\n",
    "        selected_estimators.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_clients = set(submission['ncodpers'].unique())\n",
    "test_clients = set(test_df['ncodpers'].unique())\n",
    "if submission_clients != test_clients:\n",
    "    missing_clients = list(test_clients - submission_clients)\n",
    "    missing_clients_mask = test_df['ncodpers'].isin(missing_clients)\n",
    "    \n",
    "    X1 = test_df[missing_clients_mask]\n",
    "        \n",
    "    y_preds, Y_probas = predict_all(selected_estimators, X1, **_kwargs)    \n",
    "    submission2 = get_submission(y_preds, missing_clients, X1[LC_TARGET_LABELS].values, TARGET_LABELS)\n",
    "    \n",
    "#     submission = pd.concat([submission, submission2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission2 = get_submission(y_preds, missing_clients, X1[LC_TARGET_LABELS].values, TARGET_LABELS)\n",
    "#submission = pd.concat([submission, submission2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print submission2.shape\n",
    "submission2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission DataFrame and write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "\n",
    "submission.to_csv(submission_file, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/submission_2016-11-17-16-37.csv', 'r') as r:\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
