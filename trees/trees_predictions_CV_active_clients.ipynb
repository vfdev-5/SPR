{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees tryouts on SPR data, inspired by Kaggle Forum \"When less is more\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data as \n",
    "    month : [ Features | Targets| Difference | Last Choice Targets  ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from dataset import load_trainval, LC_TARGET_LABELS, TARGET_LABELS_FRQ, TARGET_LABELS_DIFF\n",
    "from utils import to_yearmonth, TARGET_LABELS, TARGET_LABELS2\n",
    "from utils import target_str_to_labels, decimal_to_dummies, targets_str_to_indices, targets_dec_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    u'ind_empleado', u'pais_residencia',\n",
    "    u'sexo', u'age', u'ind_nuevo', u'antiguedad', u'indrel',\n",
    "    u'ult_fec_cli_1t', u'indrel_1mes', u'tiprel_1mes', u'indresi',\n",
    "    u'indext', u'conyuemp', u'canal_entrada', u'indfall', u'nomprov',\n",
    "    u'ind_actividad_cliente', u'renta', u'segmento'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load training data : \n",
      "INFO:root:- Load data : [201504, 201505, 201601, 201602, 201604, 201605]\n",
      "INFO:root:-- Select 150000 clients\n",
      "INFO:root:- Number of lines with unknown data : 30\n",
      "INFO:root:- Number of columns with nan : 9\n",
      "INFO:root:-- Process date : 201505\n",
      "INFO:root:-- Process date : 201602\n",
      "INFO:root:-- Process date : 201605\n",
      "INFO:root:-- Add logCount columns\n",
      "INFO:root:-- Process month : 2015-04-28\n",
      "INFO:root:-- Process month : 2015-05-28\n",
      "INFO:root:-- Process month : 2016-01-28\n",
      "INFO:root:-- Process month : 2016-02-28\n",
      "INFO:root:-- Process month : 2016-04-28\n",
      "INFO:root:-- Process month : 2016-05-28\n",
      "INFO:root:-- Add logDecimal columns\n",
      "INFO:root:-- Transform age/renta/logdiff\n",
      "INFO:root:-- Add target values frequencies\n",
      "INFO:root:-- Add target diff\n"
     ]
    }
   ],
   "source": [
    "# train_yearmonths_list = [201504, 201505, 201604]\n",
    "train_yearmonths_list = [201505, 201602, 201605]\n",
    "# train_yearmonths_list = [201505]\n",
    "#val_yearmonth = [201605]\n",
    "train_nb_clients = 150000\n",
    "# train_nb_clients = 1500\n",
    "#train_df, val_df = load_trainval(train_yearmonths_list, val_yearmonth, train_nb_clients, val_nb_clients=1500)\n",
    "train_df = load_trainval(train_yearmonths_list, train_nb_clients=train_nb_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_ahor_fin_ult1_frq</th>\n",
       "      <th>ind_aval_fin_ult1_frq</th>\n",
       "      <th>ind_cco_fin_ult1_frq</th>\n",
       "      <th>ind_cder_fin_ult1_frq</th>\n",
       "      <th>ind_cno_fin_ult1_frq</th>\n",
       "      <th>ind_ctju_fin_ult1_frq</th>\n",
       "      <th>ind_ctma_fin_ult1_frq</th>\n",
       "      <th>ind_ctop_fin_ult1_frq</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq</th>\n",
       "      <th>ind_plan_fin_ult1_frq</th>\n",
       "      <th>ind_pres_fin_ult1_frq</th>\n",
       "      <th>ind_reca_fin_ult1_frq</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq</th>\n",
       "      <th>ind_valo_fin_ult1_frq</th>\n",
       "      <th>ind_viv_fin_ult1_frq</th>\n",
       "      <th>ind_nomina_ult1_frq</th>\n",
       "      <th>ind_nom_pens_ult1_frq</th>\n",
       "      <th>ind_recibo_ult1_frq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210122</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.228481</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.102785</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051662</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.228481</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.102785</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638559</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663081</th>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532930</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338256</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210113</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>15903</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.164316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051671</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15903</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.164316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638492</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>15903</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.164316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663070</th>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>15903</td>\n",
       "      <td>0.99982</td>\n",
       "      <td>0.999954</td>\n",
       "      <td>0.771519</td>\n",
       "      <td>0.999542</td>\n",
       "      <td>0.897215</td>\n",
       "      <td>0.988507</td>\n",
       "      <td>0.989993</td>\n",
       "      <td>0.164316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha_dato  ncodpers  ind_ahor_fin_ult1_frq  ind_aval_fin_ult1_frq  \\\n",
       "210122   2015-04-28     15892                0.99982               0.999954   \n",
       "1051662  2015-05-28     15892                0.99982               0.999954   \n",
       "1638559  2016-01-28     15892                0.99982               0.999954   \n",
       "2663081  2016-02-28     15892                0.99982               0.999954   \n",
       "3532930  2016-04-28     15892                0.99982               0.999954   \n",
       "4338256  2016-05-28     15892                0.99982               0.999954   \n",
       "210113   2015-04-28     15903                0.99982               0.999954   \n",
       "1051671  2015-05-28     15903                0.99982               0.999954   \n",
       "1638492  2016-01-28     15903                0.99982               0.999954   \n",
       "2663070  2016-02-28     15903                0.99982               0.999954   \n",
       "\n",
       "         ind_cco_fin_ult1_frq  ind_cder_fin_ult1_frq  ind_cno_fin_ult1_frq  \\\n",
       "210122               0.228481               0.999542              0.102785   \n",
       "1051662              0.228481               0.999542              0.102785   \n",
       "1638559              0.771519               0.999542              0.897215   \n",
       "2663081              0.771519               0.999542              0.897215   \n",
       "3532930              0.771519               0.999542              0.897215   \n",
       "4338256              0.771519               0.999542              0.897215   \n",
       "210113               0.771519               0.999542              0.897215   \n",
       "1051671              0.771519               0.999542              0.897215   \n",
       "1638492              0.771519               0.999542              0.897215   \n",
       "2663070              0.771519               0.999542              0.897215   \n",
       "\n",
       "         ind_ctju_fin_ult1_frq  ind_ctma_fin_ult1_frq  ind_ctop_fin_ult1_frq  \\\n",
       "210122                0.988507               0.989993               0.835684   \n",
       "1051662               0.988507               0.989993               0.835684   \n",
       "1638559               0.988507               0.989993               0.835684   \n",
       "2663081               0.988507               0.989993               0.835684   \n",
       "3532930               0.988507               0.989993               0.835684   \n",
       "4338256               0.988507               0.989993               0.835684   \n",
       "210113                0.988507               0.989993               0.164316   \n",
       "1051671               0.988507               0.989993               0.164316   \n",
       "1638492               0.988507               0.989993               0.164316   \n",
       "2663070               0.988507               0.989993               0.164316   \n",
       "\n",
       "                ...           ind_hip_fin_ult1_frq  ind_plan_fin_ult1_frq  \\\n",
       "210122          ...                       0.992253               0.987635   \n",
       "1051662         ...                       0.992253               0.987635   \n",
       "1638559         ...                       0.992253               0.987635   \n",
       "2663081         ...                       0.992253               0.987635   \n",
       "3532930         ...                       0.992253               0.987635   \n",
       "4338256         ...                       0.992253               0.987635   \n",
       "210113          ...                       0.992253               0.987635   \n",
       "1051671         ...                       0.992253               0.987635   \n",
       "1638492         ...                       0.992253               0.987635   \n",
       "2663070         ...                       0.992253               0.987635   \n",
       "\n",
       "         ind_pres_fin_ult1_frq  ind_reca_fin_ult1_frq  ind_tjcr_fin_ult1_frq  \\\n",
       "210122                0.996609                0.06836               0.055803   \n",
       "1051662               0.996609                0.06836               0.055803   \n",
       "1638559               0.996609                0.06836               0.055803   \n",
       "2663081               0.996609                0.06836               0.055803   \n",
       "3532930               0.996609                0.06836               0.055803   \n",
       "4338256               0.996609                0.06836               0.055803   \n",
       "210113                0.996609                0.93164               0.055803   \n",
       "1051671               0.996609                0.93164               0.055803   \n",
       "1638492               0.996609                0.93164               0.055803   \n",
       "2663070               0.996609                0.93164               0.055803   \n",
       "\n",
       "         ind_valo_fin_ult1_frq  ind_viv_fin_ult1_frq  ind_nomina_ult1_frq  \\\n",
       "210122                0.033134              0.995131             0.933164   \n",
       "1051662               0.033134              0.995131             0.933164   \n",
       "1638559               0.033134              0.995131             0.933164   \n",
       "2663081               0.033134              0.995131             0.933164   \n",
       "3532930               0.033134              0.995131             0.933164   \n",
       "4338256               0.033134              0.995131             0.933164   \n",
       "210113                0.966866              0.995131             0.933164   \n",
       "1051671               0.966866              0.995131             0.933164   \n",
       "1638492               0.966866              0.995131             0.933164   \n",
       "2663070               0.966866              0.995131             0.933164   \n",
       "\n",
       "         ind_nom_pens_ult1_frq  ind_recibo_ult1_frq  \n",
       "210122                0.927901             0.159955  \n",
       "1051662               0.927901             0.159955  \n",
       "1638559               0.927901             0.159955  \n",
       "2663081               0.927901             0.159955  \n",
       "3532930               0.927901             0.159955  \n",
       "4338256               0.927901             0.159955  \n",
       "210113                0.927901             0.840045  \n",
       "1051671               0.927901             0.840045  \n",
       "1638492               0.927901             0.840045  \n",
       "2663070               0.927901             0.840045  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['fecha_dato', 'ncodpers'] + TARGET_LABELS_FRQ.tolist()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_clients(df1, mask1, mask2, df2=None):\n",
    "    active_clients1 = df1[mask1]['ncodpers'].unique()\n",
    "    if df2 is not None:\n",
    "        active_clients2 = df2[mask2]['ncodpers'].unique()\n",
    "    else:\n",
    "        active_clients2 = df1[mask2]['ncodpers'].unique()\n",
    "    active_clients = list(set(active_clients1) & set(active_clients2)) \n",
    "    \n",
    "    if df2 is not None:\n",
    "        return df1['ncodpers'].isin(active_clients), df2['ncodpers'].isin(active_clients)\n",
    "    return df1['ncodpers'].isin(active_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "# months = list(set(train_df['fecha_dato'].unique()) | set(val_df['fecha_dato'].unique()))\n",
    "months = train_df['fecha_dato'].unique()\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "\n",
    "        \n",
    "train_months = train_df['fecha_dato'].unique()\n",
    "# val_months = val_df['fecha_dato'].unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_added_products, remove_last_choice, apk, map7_score\n",
    "from visualization import visualize_train_test, visualize_folds, compare_two_datasets, compare_folds, compare_folds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_features = ['targets_diff', 'targets_logdiff', 'targets_logcount2_diff', 'targets_logcount2', 'targets_logcount1', 'targets_logDec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(current_month, df1, next_year_month, df2, months_ym_map):\n",
    "    month_mask = df1['fecha_dato'] == months_ym_map[current_month]\n",
    "    next_year_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month]\n",
    "    next_year_prev_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month - 1]\n",
    "    \n",
    "    # get common clients from df1 at this month and df2 at next year month\n",
    "    common_clients_mask1, common_clients_mask2 = get_common_clients(df1, month_mask, next_year_month_mask, df2)\n",
    "    common_clients_mask2, common_clients_mask3 = get_common_clients(df2, common_clients_mask2 & next_year_month_mask, next_year_prev_month_mask, df2)\n",
    "        \n",
    "    c1 = df1[common_clients_mask1 & month_mask]['ncodpers'].values\n",
    "    c2 = df2[common_clients_mask2 & next_year_month_mask]['ncodpers'].values\n",
    "    c3 = df2[common_clients_mask3 & next_year_prev_month_mask]['ncodpers'].values\n",
    "    assert (c1 == c2).all() and (c2 == c3).all(), \"Problem with common clients\" \n",
    "    \n",
    "    X = df1[common_clients_mask1 & month_mask][['ncodpers', 'fecha_dato'] + target_features + features + TARGET_LABELS_FRQ.tolist()]            \n",
    "\n",
    "    print \"df2[next_year_month_mask][TARGET_LABELS].isnull().all().all()\", df2[next_year_month_mask][TARGET_LABELS].isnull().all().all()\n",
    "    \n",
    "    if TARGET_LABELS[0] in df2.columns and TARGET_LABELS_FRQ[0] in df2.columns and not df2[next_year_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        print \"Define Y\"\n",
    "        Y = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str'] + TARGET_LABELS]    \n",
    "        assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        Y.index = X.index                \n",
    "    else:\n",
    "        Y = None\n",
    "    \n",
    "        print \"df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all()\", df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all()\n",
    "    \n",
    "    if TARGET_LABELS_FRQ[0] in df2.columns and not df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        print \"Add TARGET_LABELS_FRQ from previous month to X\"\n",
    "        # Add TARGET_LABELS_FRQ from previous month to X:\n",
    "        target_labels_frq = df2[common_clients_mask3 & next_year_prev_month_mask][['ncodpers'] + TARGET_LABELS_FRQ.tolist()]\n",
    "        assert (X['ncodpers'].values == target_labels_frq['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        target_labels_frq = target_labels_frq[TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.columns = [c + '_prev' for c in TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.index = X.index\n",
    "        X = pd.concat([X, target_labels_frq], axis=1)        \n",
    "\n",
    "    \n",
    "    if LC_TARGET_LABELS[0] in df2.columns:\n",
    "        clients_last_choice = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato'] + LC_TARGET_LABELS.tolist()]\n",
    "    else:\n",
    "        clients_last_choice = None\n",
    "        \n",
    "    return X, Y, clients_last_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df if months_ym_map[current_month] in train_months else val_df\n",
    "#df1 = train_df\n",
    "df2 = train_df if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = train_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"WTF\"\n",
    "assert (X['ncodpers'].values == clients_last_choice['ncodpers'].values).all(), \"WTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149985, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_diff</th>\n",
       "      <th>targets_logdiff</th>\n",
       "      <th>targets_logcount2_diff</th>\n",
       "      <th>targets_logcount2</th>\n",
       "      <th>targets_logcount1</th>\n",
       "      <th>targets_logDec</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq_prev</th>\n",
       "      <th>ind_plan_fin_ult1_frq_prev</th>\n",
       "      <th>ind_pres_fin_ult1_frq_prev</th>\n",
       "      <th>ind_reca_fin_ult1_frq_prev</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq_prev</th>\n",
       "      <th>ind_valo_fin_ult1_frq_prev</th>\n",
       "      <th>ind_viv_fin_ult1_frq_prev</th>\n",
       "      <th>ind_nomina_ult1_frq_prev</th>\n",
       "      <th>ind_nom_pens_ult1_frq_prev</th>\n",
       "      <th>ind_recibo_ult1_frq_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051662</th>\n",
       "      <td>15892</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>13.181662</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051671</th>\n",
       "      <td>15903</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>14.586878</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051672</th>\n",
       "      <td>15906</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.349075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.944197</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.072099</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051674</th>\n",
       "      <td>15908</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>14.792546</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.066836</td>\n",
       "      <td>0.072099</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051675</th>\n",
       "      <td>15911</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.196866</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051643</th>\n",
       "      <td>15919</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>14.588785</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0.944197</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051645</th>\n",
       "      <td>15921</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.296737</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051649</th>\n",
       "      <td>15925</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>14.586878</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051653</th>\n",
       "      <td>15929</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>14.572580</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.055803</td>\n",
       "      <td>0.033134</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.840045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051659</th>\n",
       "      <td>15935</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>14.589700</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992253</td>\n",
       "      <td>0.987635</td>\n",
       "      <td>0.996609</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.944197</td>\n",
       "      <td>0.966866</td>\n",
       "      <td>0.995131</td>\n",
       "      <td>0.933164</td>\n",
       "      <td>0.927901</td>\n",
       "      <td>0.159955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers  fecha_dato  targets_diff  targets_logdiff  \\\n",
       "1051662     15892  2015-05-28           0.0         0.000000   \n",
       "1051671     15903  2015-05-28           0.0         0.000000   \n",
       "1051672     15906  2015-05-28          -2.0        -1.098612   \n",
       "1051674     15908  2015-05-28           0.0         0.000000   \n",
       "1051675     15911  2015-05-28           0.0         0.000000   \n",
       "1051643     15919  2015-05-28           0.0         0.000000   \n",
       "1051645     15921  2015-05-28           0.0         0.000000   \n",
       "1051649     15925  2015-05-28           0.0         0.000000   \n",
       "1051653     15929  2015-05-28           1.0         0.693147   \n",
       "1051659     15935  2015-05-28           0.0         0.000000   \n",
       "\n",
       "         targets_logcount2_diff  targets_logcount2  targets_logcount1  \\\n",
       "1051662                0.000000           0.000009           0.000013   \n",
       "1051671                0.000000           0.001516           0.001627   \n",
       "1051672                0.000001           0.000002           0.000007   \n",
       "1051674                0.000000           0.000007           0.000007   \n",
       "1051675                0.000000           0.000002           0.000007   \n",
       "1051643                0.000000           0.000108           0.000120   \n",
       "1051645                0.000000           0.000002           0.000007   \n",
       "1051649                0.000000           0.001516           0.001627   \n",
       "1051653                0.000020           0.000028           0.000027   \n",
       "1051659                0.000000           0.000182           0.000173   \n",
       "\n",
       "         targets_logDec  ind_empleado  pais_residencia  \\\n",
       "1051662       13.181662             2                0   \n",
       "1051671       14.586878             2                0   \n",
       "1051672       13.349075             0                0   \n",
       "1051674       14.792546             2                0   \n",
       "1051675       13.196866             2                0   \n",
       "1051643       14.588785             3                0   \n",
       "1051645       13.296737             2                0   \n",
       "1051649       14.586878             2                0   \n",
       "1051653       14.572580             3                0   \n",
       "1051659       14.589700             3                0   \n",
       "\n",
       "                   ...             ind_hip_fin_ult1_frq_prev  \\\n",
       "1051662            ...                              0.992253   \n",
       "1051671            ...                              0.992253   \n",
       "1051672            ...                              0.992253   \n",
       "1051674            ...                              0.992253   \n",
       "1051675            ...                              0.992253   \n",
       "1051643            ...                              0.992253   \n",
       "1051645            ...                              0.992253   \n",
       "1051649            ...                              0.992253   \n",
       "1051653            ...                              0.992253   \n",
       "1051659            ...                              0.992253   \n",
       "\n",
       "         ind_plan_fin_ult1_frq_prev  ind_pres_fin_ult1_frq_prev  \\\n",
       "1051662                    0.987635                    0.996609   \n",
       "1051671                    0.987635                    0.996609   \n",
       "1051672                    0.987635                    0.996609   \n",
       "1051674                    0.012365                    0.996609   \n",
       "1051675                    0.987635                    0.996609   \n",
       "1051643                    0.987635                    0.996609   \n",
       "1051645                    0.012365                    0.996609   \n",
       "1051649                    0.987635                    0.996609   \n",
       "1051653                    0.987635                    0.996609   \n",
       "1051659                    0.987635                    0.996609   \n",
       "\n",
       "         ind_reca_fin_ult1_frq_prev  ind_tjcr_fin_ult1_frq_prev  \\\n",
       "1051662                     0.06836                    0.055803   \n",
       "1051671                     0.93164                    0.055803   \n",
       "1051672                     0.93164                    0.944197   \n",
       "1051674                     0.93164                    0.055803   \n",
       "1051675                     0.93164                    0.055803   \n",
       "1051643                     0.06836                    0.944197   \n",
       "1051645                     0.93164                    0.055803   \n",
       "1051649                     0.93164                    0.055803   \n",
       "1051653                     0.93164                    0.055803   \n",
       "1051659                     0.93164                    0.944197   \n",
       "\n",
       "         ind_valo_fin_ult1_frq_prev  ind_viv_fin_ult1_frq_prev  \\\n",
       "1051662                    0.033134                   0.995131   \n",
       "1051671                    0.966866                   0.995131   \n",
       "1051672                    0.966866                   0.995131   \n",
       "1051674                    0.033134                   0.995131   \n",
       "1051675                    0.033134                   0.995131   \n",
       "1051643                    0.966866                   0.995131   \n",
       "1051645                    0.033134                   0.995131   \n",
       "1051649                    0.966866                   0.995131   \n",
       "1051653                    0.033134                   0.995131   \n",
       "1051659                    0.966866                   0.995131   \n",
       "\n",
       "         ind_nomina_ult1_frq_prev  ind_nom_pens_ult1_frq_prev  \\\n",
       "1051662                  0.933164                    0.927901   \n",
       "1051671                  0.933164                    0.927901   \n",
       "1051672                  0.933164                    0.072099   \n",
       "1051674                  0.066836                    0.072099   \n",
       "1051675                  0.933164                    0.927901   \n",
       "1051643                  0.933164                    0.927901   \n",
       "1051645                  0.933164                    0.927901   \n",
       "1051649                  0.933164                    0.927901   \n",
       "1051653                  0.933164                    0.927901   \n",
       "1051659                  0.933164                    0.927901   \n",
       "\n",
       "         ind_recibo_ult1_frq_prev  \n",
       "1051662                  0.159955  \n",
       "1051671                  0.840045  \n",
       "1051672                  0.159955  \n",
       "1051674                  0.159955  \n",
       "1051675                  0.159955  \n",
       "1051643                  0.159955  \n",
       "1051645                  0.159955  \n",
       "1051649                  0.159955  \n",
       "1051653                  0.840045  \n",
       "1051659                  0.159955  \n",
       "\n",
       "[10 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X.shape\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149985, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_str</th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>ind_cder_fin_ult1</th>\n",
       "      <th>ind_cno_fin_ult1</th>\n",
       "      <th>ind_ctju_fin_ult1</th>\n",
       "      <th>ind_ctma_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1</th>\n",
       "      <th>ind_plan_fin_ult1</th>\n",
       "      <th>ind_pres_fin_ult1</th>\n",
       "      <th>ind_reca_fin_ult1</th>\n",
       "      <th>ind_tjcr_fin_ult1</th>\n",
       "      <th>ind_valo_fin_ult1</th>\n",
       "      <th>ind_viv_fin_ult1</th>\n",
       "      <th>ind_nomina_ult1</th>\n",
       "      <th>ind_nom_pens_ult1</th>\n",
       "      <th>ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1051662</th>\n",
       "      <td>15892</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000001100001110001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051671</th>\n",
       "      <td>15903</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010000000000100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051672</th>\n",
       "      <td>15906</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010011001000000000011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051674</th>\n",
       "      <td>15908</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001010001000100100110111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051675</th>\n",
       "      <td>15911</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010000001100000110001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051643</th>\n",
       "      <td>15919</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000001000001000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051645</th>\n",
       "      <td>15921</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010001010100110001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051649</th>\n",
       "      <td>15925</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010000000000100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051653</th>\n",
       "      <td>15929</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000001000100000110001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051659</th>\n",
       "      <td>15935</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010001100000000001</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers  fecha_dato               targets_str  ind_ahor_fin_ult1  \\\n",
       "1051662     15892  2016-05-28  001000000001100001110001                  0   \n",
       "1051671     15903  2016-05-28  001000010000000000100000                  0   \n",
       "1051672     15906  2016-05-28  000010011001000000000011                  0   \n",
       "1051674     15908  2016-05-28  001010001000100100110111                  0   \n",
       "1051675     15911  2016-05-28  000010000001100000110001                  0   \n",
       "1051643     15919  2016-05-28  001000000001000001000001                  0   \n",
       "1051645     15921  2016-05-28  001000010001010100110001                  0   \n",
       "1051649     15925  2016-05-28  001000010000000000100000                  0   \n",
       "1051653     15929  2016-05-28  001000001000100000110001                  0   \n",
       "1051659     15935  2016-05-28  001000010001100000000001                  0   \n",
       "\n",
       "         ind_aval_fin_ult1  ind_cco_fin_ult1  ind_cder_fin_ult1  \\\n",
       "1051662                  0                 1                  0   \n",
       "1051671                  0                 1                  0   \n",
       "1051672                  0                 0                  0   \n",
       "1051674                  0                 1                  0   \n",
       "1051675                  0                 0                  0   \n",
       "1051643                  0                 1                  0   \n",
       "1051645                  0                 1                  0   \n",
       "1051649                  0                 1                  0   \n",
       "1051653                  0                 1                  0   \n",
       "1051659                  0                 1                  0   \n",
       "\n",
       "         ind_cno_fin_ult1  ind_ctju_fin_ult1  ind_ctma_fin_ult1  \\\n",
       "1051662                 0                  0                  0   \n",
       "1051671                 0                  0                  0   \n",
       "1051672                 1                  0                  0   \n",
       "1051674                 1                  0                  0   \n",
       "1051675                 1                  0                  0   \n",
       "1051643                 0                  0                  0   \n",
       "1051645                 0                  0                  0   \n",
       "1051649                 0                  0                  0   \n",
       "1051653                 0                  0                  0   \n",
       "1051659                 0                  0                  0   \n",
       "\n",
       "              ...         ind_hip_fin_ult1  ind_plan_fin_ult1  \\\n",
       "1051662       ...                        0                  0   \n",
       "1051671       ...                        0                  0   \n",
       "1051672       ...                        0                  0   \n",
       "1051674       ...                        0                  1   \n",
       "1051675       ...                        0                  0   \n",
       "1051643       ...                        0                  0   \n",
       "1051645       ...                        0                  1   \n",
       "1051649       ...                        0                  0   \n",
       "1051653       ...                        0                  0   \n",
       "1051659       ...                        0                  0   \n",
       "\n",
       "         ind_pres_fin_ult1  ind_reca_fin_ult1  ind_tjcr_fin_ult1  \\\n",
       "1051662                  0                  1                  1   \n",
       "1051671                  0                  0                  1   \n",
       "1051672                  0                  0                  0   \n",
       "1051674                  0                  0                  1   \n",
       "1051675                  0                  0                  1   \n",
       "1051643                  0                  1                  0   \n",
       "1051645                  0                  0                  1   \n",
       "1051649                  0                  0                  1   \n",
       "1051653                  0                  0                  1   \n",
       "1051659                  0                  0                  0   \n",
       "\n",
       "         ind_valo_fin_ult1  ind_viv_fin_ult1  ind_nomina_ult1  \\\n",
       "1051662                  1                 0              0.0   \n",
       "1051671                  0                 0              0.0   \n",
       "1051672                  0                 0              0.0   \n",
       "1051674                  1                 0              1.0   \n",
       "1051675                  1                 0              0.0   \n",
       "1051643                  0                 0              0.0   \n",
       "1051645                  1                 0              0.0   \n",
       "1051649                  0                 0              0.0   \n",
       "1051653                  1                 0              0.0   \n",
       "1051659                  0                 0              0.0   \n",
       "\n",
       "         ind_nom_pens_ult1  ind_recibo_ult1  \n",
       "1051662                0.0                1  \n",
       "1051671                0.0                0  \n",
       "1051672                1.0                1  \n",
       "1051674                1.0                1  \n",
       "1051675                0.0                1  \n",
       "1051643                0.0                1  \n",
       "1051645                0.0                1  \n",
       "1051649                0.0                0  \n",
       "1051653                0.0                1  \n",
       "1051659                0.0                1  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Y.shape\n",
    "Y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149985, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>lc_ind_ahor_fin_ult1</th>\n",
       "      <th>lc_ind_aval_fin_ult1</th>\n",
       "      <th>lc_ind_cco_fin_ult1</th>\n",
       "      <th>lc_ind_cder_fin_ult1</th>\n",
       "      <th>lc_ind_cno_fin_ult1</th>\n",
       "      <th>lc_ind_ctju_fin_ult1</th>\n",
       "      <th>lc_ind_ctma_fin_ult1</th>\n",
       "      <th>lc_ind_ctop_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>lc_ind_hip_fin_ult1</th>\n",
       "      <th>lc_ind_plan_fin_ult1</th>\n",
       "      <th>lc_ind_pres_fin_ult1</th>\n",
       "      <th>lc_ind_reca_fin_ult1</th>\n",
       "      <th>lc_ind_tjcr_fin_ult1</th>\n",
       "      <th>lc_ind_valo_fin_ult1</th>\n",
       "      <th>lc_ind_viv_fin_ult1</th>\n",
       "      <th>lc_ind_nomina_ult1</th>\n",
       "      <th>lc_ind_nom_pens_ult1</th>\n",
       "      <th>lc_ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4338256</th>\n",
       "      <td>15892</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338245</th>\n",
       "      <td>15903</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338244</th>\n",
       "      <td>15906</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338242</th>\n",
       "      <td>15908</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338240</th>\n",
       "      <td>15911</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338260</th>\n",
       "      <td>15919</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338262</th>\n",
       "      <td>15921</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338284</th>\n",
       "      <td>15925</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338280</th>\n",
       "      <td>15929</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4338275</th>\n",
       "      <td>15935</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers  fecha_dato  lc_ind_ahor_fin_ult1  lc_ind_aval_fin_ult1  \\\n",
       "4338256     15892  2016-05-28                   0.0                   0.0   \n",
       "4338245     15903  2016-05-28                   0.0                   0.0   \n",
       "4338244     15906  2016-05-28                   0.0                   0.0   \n",
       "4338242     15908  2016-05-28                   0.0                   0.0   \n",
       "4338240     15911  2016-05-28                   0.0                   0.0   \n",
       "4338260     15919  2016-05-28                   0.0                   0.0   \n",
       "4338262     15921  2016-05-28                   0.0                   0.0   \n",
       "4338284     15925  2016-05-28                   0.0                   0.0   \n",
       "4338280     15929  2016-05-28                   0.0                   0.0   \n",
       "4338275     15935  2016-05-28                   0.0                   0.0   \n",
       "\n",
       "         lc_ind_cco_fin_ult1  lc_ind_cder_fin_ult1  lc_ind_cno_fin_ult1  \\\n",
       "4338256                  1.0                   0.0                  0.0   \n",
       "4338245                  1.0                   0.0                  0.0   \n",
       "4338244                  0.0                   0.0                  1.0   \n",
       "4338242                  1.0                   0.0                  1.0   \n",
       "4338240                  0.0                   0.0                  1.0   \n",
       "4338260                  1.0                   0.0                  0.0   \n",
       "4338262                  1.0                   0.0                  0.0   \n",
       "4338284                  1.0                   0.0                  0.0   \n",
       "4338280                  1.0                   0.0                  0.0   \n",
       "4338275                  1.0                   0.0                  0.0   \n",
       "\n",
       "         lc_ind_ctju_fin_ult1  lc_ind_ctma_fin_ult1  lc_ind_ctop_fin_ult1  \\\n",
       "4338256                   0.0                   0.0                   0.0   \n",
       "4338245                   0.0                   0.0                   1.0   \n",
       "4338244                   0.0                   0.0                   1.0   \n",
       "4338242                   0.0                   0.0                   0.0   \n",
       "4338240                   0.0                   0.0                   0.0   \n",
       "4338260                   0.0                   0.0                   0.0   \n",
       "4338262                   0.0                   0.0                   1.0   \n",
       "4338284                   0.0                   0.0                   1.0   \n",
       "4338280                   0.0                   0.0                   0.0   \n",
       "4338275                   0.0                   0.0                   1.0   \n",
       "\n",
       "                ...          lc_ind_hip_fin_ult1  lc_ind_plan_fin_ult1  \\\n",
       "4338256         ...                          0.0                   0.0   \n",
       "4338245         ...                          0.0                   0.0   \n",
       "4338244         ...                          0.0                   0.0   \n",
       "4338242         ...                          0.0                   1.0   \n",
       "4338240         ...                          0.0                   0.0   \n",
       "4338260         ...                          0.0                   0.0   \n",
       "4338262         ...                          0.0                   1.0   \n",
       "4338284         ...                          0.0                   0.0   \n",
       "4338280         ...                          0.0                   0.0   \n",
       "4338275         ...                          0.0                   0.0   \n",
       "\n",
       "         lc_ind_pres_fin_ult1  lc_ind_reca_fin_ult1  lc_ind_tjcr_fin_ult1  \\\n",
       "4338256                   0.0                   1.0                   1.0   \n",
       "4338245                   0.0                   0.0                   1.0   \n",
       "4338244                   0.0                   0.0                   0.0   \n",
       "4338242                   0.0                   0.0                   1.0   \n",
       "4338240                   0.0                   0.0                   1.0   \n",
       "4338260                   0.0                   1.0                   0.0   \n",
       "4338262                   0.0                   0.0                   1.0   \n",
       "4338284                   0.0                   0.0                   1.0   \n",
       "4338280                   0.0                   0.0                   1.0   \n",
       "4338275                   0.0                   0.0                   0.0   \n",
       "\n",
       "         lc_ind_valo_fin_ult1  lc_ind_viv_fin_ult1  lc_ind_nomina_ult1  \\\n",
       "4338256                   1.0                  0.0                 0.0   \n",
       "4338245                   0.0                  0.0                 0.0   \n",
       "4338244                   0.0                  0.0                 0.0   \n",
       "4338242                   1.0                  0.0                 1.0   \n",
       "4338240                   1.0                  0.0                 0.0   \n",
       "4338260                   0.0                  0.0                 0.0   \n",
       "4338262                   1.0                  0.0                 0.0   \n",
       "4338284                   0.0                  0.0                 0.0   \n",
       "4338280                   1.0                  0.0                 0.0   \n",
       "4338275                   0.0                  0.0                 0.0   \n",
       "\n",
       "         lc_ind_nom_pens_ult1  lc_ind_recibo_ult1  \n",
       "4338256                   0.0                 1.0  \n",
       "4338245                   0.0                 0.0  \n",
       "4338244                   1.0                 1.0  \n",
       "4338242                   1.0                 1.0  \n",
       "4338240                   0.0                 1.0  \n",
       "4338260                   0.0                 1.0  \n",
       "4338262                   0.0                 1.0  \n",
       "4338284                   0.0                 1.0  \n",
       "4338280                   0.0                 0.0  \n",
       "4338275                   0.0                 1.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print clients_last_choice.shape\n",
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another train/predict + CV implementation\n",
    "\n",
    "### Input\n",
    "\n",
    "- `X` : `[nb_samples, nb_features]` shaped pd.DataFrame\n",
    "    - `features_masks_list` : `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "    \n",
    "- `Y` : `[nb_samples, nb_labels]` shaped pd.DataFrame\n",
    "    - `labels_masks_list` : `{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "\n",
    "- `samples_masks_list` : `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "\n",
    "\n",
    "- Set of models `models` : list of functions to create a model, e.g. `[create_RF, create_NN, create_GBT]`\n",
    "\n",
    "\n",
    "### Training phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_masks_list = [\n",
    "#    lambda x:  ~(x['targets_diff'].isin([0])), \n",
    "   lambda x:  (x['targets_diff'] > 0), \n",
    "   lambda x:  (x['targets_diff'] < 0), \n",
    "]\n",
    "\n",
    "TARGET_LABELS_FRQ_PREV = [c + '_prev' for c in TARGET_LABELS_FRQ]\n",
    "\n",
    "features_masks_dict = {\n",
    "#     'fm_all': None,\n",
    "    'fm0': features + target_features + TARGET_LABELS_FRQ.tolist() + TARGET_LABELS_FRQ_PREV,\n",
    "    'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm2': target_features,\n",
    "    'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "    'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "    'fm6': TARGET_LABELS_FRQ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "# https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "def create_RF(input_shape, output_shape):        \n",
    "    return RandomForestClassifier(n_estimators=20, \n",
    "#                                   min_samples_split=100,\n",
    "#                                   min_samples_leaf=50,\n",
    "#                                   max_depth=10\n",
    "                                 )\n",
    "\n",
    "def create_ET(input_shape, output_shape):\n",
    "    return ExtraTreesClassifier(n_estimators=20, \n",
    "#                                 max_depth=10\n",
    "                               )\n",
    "\n",
    "def create_GB(input_shape, output_shape):\n",
    "    return GradientBoostingClassifier(n_estimators=75)\n",
    "\n",
    "models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "    'gb': create_GB,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ('Saving Account', 'ind_ahor_fin_ult1')\n",
      "1 ('Guarantees', 'ind_aval_fin_ult1')\n",
      "2 ('Current Accounts', 'ind_cco_fin_ult1')\n",
      "3 ('Derivada Account', 'ind_cder_fin_ult1')\n",
      "4 ('Payroll Account', 'ind_cno_fin_ult1')\n",
      "5 ('Junior Account', 'ind_ctju_fin_ult1')\n",
      "6 ('Mas particular Account', 'ind_ctma_fin_ult1')\n",
      "7 ('particular Account', 'ind_ctop_fin_ult1')\n",
      "8 ('particular Plus Account', 'ind_ctpp_fin_ult1')\n",
      "9 ('Short-term deposits', 'ind_deco_fin_ult1')\n",
      "10 ('Medium-term deposits', 'ind_deme_fin_ult1')\n",
      "11 ('Long-term deposits', 'ind_dela_fin_ult1')\n",
      "12 ('e-account', 'ind_ecue_fin_ult1')\n",
      "13 ('Funds', 'ind_fond_fin_ult1')\n",
      "14 ('Mortgage', 'ind_hip_fin_ult1')\n",
      "15 ('Pensions (plan fin)', 'ind_plan_fin_ult1')\n",
      "16 ('Loans', 'ind_pres_fin_ult1')\n",
      "17 ('Taxes', 'ind_reca_fin_ult1')\n",
      "18 ('Credit Card', 'ind_tjcr_fin_ult1')\n",
      "19 ('Securities', 'ind_valo_fin_ult1')\n",
      "20 ('Home Account', 'ind_viv_fin_ult1')\n",
      "21 ('Payroll', 'ind_nomina_ult1')\n",
      "22 ('Pensions', 'ind_nom_pens_ult1')\n",
      "23 ('Direct Debit', 'ind_recibo_ult1')\n",
      "{'lm_12': array(['ind_nomina_ult1'], \n",
      "      dtype='|S17'), 'lm_13': array(['ind_nom_pens_ult1'], \n",
      "      dtype='|S17'), 'lm_10': array(['ind_tjcr_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_11': array(['ind_ecue_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_16': array(['ind_reca_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_14': array(['ind_recibo_ult1'], \n",
      "      dtype='|S17'), 'lm_15': array(['ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctop_fin_ult1',\n",
      "       'ind_ctpp_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_8': array(['ind_tjcr_fin_ult1', 'ind_recibo_ult1', 'ind_nomina_ult1',\n",
      "       'ind_nom_pens_ult1'], \n",
      "      dtype='|S17'), 'lm_9': array(['ind_nomina_ult1', 'ind_recibo_ult1', 'ind_nom_pens_ult1',\n",
      "       'ind_cno_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_others': array(['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_deco_fin_ult1',\n",
      "       'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_fond_fin_ult1',\n",
      "       'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1',\n",
      "       'ind_valo_fin_ult1', 'ind_viv_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_0': array(['ind_cco_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_1': array(['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1',\n",
      "       'ind_ctju_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_2': array(['ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n",
      "       'ind_ecue_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_3': array(['ind_cco_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_recibo_ult1'], \n",
      "      dtype='|S17'), 'lm_4': array(['ind_nomina_ult1', 'ind_nom_pens_ult1'], \n",
      "      dtype='|S17'), 'lm_5': array(['ind_cco_fin_ult1', 'ind_ecue_fin_ult1', 'ind_tjcr_fin_ult1'], \n",
      "      dtype='|S17'), 'lm_6': array(['ind_cco_fin_ult1', 'ind_ecue_fin_ult1', 'ind_recibo_ult1'], \n",
      "      dtype='|S17'), 'lm_7': array(['ind_cco_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_recibo_ult1'], \n",
      "      dtype='|S17')}\n"
     ]
    }
   ],
   "source": [
    "common_groups = [\n",
    "    [2, ],\n",
    "    [2, 3, 4, 5],\n",
    "    [6, 7, 8, 12],\n",
    "    [2, 18, 23], \n",
    "    [21, 22],\n",
    "    [2, 12, 18],\n",
    "    [2, 12, 23],\n",
    "    [2, 18, 23],\n",
    "    [18, 23, 21, 22],\n",
    "    [21, 23, 22, 4],\n",
    "    [18, ],\n",
    "    [12, ],\n",
    "    [21, ],\n",
    "    [22, ],\n",
    "    [23, ],\n",
    "    [3, 4, 7, 8],\n",
    "    [17, ],\n",
    "#     [i] for i in range(24)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def flatten(array):\n",
    "    out = []\n",
    "    for item in array:\n",
    "        out += item\n",
    "    return out\n",
    "\n",
    "others = list(set(range(24)) - set(flatten(common_groups)))\n",
    "NP_TARGET_LABELS = np.array(TARGET_LABELS)\n",
    "\n",
    "for i, a in enumerate(zip(TARGET_LABELS2, TARGET_LABELS)):\n",
    "    print i, a\n",
    "    \n",
    "s = set({})\n",
    "labels_masks_dict = {}\n",
    "for i, g in enumerate(common_groups):\n",
    "    labels_masks_dict['lm_%i' % i] = NP_TARGET_LABELS[g]\n",
    "    s |= set(g)\n",
    "labels_masks_dict['lm_others'] = NP_TARGET_LABELS[others]\n",
    "s |= set(others)\n",
    "\n",
    "assert len(s) == len(TARGET_LABELS), \"Sum is not equal 24, s=%i\" % s\n",
    "print labels_masks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'et': [(None, 'lm_15'),\n",
       "  (None, 'lm_8'),\n",
       "  (None, 'lm_9'),\n",
       "  (None, 'lm_others'),\n",
       "  (None, 'lm_1'),\n",
       "  (None, 'lm_2'),\n",
       "  (None, 'lm_3'),\n",
       "  (None, 'lm_4'),\n",
       "  (None, 'lm_5'),\n",
       "  (None, 'lm_6'),\n",
       "  (None, 'lm_7')],\n",
       " 'gb': [(None, 'lm_12'),\n",
       "  (None, 'lm_13'),\n",
       "  (None, 'lm_10'),\n",
       "  (None, 'lm_11'),\n",
       "  (None, 'lm_16'),\n",
       "  (None, 'lm_14'),\n",
       "  (None, 'lm_0')],\n",
       " 'rf': [(None, 'lm_15'),\n",
       "  (None, 'lm_8'),\n",
       "  (None, 'lm_9'),\n",
       "  (None, 'lm_others'),\n",
       "  (None, 'lm_1'),\n",
       "  (None, 'lm_2'),\n",
       "  (None, 'lm_3'),\n",
       "  (None, 'lm_4'),\n",
       "  (None, 'lm_5'),\n",
       "  (None, 'lm_6'),\n",
       "  (None, 'lm_7')]}"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_pipelines = {\n",
    "    'gb' : [(None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) == 1],\n",
    "    'rf' : [(None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "    'et' : [(None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "}\n",
    "models_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import train_all, predict_all, probas_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000, 75) (110000, 27) (110000, 26)\n",
      "(39985, 75) (39985, 27) (39985, 26)\n"
     ]
    }
   ],
   "source": [
    "ll = 110000\n",
    "mask = X.index.isin(X.index[:ll])\n",
    "\n",
    "X1 = X[mask]\n",
    "Y1 = Y[mask]\n",
    "clc = clients_last_choice[mask]\n",
    "print X1.shape, Y1.shape, clc.shape\n",
    "\n",
    "mask = X.index.isin(X.index[ll:ll+ll//2])\n",
    "X2 = X[mask]\n",
    "Y2 = Y[mask]\n",
    "clc2 = clients_last_choice[mask]\n",
    "print X2.shape, Y2.shape, clc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_kwargs = {'samples_masks_list': samples_masks_list, \n",
    "            'features_masks_dict': features_masks_dict, \n",
    "            'labels_masks_dict': labels_masks_dict, \n",
    "            'models_dict': models_dict,\n",
    "            'labels': TARGET_LABELS,\n",
    "            'transform_proba_func': probas_to_indices,\n",
    "            'threshold': 0.0,\n",
    "            'n_highest': 7,\n",
    "            'mode': 'sum',\n",
    "            'verbose': False,\n",
    "            'models_pipelines': models_pipelines,\n",
    "            'return_probas': True\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.886840\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.878258\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.820089\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.948506\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.972346\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.812142\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.909727\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.909091\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.667832\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.667514\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.737444\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.735537\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.941195\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.938334\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.875079\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.884298\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.888112\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.933884\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.934520\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.665289\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.665289\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.909409\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.906230\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.762873\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.759695\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.745709\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.745073\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.665289\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.664654\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.736809\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.719326\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748887\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.668468\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.739034\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.649396\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.557216\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.557216\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.512079\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.503814\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.524793\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.520343\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.742212\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.739034\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.629371\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.650668\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.671647\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.522250\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.525429\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.488239\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.486332\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.781945\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.778767\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.507629\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.515893\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.468214\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.472664\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.488239\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.493325\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.740941\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.718690\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.744437\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.699936\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.740305\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.626510\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.468214\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.467260\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.401144\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.393833\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.419263\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.413223\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.724094\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.723776\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.613477\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.555626\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.584870\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.467260\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.472346\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.355690\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.356325\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.750477\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.750159\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.416720\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.425302\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.348379\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.357915\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.355690\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.362047\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.958042\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.957406\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.923077\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993961\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.885251\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997457\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993007\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995868\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998411\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.983471\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999364\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997775\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994914\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997775\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995550\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996821\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994278\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737444\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.717419\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.744755\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.697076\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737444\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.647171\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.411952\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.410998\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.328989\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.324539\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.332486\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.328989\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.695168\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.695804\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.610617\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.547362\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.545137\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.412905\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.414177\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.290528\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.287349\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.721551\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.721233\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.373172\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.373490\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.281627\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.282899\n",
      "INFO:root:-- Process : sample_mask=3146/110000, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.290528\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.290528\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.844867\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.818839\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.856641\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.949804\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.967982\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.825036\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.899814\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.898988\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.612890\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.612890\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.651931\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.649866\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.927288\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.925842\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.874613\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.867383\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.867383\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.933485\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.932452\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.679405\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.679405\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.798595\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.795290\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.757075\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.756455\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.742202\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.741582\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.679405\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.677339\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.759967\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.651312\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.754596\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.649039\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737038\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.611857\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.526338\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.528403\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.453832\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.444949\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.443297\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.432555\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.761000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.760380\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.571163\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.579219\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.609172\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.515596\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.517042\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.440818\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.443503\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.707705\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.699649\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.453419\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.459616\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.413344\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.420574\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.440818\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.448461\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.759347\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.673001\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.753563\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.696963\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738277\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.571783\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.460855\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.460442\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.385458\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.375336\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.385044\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.377815\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.746953\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.744887\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.587275\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.492667\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.511051\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.478414\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.479033\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.339806\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.338153\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.701921\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.696344\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.386697\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.388143\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.326999\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.325346\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.339806\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.339393\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944640\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944640\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.920471\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.992357\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.878537\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998761\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.989672\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994836\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999174\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.982029\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998554\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998347\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995249\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998141\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996901\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996901\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993596\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.758728\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.680438\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.754183\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.695724\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738277\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.603594\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.428424\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.425532\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.303450\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.299525\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.294361\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.292295\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.729808\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.729808\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.584590\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.488949\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.474695\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.450114\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.450940\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.272258\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.271845\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.670936\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.670936\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.341665\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.341252\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.261723\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.260277\n",
      "INFO:root:-- Process : sample_mask=4841/110000, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.272258\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.269779\n"
     ]
    }
   ],
   "source": [
    "estimators = train_all(X1, Y1, **_kwargs)\n",
    "\n",
    "#print estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predict all --\n"
     ]
    }
   ],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "#print y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Y_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Compute max map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0302613480055\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0218204961781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.021820496178130314"
      ]
     },
     "execution_count": 644,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val = targets_str_to_indices(Y2[TARGET_LABELS].values)\n",
    "\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "map7_score(y_val, y_val, clc2[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute map7 score\")\n",
    "map7_score(y_val, y_preds, clc2[LC_TARGET_LABELS].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.0211362663776694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print labels_masks_dict[estimators[0][0][1]]\n",
    "# print estimators[0][1].classes_\n",
    "# print estimators[0][1].n_classes_\n",
    "# print estimators[0][1].n_features_\n",
    "# print estimators[0][1].n_outputs_\n",
    "# print estimators[0][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import targets_to_labels, targets_indices_to_labels, remove_last_choice\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Count =  1\n",
      "['Credit Card']\n",
      "['particular Account'] ['Direct Debit', 'Current Accounts', 'e-account', 'Payroll Account', 'Pensions', 'Payroll', 'particular Account']\n",
      "--- Count =  2\n",
      "['Taxes']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Pensions', 'Current Accounts', 'Payroll', 'e-account', 'particular Account']\n",
      "--- Count =  3\n",
      "['Credit Card']\n",
      "['Current Accounts', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'e-account', 'Pensions', 'Payroll', 'particular Account']\n",
      "--- Count =  4\n",
      "['Credit Card']\n",
      "['Direct Debit', 'particular Account', 'Payroll Account'] ['Current Accounts', 'Direct Debit', 'e-account', 'particular Account', 'Payroll Account']\n",
      "--- Count =  5\n",
      "['Credit Card']\n",
      "['Current Accounts'] ['Direct Debit', 'e-account', 'Payroll Account', 'Pensions', 'Current Accounts', 'Payroll', 'Funds']\n",
      "--- Count =  6\n",
      "['Credit Card']\n",
      "['Payroll Account', 'e-account', 'Pensions'] ['Direct Debit', 'Current Accounts', 'Payroll Account', 'e-account', 'Funds', 'Securities', 'Pensions']\n",
      "--- Count =  7\n",
      "['Credit Card']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'Payroll', 'e-account', 'particular Account']\n",
      "--- Count =  8\n",
      "['Credit Card']\n",
      "['Payroll Account', 'e-account', 'Pensions'] ['Direct Debit', 'Current Accounts', 'Payroll Account', 'e-account', 'Securities', 'Funds', 'Pensions']\n",
      "--- Count =  9\n",
      "['Credit Card']\n",
      "['Current Accounts', 'Long-term deposits'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'e-account', 'Pensions', 'Payroll', 'Long-term deposits']\n",
      "--- Count =  10\n",
      "['Credit Card']\n",
      "['Payroll Account', 'Pensions'] ['Current Accounts', 'Direct Debit', 'e-account', 'Payroll Account', 'Securities', 'Funds', 'Pensions']\n",
      "--- Count =  11\n",
      "['Credit Card']\n",
      "['Payroll Account', 'e-account', 'Pensions', 'Payroll', 'Long-term deposits'] ['Direct Debit', 'Current Accounts', 'Payroll Account', 'e-account', 'Pensions', 'Payroll', 'Long-term deposits']\n",
      "--- Count =  12\n",
      "['Credit Card']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'Payroll', 'e-account', 'particular Account']\n",
      "--- Count =  13\n",
      "['Credit Card']\n",
      "['Payroll Account', 'Long-term deposits', 'particular Account', 'Pensions'] ['Direct Debit', 'Current Accounts', 'e-account', 'Payroll Account', 'Long-term deposits', 'particular Account', 'Pensions']\n",
      "--- Count =  14\n",
      "['Credit Card']\n",
      "['Current Accounts', 'Pensions', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'Pensions (plan fin)', 'e-account', 'particular Account']\n",
      "--- Count =  15\n",
      "['Credit Card']\n",
      "['Direct Debit', 'Current Accounts', 'e-account', 'Pensions', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'e-account', 'Pensions', 'Long-term deposits', 'particular Account']\n",
      "--- Count =  16\n",
      "['Payroll', 'Pensions']\n",
      "['particular Account', 'Payroll Account'] ['Current Accounts', 'Direct Debit', 'particular Account', 'Payroll Account']\n",
      "--- Count =  17\n",
      "['Taxes']\n",
      "['Direct Debit', 'particular Account', 'Payroll Account'] ['Current Accounts', 'Direct Debit', 'particular Account', 'Payroll Account']\n",
      "--- Count =  18\n",
      "['Credit Card']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Pensions', 'Payroll', 'Current Accounts', 'e-account', 'particular Account']\n",
      "--- Count =  19\n",
      "['Credit Card']\n",
      "['Direct Debit', 'particular Account', 'Payroll Account', 'Pensions'] ['Current Accounts', 'Direct Debit', 'e-account', 'particular Account', 'Payroll Account', 'Pensions', 'Long-term deposits']\n",
      "--- Count =  20\n",
      "['Credit Card']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'Payroll', 'e-account', 'particular Account']\n",
      "--- Count =  21\n",
      "['Credit Card']\n",
      "['Current Accounts', 'Long-term deposits'] ['Direct Debit', 'Payroll Account', 'e-account', 'Pensions', 'Payroll', 'Current Accounts', 'Long-term deposits']\n",
      "--- Count =  22\n",
      "['Credit Card']\n",
      "['Payroll Account', 'Pensions', 'e-account', 'Securities', 'Payroll'] ['Direct Debit', 'Current Accounts', 'Payroll Account', 'Pensions', 'e-account', 'Securities', 'Payroll']\n",
      "--- Count =  23\n",
      "['Payroll']\n",
      "['Current Accounts', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'e-account', 'particular Account']\n",
      "--- Count =  24\n",
      "['Taxes']\n",
      "['Direct Debit', 'Current Accounts', 'Pensions', 'e-account', 'particular Account'] ['Direct Debit', 'Payroll Account', 'Current Accounts', 'Pensions', 'e-account', 'particular Account']\n"
     ]
    }
   ],
   "source": [
    "limit = 25\n",
    "count = 0\n",
    "\n",
    "not_predicted_predicted = defaultdict(int)\n",
    "for last_choice, targets, products, proba in zip(clc2[LC_TARGET_LABELS].values, y_val, y_preds, Y_probas.values):\n",
    "    added_products = remove_last_choice(targets, last_choice)\n",
    "    predictions = remove_last_choice(products, last_choice)\n",
    "    \n",
    "    if len(added_products) == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(set(added_products) & set(predictions)) > 0:\n",
    "#         print \"Predicted : \", added_products, predictions\n",
    "#         print set(added_products) & set(predictions)\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    if count < limit:\n",
    "        print \"--- Count = \", count\n",
    "        print targets_indices_to_labels(added_products, TARGET_LABELS2)#, targets_indices_to_labels(targets, TARGET_LABELS2)\n",
    "        print targets_indices_to_labels(predictions, TARGET_LABELS2), targets_indices_to_labels(products, TARGET_LABELS2)#, proba\n",
    "    \n",
    "    for p in added_products:\n",
    "        not_predicted_predicted[TARGET_LABELS2[p]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'e-account': 1, 'Payroll': 10, 'Pensions': 8, 'Taxes': 16, 'Securities': 2, 'Credit Card': 52}) 39985\n"
     ]
    }
   ],
   "source": [
    "print not_predicted_predicted, y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_probas[:10, target_groups[0]]\n",
    "#print Y[np.array(TARGET_LABELS)[target_groups[0]]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KFold Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Cross validation : \n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 1 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.871778\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.863080\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.870490\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.942977\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968750\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.779961\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.899485\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.898840\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.638853\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.638853\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.675902\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.674291\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.952320\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.950709\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.848905\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.834729\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.839884\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.939111\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.938789\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.621456\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.619523\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.886598\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.885631\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.750966\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.748711\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.673325\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.674291\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.621456\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.622101\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.759343\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.749356\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.828930\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738724\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.827964\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.639175\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.695876\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.694265\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.603737\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.596005\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.595361\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.590206\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.857603\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.854381\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.622745\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.676869\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.713273\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.707152\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.704897\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.557668\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.557023\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.827964\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.825387\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.600193\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.601160\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.540915\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.543814\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.557668\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.559923\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.758376\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748711\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.826031\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.754188\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.826353\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.610180\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.597938\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.597294\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.461018\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.453286\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.441044\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.429768\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.838918\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.838595\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.604381\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.564755\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.578286\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.649162\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.651740\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.396907\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.391430\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.774807\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.774485\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.472938\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.477126\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.384021\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.386598\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.396907\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.395619\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956508\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.955541\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.953608\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.994201\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.879188\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999356\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995490\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996778\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999356\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.977126\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998067\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998389\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994523\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996778\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998389\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995812\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994201\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.758376\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748067\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.826031\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.754510\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.826031\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.635954\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.549291\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.549613\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.384343\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.382732\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.355348\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.356959\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.818299\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.817977\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.595039\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.558312\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.549936\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.611147\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.612113\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.319910\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.319265\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.750966\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.750966\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.420747\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.420103\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.306379\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.307345\n",
      "INFO:root:-- Process : sample_mask=3104/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.319910\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.322487\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.837402\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.811646\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.896081\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.941545\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968421\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.791041\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.890258\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.890034\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.590370\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.589474\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.599328\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.596193\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.948264\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.946697\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.832923\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.817469\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.821277\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.935946\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.936394\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.632475\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.630907\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.784099\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.783427\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.735722\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.735050\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.662710\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.662262\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.632475\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.631131\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.785890\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.716013\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.841209\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.732587\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.831131\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.621053\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.672788\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.671445\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.586338\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.576932\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.559239\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.546249\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.873908\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.873236\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.587234\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.622620\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.655543\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.696305\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.697648\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.543785\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.550504\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.778723\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.772676\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.574468\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.577380\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.516013\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.521837\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.543785\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.548936\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782755\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.718701\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.840314\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.745353\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.830011\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.583203\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.572452\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.572228\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.465398\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.455095\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.427324\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.418141\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.862038\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.861142\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.586562\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.477044\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.508623\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.636058\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.634714\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.387682\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.386338\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.746920\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.743561\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.451064\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.452632\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.355431\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.352296\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.387682\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.385218\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.943337\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944905\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.946697\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993281\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.883315\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999328\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.992161\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994401\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999776\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.977828\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998208\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999104\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996865\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997760\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996417\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994177\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993729\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782531\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.721165\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.840314\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748712\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.830235\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.608959\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.538634\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.537066\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.399328\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.399104\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.353415\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.356775\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.845241\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.845465\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.583427\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.466965\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.458231\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.615006\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.614782\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.329227\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.327660\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.720941\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.720717\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.397088\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.398656\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.299440\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.301008\n",
      "INFO:root:-- Process : sample_mask=4465/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.329227\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.324076\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0302291604822\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 2 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.876905\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.868838\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.865252\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944727\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.967434\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.790559\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.903794\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.902898\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.659994\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.659098\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.696445\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.697640\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.947714\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.946220\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.855692\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.846728\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.848521\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.938452\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.939647\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.640574\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.638781\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.895429\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.894831\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.758889\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.755901\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.691365\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.688079\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.640574\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.642068\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.752316\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738273\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.808186\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.719151\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.800120\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.654019\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.655214\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.652226\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.578130\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.574544\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.568569\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.562295\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.809083\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.805497\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.626531\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.668659\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.690170\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.655512\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.655512\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.539289\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.540783\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.813564\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.806991\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.576935\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.580520\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.518076\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.525246\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.539289\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.542575\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.753809\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737676\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.804601\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737974\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.800717\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.626830\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.567673\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.568569\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.448163\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.441589\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.434120\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.423663\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.796833\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.794443\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.605019\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.537795\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.564984\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.598446\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.601733\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.386615\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.394383\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.767852\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.766657\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.452943\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.461309\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.366298\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.368688\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.386615\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.385719\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.960860\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.959665\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.947714\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.994921\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999402\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.886167\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999402\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996116\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994323\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999701\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.979385\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998506\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999402\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993726\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999104\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996415\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996415\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995817\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.753511\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738273\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.806095\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.736779\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.799821\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.651031\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.520167\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.520765\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.385420\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.384523\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.360920\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.359426\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.772632\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.772931\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.603526\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.534210\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.536899\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.567673\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.568868\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.324470\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.324470\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.741858\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.741858\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.408724\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.408127\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.306244\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.306842\n",
      "INFO:root:-- Process : sample_mask=3347/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.324470\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.325366\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.841371\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.821044\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.887007\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944599\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968513\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.803308\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.897768\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.897170\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.603826\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.606018\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.622160\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.626544\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.936030\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.934635\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.850139\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.838581\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.840972\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.937226\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.937625\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.656038\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.655839\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.795536\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.793344\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.753886\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.753487\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.695297\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.694301\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.656038\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.656038\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.774213\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.678557\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.809685\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.693902\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.795337\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.632324\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.624751\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.621961\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.519131\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.507772\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.486250\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.478677\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.820845\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.819450\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.579115\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.597848\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.634516\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.633320\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.636110\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.504185\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.509167\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.739737\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.724990\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.519530\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.523515\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.475289\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.486648\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.504185\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.509566\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.771622\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.698485\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.810084\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.732563\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.796931\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.578318\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.542248\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.539259\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.422678\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.413113\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.405341\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.391590\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.808290\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.809486\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.580510\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.464727\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.501196\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.597848\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.599641\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.362894\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.364488\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.722599\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.718414\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.433440\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.431845\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.341770\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.344560\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.362894\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.362694\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944201\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944599\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.940415\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.994420\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.886010\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999203\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993224\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993623\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999601\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.977282\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998406\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999402\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993025\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998007\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996014\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995616\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993822\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.771821\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.702073\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.809087\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.735552\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.795536\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.617178\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.508171\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.506178\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.358709\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.355520\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.337385\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.332403\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.794340\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.793145\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.583300\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.456556\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.466521\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.579314\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.579514\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.310482\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.308689\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.701873\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.701873\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.377840\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.378238\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.292547\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.293743\n",
      "INFO:root:-- Process : sample_mask=5018/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.310482\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.307094\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0248171113408\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 3 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.879488\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.871973\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.853048\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.947119\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.969942\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.801837\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.902032\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.900640\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.661564\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.661008\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.709713\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.705260\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.949068\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.947398\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.861675\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.856109\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.856944\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.939048\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.938770\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.653771\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.650988\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.896465\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.895909\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.763707\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.760924\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.715558\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.712775\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.653771\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.652658\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.741163\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.724464\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.793487\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.708878\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.779293\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.656276\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.600056\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.600891\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.545505\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.535486\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.541887\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.533537\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.785694\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.783746\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.624826\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.642917\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.672419\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.604230\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.603952\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.513498\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.516560\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.792374\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.787364\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.544949\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.547732\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.489285\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.493738\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.513498\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.514612\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.740885\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.723908\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.791261\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.734762\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.778458\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.636515\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.520178\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.518230\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.428055\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.416643\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.413025\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.405232\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.770665\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.770944\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.603952\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.542165\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.562204\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.562204\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.563596\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.372391\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.372669\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.750348\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.749235\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.440301\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.439466\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.359310\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.362093\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.372391\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.373504\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.957696\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.959365\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.936265\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993320\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999443\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.877818\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998608\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993320\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997217\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997773\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.977456\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998330\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998330\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994712\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997773\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996104\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994990\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995547\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.741720\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.724186\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.792652\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.734762\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.777345\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.658781\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.469246\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.470637\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.367659\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.363763\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.352352\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.348177\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.747286\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.747008\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.604230\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.522405\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.538269\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.522126\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.522961\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.318119\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.315614\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.726412\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.725021\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.399388\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.399944\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.307264\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.309769\n",
      "INFO:root:-- Process : sample_mask=3593/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.318119\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.317562\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.843651\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.817252\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.885852\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.947388\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968210\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.817810\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.902212\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.901097\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.612010\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.611266\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.635062\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.632088\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.934932\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.934746\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.860383\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.849228\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.852203\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.937721\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.938093\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.668340\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.668712\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.795873\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.794386\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.760178\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.760550\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.710355\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.709054\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.668340\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.666481\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770775\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.669083\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.800521\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.684886\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782487\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.627998\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.587098\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.582264\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.493586\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.485220\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.472393\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.463655\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.802008\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.799591\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.573155\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.578732\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.596579\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.600297\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.600112\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.483733\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.489682\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.726529\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.721695\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.496375\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.503439\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.448596\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.455289\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.483733\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.490612\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770589\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.691950\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.799963\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.723183\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.783603\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.571854\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.507157\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.508087\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.415319\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.403235\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.395798\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.382785\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.784904\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.784347\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.586726\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.476669\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.493586\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.554936\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.557724\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.354341\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.357501\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.713144\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.707938\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.415505\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.416992\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.329429\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.328500\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.354341\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.352668\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944599\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944971\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.936234\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993493\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999814\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.883993\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999070\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.991262\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.992378\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999814\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.978621\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998885\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998327\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994051\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997769\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997769\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996654\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.992750\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770775\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.696412\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.800335\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.723926\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.781930\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.615728\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.475553\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.475367\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.341885\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.344488\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.322922\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.320692\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.771891\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.772634\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.590816\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.465514\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.485964\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.537832\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.537089\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.302101\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.295036\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.689719\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.689533\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.370329\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.374233\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.278862\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.277933\n",
      "INFO:root:-- Process : sample_mask=5379/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.302101\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.298197\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0179218781667\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 4 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.882927\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.873984\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.840108\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944173\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.970461\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.806504\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.905962\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.903523\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.665583\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.663686\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.723848\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.722222\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.939837\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.939566\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.865312\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.862602\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.864499\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.933333\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.933333\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.655556\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.655556\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.901084\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.900000\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.756369\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.755827\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.720054\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.719241\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.655556\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.653930\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.747425\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.730352\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.778591\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.712195\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.768835\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.643360\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.589160\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.589431\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.544173\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.533333\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.541463\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.542276\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.773171\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.768022\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.622222\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.656369\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.688076\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.582385\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.581843\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.507859\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.509756\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.794580\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.791870\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.540921\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.553117\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.486721\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.493496\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.507859\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.512737\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748780\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.731165\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.776423\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738482\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.768022\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.618699\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.501355\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.500813\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.413008\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.410027\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.412195\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.408130\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.751220\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.750678\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.604878\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.550136\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.577236\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.537398\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.538753\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.360976\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.359079\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.760705\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.760976\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.436585\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.440379\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.359079\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.360434\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.360976\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.361518\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.957182\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956640\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.934688\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.993496\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999187\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.884824\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998645\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995393\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996206\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999458\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.979675\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998374\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997832\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994851\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998916\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995935\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997290\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995935\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748238\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.731436\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.776694\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.738753\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.767480\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.649322\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.452846\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.452846\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.355285\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.354201\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.348238\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.349864\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.730081\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.730081\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.604065\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.537669\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.548238\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.497561\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.497832\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.304607\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.303794\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.734146\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.733604\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.394309\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.393496\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.301355\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.300542\n",
      "INFO:root:-- Process : sample_mask=3690/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.304607\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.303252\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.845204\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.818540\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.876700\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944345\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968325\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.817824\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.897280\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.897280\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.614352\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.613815\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.640838\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.639406\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.928239\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.927165\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.861847\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.850036\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.852362\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.931997\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.931818\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.671976\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.670365\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.799213\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.797065\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.753221\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.752863\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.717251\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.715999\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.671976\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.671439\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.771832\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.672155\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.789728\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.679134\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.767359\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.617215\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.569971\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.568898\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.495168\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.488010\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.479957\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.466535\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.786507\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.781496\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.573908\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.595741\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.615068\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.571403\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.571582\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.480852\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.482105\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.730852\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.726557\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.493021\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.495168\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.450966\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.461346\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.480852\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.481747\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.769506\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.689871\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.789191\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.716356\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770401\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.568361\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.484610\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.482105\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.403901\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.395669\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.389048\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.380816\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.768969\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.768074\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.582319\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.465820\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.492484\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.520401\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.523801\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.345383\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.344667\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.710272\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.707588\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.400859\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.400501\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.322835\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.323908\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.345383\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.345383\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944524\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.945598\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.932534\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.992126\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999821\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.883321\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998926\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993379\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993558\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.979420\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999105\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998210\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994273\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996779\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995347\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997137\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993558\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.769864\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.693092\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.789907\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.720472\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.768611\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.605047\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.463672\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.463314\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.333751\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.340551\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.315140\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.318540\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.755011\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.755369\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.593057\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.480852\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.484431\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.507337\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.506442\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.295455\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.295097\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.681102\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.694166\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.367037\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.367394\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.279528\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.280601\n",
      "INFO:root:-- Process : sample_mask=5588/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.295455\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.297960\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0169989684154\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 5 / 5\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.888263\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.881446\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.824541\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.949318\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.972140\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.807350\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.909306\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.907528\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.661529\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.660937\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.729105\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.729105\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.943391\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.943094\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.874926\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.880854\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.885003\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.935981\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.936277\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.659158\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.657973\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.907825\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.906935\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.762300\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.759336\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.738293\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.737404\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.659158\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.654713\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.737996\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.721695\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.757854\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.677534\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748074\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.647007\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.565205\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.561648\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.510966\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.507410\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.518672\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.515412\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.751037\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.744813\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.628927\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.651156\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.677830\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.540012\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.542087\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.487848\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.490516\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.784529\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.782454\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.512448\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.518969\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.465619\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.470065\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.487848\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.489330\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.741553\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.722881\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.753408\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.706580\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748963\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.630113\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.483699\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.483106\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.403972\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.398340\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.417605\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.415827\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.736218\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.734736\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.618554\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.565205\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.582098\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.488441\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.494369\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.361292\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.365442\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.750445\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.749259\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.424422\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.427386\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.351215\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.358032\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.361292\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.364552\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956135\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956728\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.924718\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.992887\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.882039\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998814\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993776\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993776\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999407\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.981921\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999407\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998814\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.992294\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998814\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996740\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994369\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994369\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.739182\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.721399\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.755187\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.704209\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.746888\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.647896\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.430053\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.430053\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.336692\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.332839\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.334025\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.330765\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.710136\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.710729\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.612626\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.552756\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.559573\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.439241\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.438352\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.295199\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.292531\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.724363\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.724363\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.381743\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.379075\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.286307\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.284232\n",
      "INFO:root:-- Process : sample_mask=3374/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.295199\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.295791\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.843594\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.817237\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.861100\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.949981\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968065\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.820508\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.900154\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.900539\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.605425\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.601962\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.641208\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.640246\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.930358\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.928049\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.869950\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.864371\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.865910\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.934783\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.934975\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.670835\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.671412\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.795498\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.793190\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.755483\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.755098\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.730666\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.730281\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.670835\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.670835\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.762024\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.653905\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.762601\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.659677\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.748365\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.610427\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.542709\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.543286\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.455560\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.445364\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.439977\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.425741\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.773759\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.771451\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.573875\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.583109\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.612351\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.536745\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.542324\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.444017\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.449211\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.708542\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.701424\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.455945\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.462678\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.415929\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.427087\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.444017\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.450173\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.761447\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.679107\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.762793\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.705848\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.750673\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.571374\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.471335\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.470566\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.386110\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.377838\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.379761\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.373028\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.760677\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.759331\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.586379\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.489611\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.510581\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.500962\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.501924\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.339554\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.342439\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.703540\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.701616\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.392074\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.397076\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.326087\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.324740\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.339554\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.346479\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.942093\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.943825\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.924202\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.992689\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.876683\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998846\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993651\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994806\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998653\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.980377\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998269\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999038\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995190\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998461\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994421\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.996922\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993459\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.761254\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.684302\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.762793\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.705079\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.749904\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.605040\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.443247\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.442285\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.308195\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.308580\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.301462\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.296268\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.744710\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.743940\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.587149\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.500385\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.495190\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.475568\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.476722\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.277414\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.277607\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.674875\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.671797\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.349750\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.349558\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.266064\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.264332\n",
      "INFO:root:-- Process : sample_mask=5198/119988, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.277414\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.274336\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0221402060841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation \n",
      " 5 | 0.016999 | 0.022421 | 0.022140 | 0.030229 | 0.00483 \n"
     ]
    }
   ],
   "source": [
    "nb_folds = 5\n",
    "results = cross_val_score((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                            nb_folds=nb_folds, **_kwargs)\n",
    "\n",
    "print \"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), np.median(results), results.max(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 201505 -> 201605 \n",
    "\n",
    "Cross-Validation \n",
    " 5 | 0.014585 | 0.018385 | 0.019147 | 0.022227 | 0.00294 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cross-validation across several months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_folds = 3\n",
    "yms = [201504, 201505]\n",
    "#yms = [201505]\n",
    "\n",
    "for ym in yms:\n",
    "    logging.info(\"\\n-------------------------\")\n",
    "    logging.info(\"- Process month : %s\" % ym)\n",
    "    logging.info(\"-------------------------\\n\")\n",
    "    \n",
    "    ym1 = ym + 100    \n",
    "    df1 = train_df if months_ym_map[ym] in train_months else val_df\n",
    "    df2 = train_df if months_ym_map[ym1] in train_months else val_df\n",
    "    X, Y, clients_last_choice = get_XY(ym, df1, ym1, df2) \n",
    "    results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                                profiles=profiles,\n",
    "                                nb_folds=nb_folds)\n",
    "    print \"Cross-Validation \\n %i | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), results.max(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df\n",
    "#df1 = val_df\n",
    "df2 = train_df #if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = val_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.878419\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.870002\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.850129\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944587\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.969605\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.797522\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.902502\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.901099\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.651157\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.649053\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.702361\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.698387\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.944120\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.943184\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.860182\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.854337\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.857844\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.935703\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.935936\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.640870\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.639233\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.895020\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.894552\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.753098\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.752864\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.704466\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.703063\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.640870\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.640402\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.747253\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.730652\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.791910\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.710545\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782558\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.643909\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.607201\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.607201\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.540566\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.533785\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.536123\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.528642\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.789105\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.784195\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.620762\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.649287\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.675006\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.605097\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.606266\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.504092\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.506430\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.796353\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.792378\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.541969\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.547346\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.481646\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.484452\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.504092\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.501286\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.747954\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.732055\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.789572\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.731588\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782792\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.621230\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.521861\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.523264\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.412439\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.406360\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.404723\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.397475\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.772270\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.773673\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.602058\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.545943\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.567454\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.556699\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.558335\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.358896\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.356325\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.755202\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.753799\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.433715\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.436755\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.347907\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.347674\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.358896\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.354454\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956044\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.956278\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.938041\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.994155\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999299\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.877017\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999299\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993921\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994389\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999532\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.977788\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998831\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998597\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995324\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998363\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997662\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995090\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994389\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.747720\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.731821\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.790274\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.732990\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782558\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.648352\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.480477\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.480243\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.361468\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.360065\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.345569\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.343699\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.753332\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.753332\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.601356\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.532383\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.553893\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.523264\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.525368\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.306056\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.306056\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.734627\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.734393\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.394903\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.394903\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.295534\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.297405\n",
      "INFO:root:-- Process : sample_mask=4277/149985, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.306056\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.305120\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.842327\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.817062\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.880381\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.944947\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.968185\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.809888\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.896756\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.895664\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.599969\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.597473\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.622271\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.621335\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.933094\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.931847\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.854803\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.844042\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.846070\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.934498\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.934966\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.656425\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.656114\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.791173\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.786650\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.748284\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.747661\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.701497\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.700405\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm6, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.656425\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.657049\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.772926\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.675140\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.798815\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.685434\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.782595\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.616032\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.582034\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.580942\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.490643\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.483157\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.467093\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.458203\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.805053\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.803182\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.573612\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.591547\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.609170\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.593107\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.593886\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.474267\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.475359\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.729102\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.723643\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.491734\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.492046\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.442608\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.448066\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm5, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.474267\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.478010\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770430\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.692920\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.798503\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.721460\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.784779\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.567218\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.503587\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.503743\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.405022\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.399563\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.384279\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.370243\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.791641\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.790393\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.580786\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.463038\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.481597\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.551622\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.555053\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.343575\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.343107\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.713038\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.708515\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.405022\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.407673\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.320961\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.324236\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm3, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.343575\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.341391\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.941672\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.943543\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.934810\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.992670\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.999844\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.880381\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999532\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.993606\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994386\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999220\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.978946\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998284\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.998908\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994541\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.997973\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995945\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.995165\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm0, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 1.000000\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.994541\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_12\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.770274\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_13\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.698066\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_10\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.798971\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_11\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.724891\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_16\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.783687\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_14\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.603400\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_15\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.480973\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.480193\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_8\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.338116\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.340611\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_9\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.316750\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.314410\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.779476\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.778852\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='gb', fit accuracy : 0.585465\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.464910\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.464910\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.539457\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.539301\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.297723\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.296787\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.690892\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.689956\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.367904\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.368216\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.279008\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.278072\n",
      "INFO:root:-- Process : sample_mask=6412/149985, features_mask=fm1, labels_mask=lm_7\n",
      "INFO:root:--- Score : model='et', fit accuracy : 0.297723\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.300374\n"
     ]
    }
   ],
   "source": [
    "estimators = train_all(X, Y, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predict all --\n"
     ]
    }
   ],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check score on the data 2016/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.35228393896\n",
      "INFO:root:- Compute max map7 score\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35228393896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predicted map7 score: 0.488183068651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.488183068651\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"- Compute map7 score\")\n",
    "print map7_score(y_val, y_preds, clients_last_choice[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "print map7_score(y_val, y_val, clients_last_choice[LC_TARGET_LABELS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for 2016/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load training data : \n",
      "INFO:root:- Load data : [201505, 201506]\n",
      "INFO:root:-- Select max clients\n",
      "INFO:root:- Number of lines with unknown data : 3716\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:-- Process date : 201506\n",
      "INFO:root:-- Add logCount columns\n",
      "INFO:root:-- Process month : 2015-05-28\n",
      "INFO:root:-- Process month : 2015-06-28\n",
      "INFO:root:-- Add logDecimal columns\n",
      "INFO:root:-- Transform age/renta/logdiff\n",
      "INFO:root:-- Add target frequencies\n",
      "INFO:root:-- Add target diff\n",
      "INFO:root:- Load test data : \n",
      "INFO:root:- Load data : [201605]\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:- Load data : []\n",
      "INFO:root:-- Read all data from the file : ../data/test_ver2.csv\n",
      "INFO:root:- Number of lines with unknown data : 0\n",
      "INFO:root:- Number of columns with nan : 10\n",
      "INFO:root:-- Process date : 201606\n",
      "INFO:root:-- Add target frequencies\n"
     ]
    }
   ],
   "source": [
    "full_train_df, test_df = load_train_test([201506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>sexo</th>\n",
       "      <th>age</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>ind_nuevo</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>indrel</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_diff</th>\n",
       "      <th>ind_plan_fin_ult1_diff</th>\n",
       "      <th>ind_pres_fin_ult1_diff</th>\n",
       "      <th>ind_reca_fin_ult1_diff</th>\n",
       "      <th>ind_tjcr_fin_ult1_diff</th>\n",
       "      <th>ind_valo_fin_ult1_diff</th>\n",
       "      <th>ind_viv_fin_ult1_diff</th>\n",
       "      <th>ind_nomina_ult1_diff</th>\n",
       "      <th>ind_nom_pens_ult1_diff</th>\n",
       "      <th>ind_recibo_ult1_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631955</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053410</th>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631956</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053333</th>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>15890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421295</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15892</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "      <td>-99999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         fecha_dato  ncodpers  ind_empleado  pais_residencia  sexo  age  \\\n",
       "631955   2015-05-28     15889             2                0     1    9   \n",
       "1053410  2015-06-28     15889             2                0     1    9   \n",
       "631956   2015-05-28     15890             1                0     1   11   \n",
       "1053333  2015-06-28     15890             1                0     1   11   \n",
       "421295   2015-05-28     15892             2                0     0   11   \n",
       "\n",
       "         fecha_alta  ind_nuevo  antiguedad  indrel          ...           \\\n",
       "631955   1995-01-16          0         244     1.0          ...            \n",
       "1053410  1995-01-16          0         245     1.0          ...            \n",
       "631956   1995-01-16          0         244     1.0          ...            \n",
       "1053333  1995-01-16          0         245     1.0          ...            \n",
       "421295   1995-01-16          0         244     1.0          ...            \n",
       "\n",
       "         ind_hip_fin_ult1_diff  ind_plan_fin_ult1_diff  \\\n",
       "631955                -99999.0                -99999.0   \n",
       "1053410                    0.0                     0.0   \n",
       "631956                -99999.0                -99999.0   \n",
       "1053333                    0.0                     0.0   \n",
       "421295                -99999.0                -99999.0   \n",
       "\n",
       "         ind_pres_fin_ult1_diff  ind_reca_fin_ult1_diff  \\\n",
       "631955                 -99999.0                -99999.0   \n",
       "1053410                     0.0                     0.0   \n",
       "631956                 -99999.0                -99999.0   \n",
       "1053333                     0.0                     0.0   \n",
       "421295                 -99999.0                -99999.0   \n",
       "\n",
       "         ind_tjcr_fin_ult1_diff  ind_valo_fin_ult1_diff  \\\n",
       "631955                 -99999.0                -99999.0   \n",
       "1053410                     0.0                     0.0   \n",
       "631956                 -99999.0                -99999.0   \n",
       "1053333                     0.0                     0.0   \n",
       "421295                 -99999.0                -99999.0   \n",
       "\n",
       "         ind_viv_fin_ult1_diff  ind_nomina_ult1_diff  ind_nom_pens_ult1_diff  \\\n",
       "631955                -99999.0              -99999.0                -99999.0   \n",
       "1053410                    0.0                   0.0                     0.0   \n",
       "631956                -99999.0              -99999.0                -99999.0   \n",
       "1053333                    0.0                   0.0                     0.0   \n",
       "421295                -99999.0              -99999.0                -99999.0   \n",
       "\n",
       "         ind_recibo_ult1_diff  \n",
       "631955               -99999.0  \n",
       "1053410                   0.0  \n",
       "631956               -99999.0  \n",
       "1053333                   0.0  \n",
       "421295               -99999.0  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>antiguedad</th>\n",
       "      <th>canal_entrada</th>\n",
       "      <th>conyuemp</th>\n",
       "      <th>fecha_alta</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ind_actividad_cliente</th>\n",
       "      <th>ind_ahor_fin_ult1</th>\n",
       "      <th>ind_aval_fin_ult1</th>\n",
       "      <th>ind_cco_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq</th>\n",
       "      <th>ind_plan_fin_ult1_frq</th>\n",
       "      <th>ind_pres_fin_ult1_frq</th>\n",
       "      <th>ind_reca_fin_ult1_frq</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq</th>\n",
       "      <th>ind_valo_fin_ult1_frq</th>\n",
       "      <th>ind_viv_fin_ult1_frq</th>\n",
       "      <th>ind_nomina_ult1_frq</th>\n",
       "      <th>ind_nom_pens_ult1_frq</th>\n",
       "      <th>ind_recibo_ult1_frq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310094</th>\n",
       "      <td>56</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.878428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929615</th>\n",
       "      <td>56</td>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310093</th>\n",
       "      <td>63</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.976952</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547974</th>\n",
       "      <td>63</td>\n",
       "      <td>257</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310092</th>\n",
       "      <td>62</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1995-01-16</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  antiguedad  canal_entrada  conyuemp  fecha_alta  fecha_dato  \\\n",
       "310094    56         256              3         1  1995-01-16  2016-05-28   \n",
       "929615    56         257              3         1  1995-01-16  2016-06-28   \n",
       "310093    63         256              3         1  1995-01-16  2016-05-28   \n",
       "1547974   63         257              3         1  1995-01-16  2016-06-28   \n",
       "310092    62         256              3         1  1995-01-16  2016-05-28   \n",
       "\n",
       "         ind_actividad_cliente  ind_ahor_fin_ult1  ind_aval_fin_ult1  \\\n",
       "310094                       1                0.0                0.0   \n",
       "929615                       1                NaN                NaN   \n",
       "310093                       1                0.0                0.0   \n",
       "1547974                      1                NaN                NaN   \n",
       "310092                       1                0.0                0.0   \n",
       "\n",
       "         ind_cco_fin_ult1         ...           ind_hip_fin_ult1_frq  \\\n",
       "310094                1.0         ...                       0.995129   \n",
       "929615                NaN         ...                            NaN   \n",
       "310093                0.0         ...                       0.995129   \n",
       "1547974               NaN         ...                            NaN   \n",
       "310092                1.0         ...                       0.995129   \n",
       "\n",
       "         ind_plan_fin_ult1_frq  ind_pres_fin_ult1_frq  ind_reca_fin_ult1_frq  \\\n",
       "310094                0.992084               0.997858               0.951056   \n",
       "929615                     NaN                    NaN                    NaN   \n",
       "310093                0.007916               0.997858               0.951056   \n",
       "1547974                    NaN                    NaN                    NaN   \n",
       "310092                0.992084               0.997858               0.048944   \n",
       "\n",
       "         ind_tjcr_fin_ult1_frq  ind_valo_fin_ult1_frq  ind_viv_fin_ult1_frq  \\\n",
       "310094                0.037459               0.023048              0.996817   \n",
       "929615                     NaN                    NaN                   NaN   \n",
       "310093                0.037459               0.976952              0.996817   \n",
       "1547974                    NaN                    NaN                   NaN   \n",
       "310092                0.037459               0.023048              0.996817   \n",
       "\n",
       "         ind_nomina_ult1_frq  ind_nom_pens_ult1_frq  ind_recibo_ult1_frq  \n",
       "310094              0.948039               0.943156             0.878428  \n",
       "929615                   NaN                    NaN                  NaN  \n",
       "310093              0.051961               0.056844             0.121572  \n",
       "1547974                  NaN                    NaN                  NaN  \n",
       "310092              0.948039               0.943156             0.121572  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "months = list(set(full_train_df['fecha_dato'].unique()) | set(test_df['fecha_dato'].unique()))\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "    \n",
    "full_train_months = full_train_df['fecha_dato'].unique()\n",
    "test_months = test_df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df2[next_year_month_mask][TARGET_LABELS].isnull().all().all() True\n",
      "df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all() False\n",
      "Add TARGET_LABELS_FRQ from previous month to X\n"
     ]
    }
   ],
   "source": [
    "current_month = 201506\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = full_train_df\n",
    "df2 = test_df\n",
    "X, _, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(619034, 75) (1859230, 96)\n"
     ]
    }
   ],
   "source": [
    "print X.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_diff</th>\n",
       "      <th>targets_logdiff</th>\n",
       "      <th>targets_logcount2_diff</th>\n",
       "      <th>targets_logcount2</th>\n",
       "      <th>targets_logcount1</th>\n",
       "      <th>targets_logDec</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq_prev</th>\n",
       "      <th>ind_plan_fin_ult1_frq_prev</th>\n",
       "      <th>ind_pres_fin_ult1_frq_prev</th>\n",
       "      <th>ind_reca_fin_ult1_frq_prev</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq_prev</th>\n",
       "      <th>ind_valo_fin_ult1_frq_prev</th>\n",
       "      <th>ind_viv_fin_ult1_frq_prev</th>\n",
       "      <th>ind_nomina_ult1_frq_prev</th>\n",
       "      <th>ind_nom_pens_ult1_frq_prev</th>\n",
       "      <th>ind_recibo_ult1_frq_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1053410</th>\n",
       "      <td>15889</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.031536e-05</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>14.571618</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.878428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053333</th>\n",
       "      <td>15890</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.595545e-05</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>13.234620</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.976952</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053311</th>\n",
       "      <td>15892</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>1572864.0</td>\n",
       "      <td>14.268409</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>1.276436e-05</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>14.559070</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053310</th>\n",
       "      <td>15893</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.389720e-03</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.878428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053309</th>\n",
       "      <td>15894</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.179954e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>14.557124</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.051961</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053308</th>\n",
       "      <td>15895</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>-524288.0</td>\n",
       "      <td>-13.169798</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>7.977726e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>14.559192</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053306</th>\n",
       "      <td>15897</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.977726e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>14.805208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053305</th>\n",
       "      <td>15899</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.786636e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>14.602025</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.007916</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053304</th>\n",
       "      <td>15900</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.385340e-04</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>13.287691</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.048944</td>\n",
       "      <td>0.962541</td>\n",
       "      <td>0.976952</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053303</th>\n",
       "      <td>15901</td>\n",
       "      <td>2015-06-28</td>\n",
       "      <td>-1024.0</td>\n",
       "      <td>-6.932448</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>2.712427e-05</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>14.572580</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.995129</td>\n",
       "      <td>0.992084</td>\n",
       "      <td>0.997858</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.037459</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.996817</td>\n",
       "      <td>0.948039</td>\n",
       "      <td>0.943156</td>\n",
       "      <td>0.121572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers  fecha_dato  targets_diff  targets_logdiff  \\\n",
       "1053410     15889  2015-06-28           0.0         0.000000   \n",
       "1053333     15890  2015-06-28           0.0         0.000000   \n",
       "1053311     15892  2015-06-28     1572864.0        14.268409   \n",
       "1053310     15893  2015-06-28           0.0         0.000000   \n",
       "1053309     15894  2015-06-28           0.0         0.000000   \n",
       "1053308     15895  2015-06-28     -524288.0       -13.169798   \n",
       "1053306     15897  2015-06-28           2.0         1.098612   \n",
       "1053305     15899  2015-06-28           0.0         0.000000   \n",
       "1053304     15900  2015-06-28           0.0         0.000000   \n",
       "1053303     15901  2015-06-28       -1024.0        -6.932448   \n",
       "\n",
       "         targets_logcount2_diff  targets_logcount2  targets_logcount1  \\\n",
       "1053410                0.000000       3.031536e-05           0.000032   \n",
       "1053333                0.000000       1.595545e-05           0.000018   \n",
       "1053311               -0.000006       1.276436e-05           0.000014   \n",
       "1053310                0.000000       1.389720e-03           0.001417   \n",
       "1053309                0.000000       7.179954e-06           0.000008   \n",
       "1053308               -0.000002       7.977726e-07           0.000002   \n",
       "1053306                0.000000       7.977726e-07           0.000002   \n",
       "1053305                0.000000       4.786636e-06           0.000005   \n",
       "1053304                0.000000       2.385340e-04           0.000177   \n",
       "1053303                0.000022       2.712427e-05           0.000030   \n",
       "\n",
       "         targets_logDec  ind_empleado  pais_residencia  \\\n",
       "1053410       14.571618             2                0   \n",
       "1053333       13.234620             1                0   \n",
       "1053311       14.559070             2                0   \n",
       "1053310        2.833213             0                0   \n",
       "1053309       14.557124             1                0   \n",
       "1053308       14.559192             1                0   \n",
       "1053306       14.805208             1                0   \n",
       "1053305       14.602025             3                0   \n",
       "1053304       13.287691             3                0   \n",
       "1053303       14.572580             2                0   \n",
       "\n",
       "                   ...             ind_hip_fin_ult1_frq_prev  \\\n",
       "1053410            ...                              0.995129   \n",
       "1053333            ...                              0.995129   \n",
       "1053311            ...                              0.995129   \n",
       "1053310            ...                              0.995129   \n",
       "1053309            ...                              0.995129   \n",
       "1053308            ...                              0.995129   \n",
       "1053306            ...                              0.995129   \n",
       "1053305            ...                              0.995129   \n",
       "1053304            ...                              0.995129   \n",
       "1053303            ...                              0.995129   \n",
       "\n",
       "         ind_plan_fin_ult1_frq_prev  ind_pres_fin_ult1_frq_prev  \\\n",
       "1053410                    0.992084                    0.997858   \n",
       "1053333                    0.007916                    0.997858   \n",
       "1053311                    0.992084                    0.997858   \n",
       "1053310                    0.992084                    0.997858   \n",
       "1053309                    0.992084                    0.997858   \n",
       "1053308                    0.007916                    0.997858   \n",
       "1053306                    0.007916                    0.997858   \n",
       "1053305                    0.007916                    0.997858   \n",
       "1053304                    0.992084                    0.997858   \n",
       "1053303                    0.992084                    0.997858   \n",
       "\n",
       "         ind_reca_fin_ult1_frq_prev  ind_tjcr_fin_ult1_frq_prev  \\\n",
       "1053410                    0.951056                    0.037459   \n",
       "1053333                    0.951056                    0.037459   \n",
       "1053311                    0.048944                    0.037459   \n",
       "1053310                    0.951056                    0.962541   \n",
       "1053309                    0.048944                    0.037459   \n",
       "1053308                    0.048944                    0.037459   \n",
       "1053306                    0.048944                    0.037459   \n",
       "1053305                    0.951056                    0.962541   \n",
       "1053304                    0.048944                    0.962541   \n",
       "1053303                    0.951056                    0.037459   \n",
       "\n",
       "         ind_valo_fin_ult1_frq_prev  ind_viv_fin_ult1_frq_prev  \\\n",
       "1053410                    0.023048                   0.996817   \n",
       "1053333                    0.976952                   0.996817   \n",
       "1053311                    0.023048                   0.996817   \n",
       "1053310                    0.023048                   0.996817   \n",
       "1053309                    0.023048                   0.996817   \n",
       "1053308                    0.023048                   0.996817   \n",
       "1053306                    0.023048                   0.996817   \n",
       "1053305                    0.023048                   0.996817   \n",
       "1053304                    0.976952                   0.996817   \n",
       "1053303                    0.023048                   0.996817   \n",
       "\n",
       "         ind_nomina_ult1_frq_prev  ind_nom_pens_ult1_frq_prev  \\\n",
       "1053410                  0.948039                    0.943156   \n",
       "1053333                  0.051961                    0.056844   \n",
       "1053311                  0.948039                    0.943156   \n",
       "1053310                  0.948039                    0.943156   \n",
       "1053309                  0.051961                    0.056844   \n",
       "1053308                  0.948039                    0.943156   \n",
       "1053306                  0.948039                    0.056844   \n",
       "1053305                  0.948039                    0.943156   \n",
       "1053304                  0.948039                    0.943156   \n",
       "1053303                  0.948039                    0.943156   \n",
       "\n",
       "         ind_recibo_ult1_frq_prev  \n",
       "1053410                  0.878428  \n",
       "1053333                  0.121572  \n",
       "1053311                  0.121572  \n",
       "1053310                  0.878428  \n",
       "1053309                  0.121572  \n",
       "1053308                  0.121572  \n",
       "1053306                  0.121572  \n",
       "1053305                  0.121572  \n",
       "1053304                  0.121572  \n",
       "1053303                  0.121572  \n",
       "\n",
       "[10 rows x 75 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>lc_ind_ahor_fin_ult1</th>\n",
       "      <th>lc_ind_aval_fin_ult1</th>\n",
       "      <th>lc_ind_cco_fin_ult1</th>\n",
       "      <th>lc_ind_cder_fin_ult1</th>\n",
       "      <th>lc_ind_cno_fin_ult1</th>\n",
       "      <th>lc_ind_ctju_fin_ult1</th>\n",
       "      <th>lc_ind_ctma_fin_ult1</th>\n",
       "      <th>lc_ind_ctop_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>lc_ind_hip_fin_ult1</th>\n",
       "      <th>lc_ind_plan_fin_ult1</th>\n",
       "      <th>lc_ind_pres_fin_ult1</th>\n",
       "      <th>lc_ind_reca_fin_ult1</th>\n",
       "      <th>lc_ind_tjcr_fin_ult1</th>\n",
       "      <th>lc_ind_valo_fin_ult1</th>\n",
       "      <th>lc_ind_viv_fin_ult1</th>\n",
       "      <th>lc_ind_nomina_ult1</th>\n",
       "      <th>lc_ind_nom_pens_ult1</th>\n",
       "      <th>lc_ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>929615</th>\n",
       "      <td>15889</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547974</th>\n",
       "      <td>15890</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547975</th>\n",
       "      <td>15892</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547976</th>\n",
       "      <td>15893</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547977</th>\n",
       "      <td>15894</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547978</th>\n",
       "      <td>15895</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547980</th>\n",
       "      <td>15897</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547982</th>\n",
       "      <td>15899</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547983</th>\n",
       "      <td>15900</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547984</th>\n",
       "      <td>15901</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ncodpers  fecha_dato  lc_ind_ahor_fin_ult1  lc_ind_aval_fin_ult1  \\\n",
       "929615      15889  2016-06-28                   0.0                   0.0   \n",
       "1547974     15890  2016-06-28                   0.0                   0.0   \n",
       "1547975     15892  2016-06-28                   0.0                   0.0   \n",
       "1547976     15893  2016-06-28                   0.0                   0.0   \n",
       "1547977     15894  2016-06-28                   0.0                   0.0   \n",
       "1547978     15895  2016-06-28                   0.0                   0.0   \n",
       "1547980     15897  2016-06-28                   0.0                   0.0   \n",
       "1547982     15899  2016-06-28                   0.0                   0.0   \n",
       "1547983     15900  2016-06-28                   0.0                   0.0   \n",
       "1547984     15901  2016-06-28                   0.0                   0.0   \n",
       "\n",
       "         lc_ind_cco_fin_ult1  lc_ind_cder_fin_ult1  lc_ind_cno_fin_ult1  \\\n",
       "929615                   1.0                   0.0                  0.0   \n",
       "1547974                  0.0                   0.0                  1.0   \n",
       "1547975                  1.0                   0.0                  0.0   \n",
       "1547976                  0.0                   0.0                  0.0   \n",
       "1547977                  1.0                   0.0                  0.0   \n",
       "1547978                  1.0                   0.0                  0.0   \n",
       "1547980                  0.0                   0.0                  1.0   \n",
       "1547982                  1.0                   0.0                  0.0   \n",
       "1547983                  0.0                   0.0                  0.0   \n",
       "1547984                  1.0                   0.0                  0.0   \n",
       "\n",
       "         lc_ind_ctju_fin_ult1  lc_ind_ctma_fin_ult1  lc_ind_ctop_fin_ult1  \\\n",
       "929615                    0.0                   0.0                   0.0   \n",
       "1547974                   0.0                   0.0                   0.0   \n",
       "1547975                   0.0                   0.0                   0.0   \n",
       "1547976                   0.0                   0.0                   0.0   \n",
       "1547977                   0.0                   0.0                   0.0   \n",
       "1547978                   0.0                   0.0                   0.0   \n",
       "1547980                   0.0                   0.0                   1.0   \n",
       "1547982                   0.0                   0.0                   1.0   \n",
       "1547983                   0.0                   0.0                   1.0   \n",
       "1547984                   0.0                   0.0                   0.0   \n",
       "\n",
       "                ...          lc_ind_hip_fin_ult1  lc_ind_plan_fin_ult1  \\\n",
       "929615          ...                          0.0                   0.0   \n",
       "1547974         ...                          0.0                   1.0   \n",
       "1547975         ...                          0.0                   0.0   \n",
       "1547976         ...                          0.0                   0.0   \n",
       "1547977         ...                          0.0                   0.0   \n",
       "1547978         ...                          0.0                   1.0   \n",
       "1547980         ...                          0.0                   1.0   \n",
       "1547982         ...                          0.0                   1.0   \n",
       "1547983         ...                          0.0                   0.0   \n",
       "1547984         ...                          0.0                   0.0   \n",
       "\n",
       "         lc_ind_pres_fin_ult1  lc_ind_reca_fin_ult1  lc_ind_tjcr_fin_ult1  \\\n",
       "929615                    0.0                   0.0                   1.0   \n",
       "1547974                   0.0                   0.0                   1.0   \n",
       "1547975                   0.0                   1.0                   1.0   \n",
       "1547976                   0.0                   0.0                   0.0   \n",
       "1547977                   0.0                   1.0                   1.0   \n",
       "1547978                   0.0                   1.0                   1.0   \n",
       "1547980                   0.0                   1.0                   1.0   \n",
       "1547982                   0.0                   0.0                   0.0   \n",
       "1547983                   0.0                   1.0                   0.0   \n",
       "1547984                   0.0                   0.0                   1.0   \n",
       "\n",
       "         lc_ind_valo_fin_ult1  lc_ind_viv_fin_ult1  lc_ind_nomina_ult1  \\\n",
       "929615                    1.0                  0.0                 0.0   \n",
       "1547974                   0.0                  0.0                 1.0   \n",
       "1547975                   1.0                  0.0                 0.0   \n",
       "1547976                   1.0                  0.0                 0.0   \n",
       "1547977                   1.0                  0.0                 1.0   \n",
       "1547978                   1.0                  0.0                 0.0   \n",
       "1547980                   1.0                  0.0                 0.0   \n",
       "1547982                   1.0                  0.0                 0.0   \n",
       "1547983                   0.0                  0.0                 0.0   \n",
       "1547984                   1.0                  0.0                 0.0   \n",
       "\n",
       "         lc_ind_nom_pens_ult1  lc_ind_recibo_ult1  \n",
       "929615                    0.0                 0.0  \n",
       "1547974                   1.0                 1.0  \n",
       "1547975                   0.0                 1.0  \n",
       "1547976                   0.0                 0.0  \n",
       "1547977                   1.0                 1.0  \n",
       "1547978                   0.0                 1.0  \n",
       "1547980                   1.0                 1.0  \n",
       "1547982                   0.0                 1.0  \n",
       "1547983                   0.0                 1.0  \n",
       "1547984                   0.0                 1.0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(predicted_added_products, clients, clc, target_labels):\n",
    "    added_products_col = []\n",
    "    count = 0 \n",
    "    for products, last_choice in zip(predicted_added_products, clc):\n",
    "        predictions = remove_last_choice(products, last_choice)\n",
    "        added_products_col.append(' '.join([target_labels[i] for i in predictions]))\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            logging.info(\"Elapsed : %i\", count)\n",
    "            \n",
    "    out = pd.DataFrame(data={'ncodpers': clients, 'added_products': added_products_col}, columns=['ncodpers', 'added_products'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predict all --\n"
     ]
    }
   ],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)\n",
    "\n",
    "logging.info(\"- Get submission dataframe:\")\n",
    "clients = X['ncodpers'].values\n",
    "submission = get_submission(y_pred, clients, clients_last_choice[TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_clients = set(submission['ncodpers'].unique())\n",
    "test_clients = set(test_df['ncodpers'].unique())\n",
    "if submission_clients != test_clients:\n",
    "    missing_clients = list(test_clients - submission_clients)\n",
    "        \n",
    "#     selected_estimators = []\n",
    "#     for e in estimators:\n",
    "#         if e[0]\n",
    "        \n",
    "    \n",
    "    missing_added_products = np.zeros((len(missing_clients)))\n",
    "    submission = pd.concat([submission, \n",
    "                            pd.DataFrame(data={\n",
    "                                'ncodpers': missing_clients, \n",
    "                                'added_products': missing_added_products\n",
    "                            }, columns=['ncodpers', 'added_products'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission DataFrame and write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "\n",
    "submission.to_csv(submission_file, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/submission_2016-11-17-16-37.csv', 'r') as r:\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
