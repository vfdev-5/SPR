{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees tryouts on SPR data, inspired by Kaggle Forum \"When less is more\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data as \n",
    "    month : [ Features | Targets| Difference | Last Choice Targets  ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from dataset import load_trainval, LC_TARGET_LABELS, TARGET_LABELS_FRQ, TARGET_LABELS_DIFF\n",
    "from utils import to_yearmonth, TARGET_LABELS, TARGET_LABELS2\n",
    "from utils import target_str_to_labels, decimal_to_dummies, targets_str_to_indices, targets_dec_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    u'ind_empleado', u'pais_residencia',\n",
    "    u'sexo', u'age', u'ind_nuevo', u'antiguedad', u'indrel',\n",
    "    u'ult_fec_cli_1t', u'indrel_1mes', u'tiprel_1mes', u'indresi',\n",
    "    u'indext', u'conyuemp', u'canal_entrada', u'indfall', u'nomprov',\n",
    "    u'ind_actividad_cliente', u'renta', u'segmento'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Load training data : \n",
      "INFO:root:- Load data : [201504, 201505, 201601, 201602, 201604, 201605]\n"
     ]
    }
   ],
   "source": [
    "# train_yearmonths_list = [201504, 201505, 201604]\n",
    "train_yearmonths_list = [201505, 201602, 201605]\n",
    "# train_yearmonths_list = [201505]\n",
    "#val_yearmonth = [201605]\n",
    "train_nb_clients = 150000\n",
    "# train_nb_clients = 1500\n",
    "#train_df, val_df = load_trainval(train_yearmonths_list, val_yearmonth, train_nb_clients, val_nb_clients=1500)\n",
    "train_df = load_trainval(train_yearmonths_list, train_nb_clients=train_nb_clients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df[['fecha_dato', 'ncodpers'] + TARGET_LABELS_FRQ.tolist()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_clients(df1, mask1, mask2, df2=None):\n",
    "    active_clients1 = df1[mask1]['ncodpers'].unique()\n",
    "    if df2 is not None:\n",
    "        active_clients2 = df2[mask2]['ncodpers'].unique()\n",
    "    else:\n",
    "        active_clients2 = df1[mask2]['ncodpers'].unique()\n",
    "    active_clients = list(set(active_clients1) & set(active_clients2)) \n",
    "    \n",
    "    if df2 is not None:\n",
    "        return df1['ncodpers'].isin(active_clients), df2['ncodpers'].isin(active_clients)\n",
    "    return df1['ncodpers'].isin(active_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "# months = list(set(train_df['fecha_dato'].unique()) | set(val_df['fecha_dato'].unique()))\n",
    "months = train_df['fecha_dato'].unique()\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "\n",
    "        \n",
    "train_months = train_df['fecha_dato'].unique()\n",
    "# val_months = val_df['fecha_dato'].unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_added_products, remove_last_choice, apk, map7_score\n",
    "from visualization import visualize_train_test, visualize_folds, compare_two_datasets, compare_folds, compare_folds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_features = ['targets_diff', 'targets_logdiff', 'targets_logcount2_diff', 'targets_logcount2', 'targets_logcount1', 'targets_logDec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(current_month, df1, next_year_month, df2, months_ym_map):\n",
    "    month_mask = df1['fecha_dato'] == months_ym_map[current_month]\n",
    "    next_year_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month]\n",
    "    next_year_prev_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month - 1]\n",
    "    \n",
    "    # get common clients from df1 at this month and df2 at next year month\n",
    "    common_clients_mask1, common_clients_mask2 = get_common_clients(df1, month_mask, next_year_month_mask, df2)\n",
    "    common_clients_mask2, common_clients_mask3 = get_common_clients(df2, common_clients_mask2 & next_year_month_mask, next_year_prev_month_mask, df2)\n",
    "        \n",
    "    c1 = df1[common_clients_mask1 & month_mask]['ncodpers'].values\n",
    "    c2 = df2[common_clients_mask2 & next_year_month_mask]['ncodpers'].values\n",
    "    c3 = df2[common_clients_mask3 & next_year_prev_month_mask]['ncodpers'].values\n",
    "    assert (c1 == c2).all() and (c2 == c3).all(), \"Problem with common clients\" \n",
    "    \n",
    "    X = df1[common_clients_mask1 & month_mask][['ncodpers', 'fecha_dato'] + target_features + features + TARGET_LABELS_FRQ.tolist()]            \n",
    "\n",
    "    if TARGET_LABELS[0] in df2.columns and TARGET_LABELS_FRQ[0] in df2.columns:\n",
    "        Y = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str'] + TARGET_LABELS]    \n",
    "        assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        Y.index = X.index\n",
    "        \n",
    "        # Add TARGET_LABELS_FRQ to X:\n",
    "        target_labels_frq = df2[common_clients_mask3 & next_year_prev_month_mask][['ncodpers'] + TARGET_LABELS_FRQ.tolist()]\n",
    "        assert (X['ncodpers'].values == target_labels_frq['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        target_labels_frq = target_labels_frq[TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.columns = [c + '_prev' for c in TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.index = X.index\n",
    "        X = pd.concat([X, target_labels_frq], axis=1)        \n",
    "        \n",
    "    else:\n",
    "        Y = None\n",
    "    \n",
    "    if LC_TARGET_LABELS[0] in df2.columns:\n",
    "        clients_last_choice = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato'] + LC_TARGET_LABELS.tolist()]\n",
    "    else:\n",
    "        clients_last_choice = None\n",
    "        \n",
    "    return X, Y, clients_last_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df if months_ym_map[current_month] in train_months else val_df\n",
    "#df1 = train_df\n",
    "df2 = train_df if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = train_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print Y.shape\n",
    "Y.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print clients_last_choice.shape\n",
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another train/predict + CV implementation\n",
    "\n",
    "### Input\n",
    "\n",
    "- `X` : `[nb_samples, nb_features]` shaped pd.DataFrame\n",
    "    - `features_masks_list` : `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "    \n",
    "- `Y` : `[nb_samples, nb_labels]` shaped pd.DataFrame\n",
    "    - `labels_masks_list` : `{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "\n",
    "- `samples_masks_list` : `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "\n",
    "\n",
    "- Set of models `models` : list of functions to create a model, e.g. `[create_RF, create_NN, create_GBT]`\n",
    "\n",
    "\n",
    "### Training phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_masks_list = [\n",
    "   lambda x:  ~x['targets_diff'].isin([0]), \n",
    "]\n",
    "\n",
    "TARGET_LABELS_FRQ_PREV = [c + '_prev' for c in TARGET_LABELS_FRQ]\n",
    "\n",
    "features_masks_dict = {\n",
    "#     'fm_all': None,\n",
    "    'fm0': features + target_features + TARGET_LABELS_FRQ.tolist(),# + TARGET_LABELS_FRQ_PREV,\n",
    "#     'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm2': target_features,\n",
    "#     'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "#     'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "#     'fm6': TARGET_LABELS_FRQ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "\n",
    "def create_RF(input_shape, output_shape):\n",
    "    return RandomForestClassifier(n_estimators=25, max_depth=5)\n",
    "\n",
    "def create_ET(input_shape, output_shape):\n",
    "    return ExtraTreesClassifier(n_estimators=25, max_depth=5)\n",
    "\n",
    "def create_GB(input_shape, output_shape):\n",
    "    return GradientBoostingClassifier()\n",
    "\n",
    "models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "#     'gb': create_GB,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "common_groups = [\n",
    "#     [2, ],\n",
    "   [2, 18],\n",
    "   [18, 23],\n",
    "#     [23, ],\n",
    "#     [18, ],\n",
    "#     [12, ],\n",
    "#     [21, ],\n",
    "#     [22, ],\n",
    "    [3, 4, 7, 8],\n",
    "#     [17, ],\n",
    "]\n",
    "\n",
    "def flatten(array):\n",
    "    out = []\n",
    "    for item in array:\n",
    "        out += item\n",
    "    return out\n",
    "\n",
    "others = list(set(range(24)) - set(flatten(common_groups)))\n",
    "NP_TARGET_LABELS = np.array(TARGET_LABELS)\n",
    "\n",
    "for i, a in enumerate(TARGET_LABELS2):\n",
    "    print i, a\n",
    "    \n",
    "s = set({})\n",
    "labels_masks_dict = {}\n",
    "for i, g in enumerate(common_groups):\n",
    "    labels_masks_dict['lm_%i' % i] = NP_TARGET_LABELS[g]\n",
    "    s |= set(g)\n",
    "labels_masks_dict['lm_others'] = NP_TARGET_LABELS[others]\n",
    "s |= set(others)\n",
    "\n",
    "assert len(s) == len(TARGET_LABELS), \"Sum is not equal 24, s=%i\" % s\n",
    "print labels_masks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models_pipelines = {\n",
    "    'gb' : [(None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) == 1]\n",
    "}\n",
    "models_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_to_fit(X_train, Y_train):\n",
    "    x_train = X_train.values\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    y_train = Y_train.values    \n",
    "    return x_train, y_train\n",
    "\n",
    "def prepare_to_test(X_val, Y_val=None):\n",
    "    x_val = X_val.values\n",
    "    x_val = StandardScaler().fit_transform(x_val)\n",
    "    y_val = Y_val.values if Y_val is not None else None   \n",
    "    return x_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_all(X_train, Y_train, \n",
    "              samples_masks_list, \n",
    "              features_masks_dict, \n",
    "              labels_masks_dict,\n",
    "              models_dict,\n",
    "              **kwargs):\n",
    "    \"\"\"\n",
    "    Method to train a set of estimators from `models_dict` \n",
    "    on the data obtained after applying all combinations of \n",
    "    - samples mask from `samples_masks_list`,\n",
    "    - features mask from `features_masks_dict` and \n",
    "    - labels mask from `labels_masks_dict`\n",
    "    \n",
    "    :X_train: a pd.DataFrame of training dataset containing features, `(nb_samples, nb_features)` \n",
    "    :Y_train: a pd.DataFrame of training dataset containing labels, `(nb_samples, nb_labels)`\n",
    "    :samples_masks_list: a list, e.g. `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "    If an empty list is providede, all samples are used for training\n",
    "\n",
    "    :features_masks_list: a dictionary, e.g. `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "        Feature mask can be None to indicate all features.\n",
    "    :labels_masks_list: a dictionary, e.g.`{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "        Label mask can be None to indicate all labels.\n",
    "    :models_dict: a dictionary of functions to create a model, e.g. `{'rf': create_RF, 'nn': create_NN, 'gbt': create_GBT}`\n",
    "\n",
    "    In `kwargs` it is possible to define :\n",
    "        :verbose: True/False\n",
    "        :models_pipelines: (optional) a dictionary, e.g. `{model_name: [(feature_mask_name, label_mask_name), ...]}`. \n",
    "        It defines specific connection between a model and features/labels to train on. Useful, when a model can not train on \n",
    "        all types of labels. It is possible to specify only one mask name `feature_mask_name` or `label_mask_name` with None, e.g. (None, label_mask_name).\n",
    "        If models_pipelines is defined and a model is not added into models_pipelines. It will be used on all combinations of feature mask/label mask.\n",
    "\n",
    "    :return: a list of trained estimators, e.g. `[([features_mask_name, labels_mask_name, model_name], estimator_object, fit_accuracy), ...]` \n",
    "    \"\"\"    \n",
    "    logging.info(\"---------------\")\n",
    "    logging.info(\"-- Train all --\")\n",
    "    verbose = False if 'verbose' not in kwargs else kwargs['verbose']\n",
    "    models_pipelines = None if 'models_pipelines' not in kwargs else kwargs['models_pipelines']\n",
    "    \n",
    "    if len(samples_masks_list) == 0:        \n",
    "        samples_masks_list.append(lambda df: df.index.isin(df.index[:]))\n",
    "    \n",
    "    estimators = []\n",
    "    \n",
    "    for i, samples_mask in enumerate(samples_masks_list):\n",
    "        mask = samples_mask(X_train)\n",
    "        X_train_ = X_train[mask]\n",
    "        Y_train_ = Y_train[mask]\n",
    "        \n",
    "        for features_mask_name in features_masks_dict:\n",
    "            features_mask = features_masks_dict[features_mask_name]  \n",
    "            X_train__ = X_train_[features_mask] if features_mask is not None else X_train_            \n",
    "            for labels_mask_name in labels_masks_dict:\n",
    "                labels_mask = labels_masks_dict[labels_mask_name] \n",
    "                Y_train__ = Y_train_[labels_mask] if labels_mask is not None else Y_train_                           \n",
    "                logging.info(\"-- Process : sample_mask={}/{}, features_mask={}, labels_mask={}\"\n",
    "                             .format(len(X_train_), len(X_train), features_mask_name, labels_mask_name))\n",
    "                x_train, y_train = prepare_to_fit(X_train__, Y_train__)\n",
    "                logging.info(\"--- Train data shapes : {}, {}\".format(x_train.shape, y_train.shape))                \n",
    "\n",
    "                if y_train.shape[1] == 1:\n",
    "                    # avoid DataConversionWarning\n",
    "                    y_train = y_train.ravel()\n",
    "\n",
    "                for model_name in models_dict:\n",
    "                    logging.info(\"-- Create the model : %s\" % model_name)\n",
    "                    \n",
    "                    can_fit = True\n",
    "                    if models_pipelines is not None and model_name in models_pipelines:\n",
    "                        can_fit = False\n",
    "                        pipelines = models_pipelines[model_name]\n",
    "                        # pipelines = [(feature_mask_name, label_mask_name), ...]\n",
    "                        for _features_mask_name, _labels_mask_name in pipelines:        \n",
    "                            b1 = _features_mask_name is None\n",
    "                            b2 = _labels_mask_name is None\n",
    "                            assert not (b1 and b2), \"Feature_mask_name and label_mask_name can not be both None\"\n",
    "                            if _features_mask_name is not None and _features_mask_name == features_mask_name:\n",
    "                                b1 = True\n",
    "                            if _labels_mask_name is not None and _labels_mask_name == labels_mask_name:\n",
    "                                b2 = True\n",
    "                            can_fit = b1 and b2\n",
    "                            if can_fit:\n",
    "                                break\n",
    "                                        \n",
    "                    if not can_fit:\n",
    "                        continue\n",
    "                    \n",
    "                    estimator = models_dict[model_name](input_shape=x_train.shape, output_shape=y_train.shape)\n",
    "                    logging.info(\"--- Fit the model\")\n",
    "                    estimator.fit(x_train, y_train)                    \n",
    "                    acc = estimator.score(x_train, y_train)\n",
    "                    logging.info(\"--- Score : fit accuracy : %f\" % acc)\n",
    "                    estimators.append(([features_mask_name, labels_mask_name, model_name], estimator, acc))\n",
    "                \n",
    "                    if verbose:                        \n",
    "                        logging.info(\"\\n\\n\\t -- Feature ranking : -- \\n\\n\")\n",
    "                        logging.info(\"--- Estimator : {}, {}, {}\".format(features_mask_name, labels_mask_name, model_name))\n",
    "                        importances = estimator.feature_importances_\n",
    "                        indices = np.argsort(importances)[::-1]            \n",
    "                        for f in range(len(features_mask)):                \n",
    "                            logging.info(\"%d. feature %d '%s' (%f)\" % (f + 1, indices[f], features_mask[indices[f]], importances[indices[f]]))                            \n",
    "    return estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def probas_to_indices(Y_probas, **kwargs):\n",
    "    mask = (~Y_probas.isnull()).any()\n",
    "    all_columns = Y_probas.columns\n",
    "    Y_probas = Y_probas[mask[mask].index]\n",
    "    y_probas = Y_probas.as_matrix()\n",
    "  \n",
    "    threshold = 0.5 if 'threshold' not in kwargs else kwargs['threshold']\n",
    "    n_highest = 7 if 'n_highest' not in kwargs else kwargs['n_highest']\n",
    "    \n",
    "    y_probas[y_probas < threshold] = 0.0\n",
    "    predicted_added_products = np.argsort(y_probas, axis=1)\n",
    "    predicted_added_products = predicted_added_products[:,::-1][:,:n_highest]\n",
    "    out = []\n",
    "    index_map = np.where(all_columns.isin(mask[mask].index))[0]\n",
    "    for i, t in enumerate(predicted_added_products):\n",
    "        out.append([index_map[j] for j in t if y_probas[i, j] > 0.0])\n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_predictions(Y_probas, y_probas, labels_mask, mode='sum', **kwargs):    \n",
    "    first_time = Y_probas[labels_mask].isnull().all().all()\n",
    "    if mode == 'max':\n",
    "        if not first_time:\n",
    "            Y_probas.loc[:, labels_mask] = np.maximum(Y_probas.loc[:, labels_mask], y_probas)\n",
    "        else:\n",
    "            Y_probas.loc[:, labels_mask] = y_probas    \n",
    "    elif mode == 'sum':\n",
    "        if not first_time:\n",
    "            Y_probas.loc[:, labels_mask] = Y_probas.loc[:, labels_mask] + y_probas\n",
    "        else:\n",
    "            Y_probas.loc[:, labels_mask] = y_probas    \n",
    "    else:\n",
    "        raise Exception(\"Existing data merge is not yet implemented\")\n",
    "\n",
    "    return Y_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_all(estimators, X_val, features_masks_dict, labels_masks_dict, labels, **kwargs):\n",
    "    \"\"\"\n",
    "    Method to compute predictions using `estmators` from a test dataset `X_val`\n",
    "    \n",
    "    :estimators: a list of object of type ([features_mask_name, labels_mask_name, model_name], estimator_object, fit_accuracy)\n",
    "    :X_val: a pd.DataFrame of shape `(nb_samples, nb_features)`\n",
    "    :features_masks_dict: a dictionary of features masks (see train_all method)\n",
    "    :labels_masks_dict: a dictionary of labels masks (see train_all method)\n",
    "    :labels: a list of all available labels for the output\n",
    "    \n",
    "    In `kwargs` it is possible to define :\n",
    "        :transform_proba_func: a function to transform computed probabilities into a custom form.\n",
    "        Function signature should be `foo(Y_probas, **kwargs)`\n",
    "\n",
    "        :verbose: True/False\n",
    "    \n",
    "    :return: \n",
    "        if `transform_proba_func` is not defined, predicted label probabilites `Y_probas` (pd.DataFrame) are returned.\n",
    "        Thus, output is an ndarray of shape (nb_samples, len(labels)).\n",
    "        \n",
    "        if `transform_proba_func` is defined, then output is an ndarray of shape `(nb_samples, ...)`, the output of `transform_proba_func`.\n",
    "    \n",
    "    \"\"\"\n",
    "    logging.info(\"-----------------\")\n",
    "    logging.info(\"-- Predict all --\")\n",
    "    verbose = False if 'verbose' not in kwargs else kwargs['verbose']\n",
    "    return_probas = False if 'return_probas' not in kwargs else kwargs['return_probas']\n",
    "    transform_proba_func = None if 'transform_proba_func' not in kwargs else kwargs['transform_proba_func']\n",
    "    \n",
    "    Y_probas = pd.DataFrame(index=X_val.index, columns=labels)\n",
    "    for estimator in estimators:\n",
    "        # estimator is ([features_mask_name, labels_mask_name, model_name], estimator_object)\n",
    "        features_mask_name, labels_mask_name, model_name = estimator[0]\n",
    "        features_mask = features_masks_dict[features_mask_name]\n",
    "        labels_mask = labels_masks_dict[labels_mask_name]\n",
    "        logging.info(\"-- Process : model={}, features_mask={}, labels_mask={}\".format(model_name, features_mask_name, labels_mask_name))\n",
    "            \n",
    "        x_val, _ = prepare_to_test(X_val[features_mask])\n",
    "        logging.debug(\"--- Test data shapes : {}\".format(x_val.shape))                \n",
    "            \n",
    "        y_probas = estimator[1].predict(x_val)\n",
    "        logging.debug(\"--- Predicted data shape : {}\".format(y_probas.shape))                \n",
    "        if y_probas.dtype == np.int:\n",
    "            y_probas = y_probas.astype(np.float)\n",
    "        if len(y_probas.shape) == 1:\n",
    "            y_probas = y_probas.reshape((y_probas.shape[0], 1))\n",
    "        # multiply by accuracy : \n",
    "        y_probas *= estimator[2]\n",
    "        Y_probas = merge_predictions(Y_probas, y_probas, labels_mask, **kwargs)\n",
    "        \n",
    "    if transform_proba_func is not None:\n",
    "        if return_probas:\n",
    "            return transform_proba_func(Y_probas, **kwargs), Y_probas\n",
    "        else:\n",
    "            return transform_proba_func(Y_probas, **kwargs)                \n",
    "    return Y_probas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ll = 50000\n",
    "mask = X.index.isin(X.index[:ll])\n",
    "\n",
    "X1 = X[mask]\n",
    "Y1 = Y[mask]\n",
    "clc = clients_last_choice[mask]\n",
    "print X1.shape, Y1.shape, clc.shape\n",
    "\n",
    "mask = X.index.isin(X.index[ll:ll+ll//2])\n",
    "X2 = X[mask]\n",
    "Y2 = Y[mask]\n",
    "clc2 = clients_last_choice[mask]\n",
    "print X2.shape, Y2.shape, clc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_kwargs = {'samples_masks_list': samples_masks_list, \n",
    "            'features_masks_dict': features_masks_dict, \n",
    "            'labels_masks_dict': labels_masks_dict, \n",
    "            'models_dict': models_dict,\n",
    "            'labels': TARGET_LABELS,\n",
    "            'transform_proba_func': probas_to_indices,\n",
    "            'threshold': 0.0,\n",
    "            'n_highest': 7,\n",
    "            'mode': 'sum',\n",
    "            'verbose': False,\n",
    "            'models_pipelines': models_pipelines,\n",
    "            'return_probas': True\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X1, Y1, **_kwargs)\n",
    "\n",
    "#print estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "#print y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_val = targets_str_to_indices(Y2[TARGET_LABELS].values)\n",
    "\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "map7_score(y_val, y_val, clc2[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute map7 score\")\n",
    "map7_score(y_val, y_preds, clc2[LC_TARGET_LABELS].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import targets_to_labels, targets_indices_to_labels, remove_last_choice\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit = 100\n",
    "count = 0\n",
    "\n",
    "not_predicted_predicted = defaultdict(int)\n",
    "for last_choice, targets, products, proba in zip(clc2[LC_TARGET_LABELS].values, y_val, y_preds, Y_probas.values):\n",
    "    added_products = remove_last_choice(targets, last_choice)\n",
    "    predictions = remove_last_choice(products, last_choice)\n",
    "    \n",
    "    if len(added_products) == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(set(added_products) & set(predictions)) > 0:\n",
    "#         print \"Predicted : \", added_products, predictions\n",
    "#         print set(added_products) & set(predictions)\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    if count < limit:\n",
    "        print \"--- Count = \", count\n",
    "        print targets_indices_to_labels(added_products, TARGET_LABELS2)#, targets_indices_to_labels(targets, TARGET_LABELS2)\n",
    "        print targets_indices_to_labels(predictions, TARGET_LABELS2), targets_indices_to_labels(products, TARGET_LABELS2)#, proba\n",
    "    \n",
    "    for p in added_products:\n",
    "        not_predicted_predicted[TARGET_LABELS2[p]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print not_predicted_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print not_predicted_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_probas[:10, target_groups[0]]\n",
    "print Y[np.array(TARGET_LABELS)[target_groups[0]]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KFold Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "from sklearn.model_selection import KFold\n",
    "def cross_val_score2(data, \n",
    "                     nb_folds=5,\n",
    "                     **kwargs):\n",
    "    \n",
    "    logging.info(\"- Cross validation : \")\n",
    "    x_df, y_df, clients_last_choice = data\n",
    "    kf = KFold(n_splits=nb_folds)\n",
    "    scores = []\n",
    "    \n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(range(x_df.shape[0])):\n",
    "        count += 1\n",
    "        logging.info(\"\\n\\n\\t\\t-- Fold : %i / %i\\n\" % (count, nb_folds))\n",
    "        \n",
    "        X_train, X_val = x_df.loc[x_df.index[train_index], :], x_df.loc[x_df.index[test_index], :]\n",
    "        Y_train, Y_val = y_df.loc[y_df.index[train_index], :], y_df.loc[y_df.index[test_index], :]\n",
    "        clc_val = clients_last_choice[test_index, :]\n",
    "\n",
    "        estimators = train_all(X_train, Y_train, **kwargs)\n",
    "        if 'return_probas' in kwargs:\n",
    "            y_preds, Y_probas = predict_all(estimators, X_val, **kwargs)\n",
    "        else:\n",
    "            y_preds = predict_all(estimators, X_val, **kwargs)\n",
    "\n",
    "        y_val = targets_str_to_indices(Y_val[TARGET_LABELS].values)\n",
    "        logging.info(\"- Compute map7 score\")\n",
    "        scores.append(map7_score(y_val, y_preds, clc_val))   \n",
    "                            \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_folds = 5\n",
    "results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                            nb_folds=nb_folds, **_kwargs)\n",
    "\n",
    "print \"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), np.median(results), results.max(), results.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 201505 -> 201605 \n",
    "\n",
    "#### Single profiles:\n",
    "\n",
    "Profiles   [0, 100] \n",
    "Cross-Validation (normalized)\n",
    " 3 | 0.011683 | 0.012817 | 0.014958 | 0.00152 \n",
    "\n",
    "Cross-Validation (not normalized)\n",
    " 3 | 0.009244 | 0.010407 | 0.011922 | 0.00112 \n",
    " \n",
    " \n",
    "Profiles :  [1, 101]\n",
    "Cross-Validation (normalized)\n",
    " 3 | 0.006793 | 0.009161 | 0.012219 | 0.00227 \n",
    "\n",
    "Cross-Validation (not normalized)\n",
    " 3 | 0.004787 | 0.009852 | 0.014922 | 0.00414\n",
    "\n",
    "\n",
    "Profiles :  [112, 12]\n",
    "Cross-Validation (normalized)\n",
    " 3 | 0.008856 | 0.012124 | 0.016443 | 0.00318 \n",
    "\n",
    "Cross-Validation (not normalized)\n",
    " 3 | 0.007298 | 0.010140 | 0.014101 | 0.00289 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cross-validation across several months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_folds = 3\n",
    "yms = [201504, 201505]\n",
    "#yms = [201505]\n",
    "\n",
    "for ym in yms:\n",
    "    logging.info(\"\\n-------------------------\")\n",
    "    logging.info(\"- Process month : %s\" % ym)\n",
    "    logging.info(\"-------------------------\\n\")\n",
    "    \n",
    "    ym1 = ym + 100    \n",
    "    df1 = train_df if months_ym_map[ym] in train_months else val_df\n",
    "    df2 = train_df if months_ym_map[ym1] in train_months else val_df\n",
    "    X, Y, clients_last_choice = get_XY(ym, df1, ym1, df2) \n",
    "    results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                                profiles=profiles,\n",
    "                                nb_folds=nb_folds)\n",
    "    print \"Cross-Validation \\n %i | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), results.max(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df\n",
    "#df1 = val_df\n",
    "df2 = train_df #if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = val_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X, Y, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_preds = predict_all(estimators, X, **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check score on the data 2016/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"- Compute map7 score\")\n",
    "print map7_score(y_val, y_preds, clients_last_choice[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "print map7_score(y_val, y_val, clients_last_choice[LC_TARGET_LABELS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for 2016/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train_df, test_df = load_train_test([201506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "months = list(set(full_train_df['fecha_dato'].unique()) | set(test_df['fecha_dato'].unique()))\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "    \n",
    "full_train_months = full_train_df['fecha_dato'].unique()\n",
    "test_months = test_df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201506\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = full_train_df\n",
    "df2 = test_df\n",
    "X, _, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(predicted_added_products, clients, clc, target_labels):\n",
    "    added_products_col = []\n",
    "    count = 0 \n",
    "    for products, last_choice in zip(predicted_added_products, clc):\n",
    "        predictions = remove_last_choice(products, last_choice)\n",
    "        added_products_col.append(' '.join([target_labels[i] for i in predictions]))\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            logging.info(\"Elapsed : %i\", count)\n",
    "            \n",
    "    out = pd.DataFrame(data={'ncodpers': clients, 'added_products': added_products_col}, columns=['ncodpers', 'added_products'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = predict_with_model(estimators, X, profiles, threshold=0.5)\n",
    "\n",
    "logging.info(\"- Get submission dataframe:\")\n",
    "clients = X['ncodpers'].values\n",
    "submission = get_submission(y_pred, clients, clients_last_choice[TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_clients = set(submission['ncodpers'].unique())\n",
    "test_clients = set(test_df['ncodpers'].unique())\n",
    "if submission_clients != test_clients:\n",
    "    missing_clients = list(test_clients - submission_clients)\n",
    "    missing_added_products = np.zeros((len(missing_clients)))\n",
    "    submission = pd.concat([submission, \n",
    "                            pd.DataFrame(data={\n",
    "                                'ncodpers': missing_clients, \n",
    "                                'added_products': missing_added_products\n",
    "                            }, columns=['ncodpers', 'added_products'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission DataFrame and write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "\n",
    "submission.to_csv(submission_file, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/submission_2016-11-17-16-37.csv', 'r') as r:\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
