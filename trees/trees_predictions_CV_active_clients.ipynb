{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees tryouts on SPR data, inspired by Kaggle Forum \"When less is more\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data as \n",
    "    month : [ Features | Targets| Difference | Last Choice Targets  ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://ipython.org/ipython-doc/3/config/extensions/autoreload.html\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../common\")\n",
    "\n",
    "from dataset import load_trainval, LC_TARGET_LABELS, TARGET_LABELS_FRQ, TARGET_LABELS_DIFF\n",
    "from utils import to_yearmonth, TARGET_LABELS, TARGET_LABELS2\n",
    "from utils import target_str_to_labels, decimal_to_dummies, targets_str_to_indices, targets_dec_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    u'ind_empleado', u'pais_residencia',\n",
    "    u'sexo', u'age', u'ind_nuevo', u'antiguedad', u'indrel',\n",
    "    u'ult_fec_cli_1t', u'indrel_1mes', u'tiprel_1mes', u'indresi',\n",
    "    u'indext', u'conyuemp', u'canal_entrada', u'indfall', u'nomprov',\n",
    "    u'ind_actividad_cliente', u'renta', u'segmento'    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train_yearmonths_list = [201504, 201505, 201604]\n",
    "# train_yearmonths_list = [201505, 201602, 201605]\n",
    "# # train_yearmonths_list = [201505]\n",
    "# #val_yearmonth = [201605]\n",
    "# train_nb_clients = 150000\n",
    "# # train_nb_clients = 1500\n",
    "# #train_df, val_df = load_trainval(train_yearmonths_list, val_yearmonth, train_nb_clients, val_nb_clients=1500)\n",
    "# train_df = load_trainval(train_yearmonths_list, train_nb_clients=train_nb_clients)\n",
    "filename = \"trainval_201505+201602+201605__150000.csv\"\n",
    "train_df = pd.read_csv('../data/generated/' + filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>ind_ahor_fin_ult1_frq</th>\n",
       "      <th>ind_aval_fin_ult1_frq</th>\n",
       "      <th>ind_cco_fin_ult1_frq</th>\n",
       "      <th>ind_cder_fin_ult1_frq</th>\n",
       "      <th>ind_cno_fin_ult1_frq</th>\n",
       "      <th>ind_ctju_fin_ult1_frq</th>\n",
       "      <th>ind_ctma_fin_ult1_frq</th>\n",
       "      <th>ind_ctop_fin_ult1_frq</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq</th>\n",
       "      <th>ind_plan_fin_ult1_frq</th>\n",
       "      <th>ind_pres_fin_ult1_frq</th>\n",
       "      <th>ind_reca_fin_ult1_frq</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq</th>\n",
       "      <th>ind_valo_fin_ult1_frq</th>\n",
       "      <th>ind_viv_fin_ult1_frq</th>\n",
       "      <th>ind_nomina_ult1_frq</th>\n",
       "      <th>ind_nom_pens_ult1_frq</th>\n",
       "      <th>ind_recibo_ult1_frq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.771587</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>15893</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>15893</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016-01-28</td>\n",
       "      <td>15893</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2016-02-28</td>\n",
       "      <td>15893</td>\n",
       "      <td>0.999878</td>\n",
       "      <td>0.999984</td>\n",
       "      <td>0.228413</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.897256</td>\n",
       "      <td>0.988464</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.835914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   fecha_dato  ncodpers  ind_ahor_fin_ult1_frq  ind_aval_fin_ult1_frq  \\\n",
       "0  2015-04-28     15889               0.999878               0.999984   \n",
       "1  2015-05-28     15889               0.999878               0.999984   \n",
       "2  2016-01-28     15889               0.999878               0.999984   \n",
       "3  2016-02-28     15889               0.999878               0.999984   \n",
       "4  2016-04-28     15889               0.999878               0.999984   \n",
       "5  2016-05-28     15889               0.999878               0.999984   \n",
       "6  2015-04-28     15893               0.999878               0.999984   \n",
       "7  2015-05-28     15893               0.999878               0.999984   \n",
       "8  2016-01-28     15893               0.999878               0.999984   \n",
       "9  2016-02-28     15893               0.999878               0.999984   \n",
       "\n",
       "   ind_cco_fin_ult1_frq  ind_cder_fin_ult1_frq  ind_cno_fin_ult1_frq  \\\n",
       "0              0.771587               0.999491              0.897256   \n",
       "1              0.771587               0.999491              0.897256   \n",
       "2              0.771587               0.999491              0.897256   \n",
       "3              0.771587               0.999491              0.897256   \n",
       "4              0.771587               0.999491              0.897256   \n",
       "5              0.771587               0.999491              0.897256   \n",
       "6              0.228413               0.999491              0.897256   \n",
       "7              0.228413               0.999491              0.897256   \n",
       "8              0.228413               0.999491              0.897256   \n",
       "9              0.228413               0.999491              0.897256   \n",
       "\n",
       "   ind_ctju_fin_ult1_frq  ind_ctma_fin_ult1_frq  ind_ctop_fin_ult1_frq  \\\n",
       "0               0.988464               0.990227               0.835914   \n",
       "1               0.988464               0.990227               0.835914   \n",
       "2               0.988464               0.990227               0.835914   \n",
       "3               0.988464               0.990227               0.835914   \n",
       "4               0.988464               0.990227               0.835914   \n",
       "5               0.988464               0.990227               0.835914   \n",
       "6               0.988464               0.990227               0.835914   \n",
       "7               0.988464               0.990227               0.835914   \n",
       "8               0.988464               0.990227               0.835914   \n",
       "9               0.988464               0.990227               0.835914   \n",
       "\n",
       "          ...           ind_hip_fin_ult1_frq  ind_plan_fin_ult1_frq  \\\n",
       "0         ...                       0.992618               0.987667   \n",
       "1         ...                       0.992618               0.987667   \n",
       "2         ...                       0.992618               0.987667   \n",
       "3         ...                       0.992618               0.987667   \n",
       "4         ...                       0.992618               0.987667   \n",
       "5         ...                       0.992618               0.987667   \n",
       "6         ...                       0.992618               0.987667   \n",
       "7         ...                       0.992618               0.987667   \n",
       "8         ...                       0.992618               0.987667   \n",
       "9         ...                       0.992618               0.987667   \n",
       "\n",
       "   ind_pres_fin_ult1_frq  ind_reca_fin_ult1_frq  ind_tjcr_fin_ult1_frq  \\\n",
       "0               0.996794               0.931887                0.94339   \n",
       "1               0.996794               0.931887                0.05661   \n",
       "2               0.996794               0.931887                0.05661   \n",
       "3               0.996794               0.931887                0.94339   \n",
       "4               0.996794               0.931887                0.94339   \n",
       "5               0.996794               0.931887                0.05661   \n",
       "6               0.996794               0.931887                0.94339   \n",
       "7               0.996794               0.931887                0.94339   \n",
       "8               0.996794               0.931887                0.94339   \n",
       "9               0.996794               0.931887                0.94339   \n",
       "\n",
       "   ind_valo_fin_ult1_frq  ind_viv_fin_ult1_frq  ind_nomina_ult1_frq  \\\n",
       "0               0.033643              0.995141             0.932789   \n",
       "1               0.033643              0.995141             0.932789   \n",
       "2               0.033643              0.995141             0.932789   \n",
       "3               0.033643              0.995141             0.932789   \n",
       "4               0.033643              0.995141             0.932789   \n",
       "5               0.033643              0.995141             0.932789   \n",
       "6               0.033643              0.995141             0.932789   \n",
       "7               0.033643              0.995141             0.932789   \n",
       "8               0.033643              0.995141             0.932789   \n",
       "9               0.033643              0.995141             0.932789   \n",
       "\n",
       "   ind_nom_pens_ult1_frq  ind_recibo_ult1_frq  \n",
       "0               0.927527             0.839655  \n",
       "1               0.927527             0.839655  \n",
       "2               0.927527             0.839655  \n",
       "3               0.927527             0.839655  \n",
       "4               0.927527             0.839655  \n",
       "5               0.927527             0.839655  \n",
       "6               0.927527             0.839655  \n",
       "7               0.927527             0.839655  \n",
       "8               0.927527             0.839655  \n",
       "9               0.927527             0.839655  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['fecha_dato', 'ncodpers'] + TARGET_LABELS_FRQ.tolist()].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_common_clients(df1, mask1, mask2, df2=None):\n",
    "    active_clients1 = df1[mask1]['ncodpers'].unique()\n",
    "    if df2 is not None:\n",
    "        active_clients2 = df2[mask2]['ncodpers'].unique()\n",
    "    else:\n",
    "        active_clients2 = df1[mask2]['ncodpers'].unique()\n",
    "    active_clients = list(set(active_clients1) & set(active_clients2)) \n",
    "    \n",
    "    if df2 is not None:\n",
    "        return df1['ncodpers'].isin(active_clients), df2['ncodpers'].isin(active_clients)\n",
    "    return df1['ncodpers'].isin(active_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "# months = list(set(train_df['fecha_dato'].unique()) | set(val_df['fecha_dato'].unique()))\n",
    "months = train_df['fecha_dato'].unique()\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "\n",
    "        \n",
    "train_months = train_df['fecha_dato'].unique()\n",
    "# val_months = val_df['fecha_dato'].unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import get_added_products, remove_last_choice, apk, map7_score\n",
    "from visualization import visualize_train_test, visualize_folds, compare_two_datasets, compare_folds, compare_folds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_features = ['targets_diff', 'targets_logdiff', 'targets_logcount2_diff', 'targets_logcount2', 'targets_logcount1', 'targets_logDec']\n",
    "TARGET_LABELS_FRQ_PREV = [c + '_prev' for c in TARGET_LABELS_FRQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_XY(current_month, df1, next_year_month, df2, months_ym_map):\n",
    "    month_mask = df1['fecha_dato'] == months_ym_map[current_month]\n",
    "    next_year_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month]\n",
    "    next_year_prev_month_mask = df2['fecha_dato'] == months_ym_map[next_year_month - 1]\n",
    "    \n",
    "    # get common clients from df1 at this month and df2 at next year month\n",
    "    common_clients_mask1, common_clients_mask2 = get_common_clients(df1, month_mask, next_year_month_mask, df2)\n",
    "    common_clients_mask2, common_clients_mask3 = get_common_clients(df2, common_clients_mask2 & next_year_month_mask, next_year_prev_month_mask, df2)\n",
    "        \n",
    "    c1 = df1[common_clients_mask1 & month_mask]['ncodpers'].values\n",
    "    c2 = df2[common_clients_mask2 & next_year_month_mask]['ncodpers'].values\n",
    "    c3 = df2[common_clients_mask3 & next_year_prev_month_mask]['ncodpers'].values\n",
    "    assert (c1 == c2).all() and (c2 == c3).all(), \"Problem with common clients\" \n",
    "    \n",
    "    X = df1[common_clients_mask1 & month_mask][['ncodpers', 'fecha_dato'] + target_features + features + TARGET_LABELS_FRQ.tolist()]            \n",
    "   \n",
    "    if TARGET_LABELS[0] in df2.columns and TARGET_LABELS_DIFF[0] in df2.columns and not df2[next_year_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        Y = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str', 'lc_targets_str', 'targets_diff'] + TARGET_LABELS + TARGET_LABELS_DIFF.tolist()]    \n",
    "        assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        Y.index = X.index                \n",
    "    else:\n",
    "        Y = None\n",
    "        \n",
    "    if TARGET_LABELS_FRQ[0] in df2.columns and not df2[next_year_prev_month_mask][TARGET_LABELS].isnull().all().all():\n",
    "        # Add TARGET_LABELS_FRQ from previous month to X:\n",
    "        target_labels_frq = df2[common_clients_mask3 & next_year_prev_month_mask][['ncodpers'] + TARGET_LABELS_FRQ.tolist()]\n",
    "        assert (X['ncodpers'].values == target_labels_frq['ncodpers'].values).all(), \"There is a problem in alignment\"\n",
    "        target_labels_frq = target_labels_frq[TARGET_LABELS_FRQ]\n",
    "        target_labels_frq.columns = TARGET_LABELS_FRQ_PREV\n",
    "        target_labels_frq.index = X.index\n",
    "        X = pd.concat([X, target_labels_frq], axis=1)        \n",
    "\n",
    "    \n",
    "    if LC_TARGET_LABELS[0] in df2.columns:\n",
    "        clients_last_choice = df2[common_clients_mask2 & next_year_month_mask][['ncodpers', 'fecha_dato', 'targets_str'] + LC_TARGET_LABELS.tolist()]\n",
    "    else:\n",
    "        clients_last_choice = None\n",
    "        \n",
    "    return X, Y, clients_last_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df if months_ym_map[current_month] in train_months else val_df\n",
    "#df1 = train_df\n",
    "df2 = train_df if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = train_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert (X['ncodpers'].values == Y['ncodpers'].values).all(), \"WTF\"\n",
    "assert (X['ncodpers'].values == clients_last_choice['ncodpers'].values).all(), \"WTF\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149983, 75)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_diff</th>\n",
       "      <th>targets_logdiff</th>\n",
       "      <th>targets_logcount2_diff</th>\n",
       "      <th>targets_logcount2</th>\n",
       "      <th>targets_logcount1</th>\n",
       "      <th>targets_logDec</th>\n",
       "      <th>ind_empleado</th>\n",
       "      <th>pais_residencia</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_frq_prev</th>\n",
       "      <th>ind_plan_fin_ult1_frq_prev</th>\n",
       "      <th>ind_pres_fin_ult1_frq_prev</th>\n",
       "      <th>ind_reca_fin_ult1_frq_prev</th>\n",
       "      <th>ind_tjcr_fin_ult1_frq_prev</th>\n",
       "      <th>ind_valo_fin_ult1_frq_prev</th>\n",
       "      <th>ind_viv_fin_ult1_frq_prev</th>\n",
       "      <th>ind_nomina_ult1_frq_prev</th>\n",
       "      <th>ind_nom_pens_ult1_frq_prev</th>\n",
       "      <th>ind_recibo_ult1_frq_prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15889</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>-0.00042</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>14.571618</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15893</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.001453</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.839655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15895</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>14.781716</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>15897</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.098612</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>14.805207</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.072473</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>15900</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>13.287691</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.966357</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15916</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.234752</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15919</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>14.588785</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.966357</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15920</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>14.803952</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.068113</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15921</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>13.296737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.012333</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.033643</td>\n",
       "      <td>0.995141</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>15922</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>14.586867</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992618</td>\n",
       "      <td>0.987667</td>\n",
       "      <td>0.996794</td>\n",
       "      <td>0.931887</td>\n",
       "      <td>0.94339</td>\n",
       "      <td>0.966357</td>\n",
       "      <td>0.004859</td>\n",
       "      <td>0.932789</td>\n",
       "      <td>0.927527</td>\n",
       "      <td>0.160345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ncodpers  fecha_dato  targets_diff  targets_logdiff  \\\n",
       "1      15889  2015-05-28          32.0         3.496508   \n",
       "7      15893  2015-05-28           0.0         0.000000   \n",
       "13     15895  2015-05-28           0.0         0.000000   \n",
       "19     15897  2015-05-28          -2.0        -1.098612   \n",
       "25     15900  2015-05-28           0.0         0.000000   \n",
       "31     15916  2015-05-28           0.0         0.000000   \n",
       "37     15919  2015-05-28           0.0         0.000000   \n",
       "43     15920  2015-05-28           0.0         0.000000   \n",
       "49     15921  2015-05-28           0.0         0.000000   \n",
       "55     15922  2015-05-28           0.0         0.000000   \n",
       "\n",
       "    targets_logcount2_diff  targets_logcount2  targets_logcount1  \\\n",
       "1                 -0.00042           0.000047           0.000053   \n",
       "7                  0.00000           0.001413           0.001453   \n",
       "13                 0.00000           0.000002           0.000007   \n",
       "19                 0.00000           0.000002           0.000007   \n",
       "25                 0.00000           0.000261           0.000307   \n",
       "31                 0.00000           0.000007           0.000007   \n",
       "37                 0.00000           0.000058           0.000047   \n",
       "43                 0.00000           0.000052           0.000100   \n",
       "49                 0.00000           0.000002           0.000007   \n",
       "55                 0.00000           0.000064           0.000067   \n",
       "\n",
       "    targets_logDec  ind_empleado  pais_residencia            ...             \\\n",
       "1        14.571618             0                0            ...              \n",
       "7         2.833213             1                0            ...              \n",
       "13       14.781716             2                0            ...              \n",
       "19       14.805207             2                0            ...              \n",
       "25       13.287691             3                0            ...              \n",
       "31       13.234752             3                0            ...              \n",
       "37       14.588785             3                0            ...              \n",
       "43       14.803952             0                0            ...              \n",
       "49       13.296737             0                0            ...              \n",
       "55       14.586867             3                0            ...              \n",
       "\n",
       "    ind_hip_fin_ult1_frq_prev  ind_plan_fin_ult1_frq_prev  \\\n",
       "1                    0.992618                    0.987667   \n",
       "7                    0.992618                    0.987667   \n",
       "13                   0.992618                    0.012333   \n",
       "19                   0.992618                    0.012333   \n",
       "25                   0.992618                    0.987667   \n",
       "31                   0.992618                    0.012333   \n",
       "37                   0.992618                    0.987667   \n",
       "43                   0.992618                    0.987667   \n",
       "49                   0.992618                    0.012333   \n",
       "55                   0.992618                    0.987667   \n",
       "\n",
       "    ind_pres_fin_ult1_frq_prev  ind_reca_fin_ult1_frq_prev  \\\n",
       "1                     0.996794                    0.931887   \n",
       "7                     0.996794                    0.931887   \n",
       "13                    0.996794                    0.068113   \n",
       "19                    0.996794                    0.068113   \n",
       "25                    0.996794                    0.068113   \n",
       "31                    0.996794                    0.068113   \n",
       "37                    0.996794                    0.068113   \n",
       "43                    0.996794                    0.068113   \n",
       "49                    0.996794                    0.931887   \n",
       "55                    0.996794                    0.931887   \n",
       "\n",
       "    ind_tjcr_fin_ult1_frq_prev  ind_valo_fin_ult1_frq_prev  \\\n",
       "1                      0.94339                    0.033643   \n",
       "7                      0.94339                    0.033643   \n",
       "13                     0.05661                    0.033643   \n",
       "19                     0.05661                    0.033643   \n",
       "25                     0.94339                    0.966357   \n",
       "31                     0.05661                    0.033643   \n",
       "37                     0.94339                    0.966357   \n",
       "43                     0.94339                    0.033643   \n",
       "49                     0.05661                    0.033643   \n",
       "55                     0.94339                    0.966357   \n",
       "\n",
       "    ind_viv_fin_ult1_frq_prev  ind_nomina_ult1_frq_prev  \\\n",
       "1                    0.995141                  0.932789   \n",
       "7                    0.995141                  0.932789   \n",
       "13                   0.995141                  0.932789   \n",
       "19                   0.995141                  0.932789   \n",
       "25                   0.995141                  0.932789   \n",
       "31                   0.995141                  0.932789   \n",
       "37                   0.995141                  0.932789   \n",
       "43                   0.995141                  0.932789   \n",
       "49                   0.995141                  0.932789   \n",
       "55                   0.004859                  0.932789   \n",
       "\n",
       "    ind_nom_pens_ult1_frq_prev  ind_recibo_ult1_frq_prev  \n",
       "1                     0.927527                  0.839655  \n",
       "7                     0.927527                  0.839655  \n",
       "13                    0.927527                  0.160345  \n",
       "19                    0.072473                  0.160345  \n",
       "25                    0.927527                  0.160345  \n",
       "31                    0.927527                  0.160345  \n",
       "37                    0.927527                  0.160345  \n",
       "43                    0.927527                  0.160345  \n",
       "49                    0.927527                  0.160345  \n",
       "55                    0.927527                  0.160345  \n",
       "\n",
       "[10 rows x 75 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print X.shape\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149983, 53)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>targets_str</th>\n",
       "      <th>lc_targets_str</th>\n",
       "      <th>ind_ahor_fin_ult1_diff</th>\n",
       "      <th>ind_aval_fin_ult1_diff</th>\n",
       "      <th>ind_cco_fin_ult1_diff</th>\n",
       "      <th>ind_cder_fin_ult1_diff</th>\n",
       "      <th>ind_cno_fin_ult1_diff</th>\n",
       "      <th>ind_ctju_fin_ult1_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_diff</th>\n",
       "      <th>ind_plan_fin_ult1_diff</th>\n",
       "      <th>ind_pres_fin_ult1_diff</th>\n",
       "      <th>ind_reca_fin_ult1_diff</th>\n",
       "      <th>ind_tjcr_fin_ult1_diff</th>\n",
       "      <th>ind_valo_fin_ult1_diff</th>\n",
       "      <th>ind_viv_fin_ult1_diff</th>\n",
       "      <th>ind_nomina_ult1_diff</th>\n",
       "      <th>ind_nom_pens_ult1_diff</th>\n",
       "      <th>ind_recibo_ult1_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>15889</td>\n",
       "      <td>001000001000000000110000</td>\n",
       "      <td>001000001000000000010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>15988</td>\n",
       "      <td>001000000000000000100000</td>\n",
       "      <td>001000000000000000000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>16525</td>\n",
       "      <td>001010001000110100100111</td>\n",
       "      <td>001010000000110100100111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>16680</td>\n",
       "      <td>000010000000000011000111</td>\n",
       "      <td>000000000000000011000111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>16826</td>\n",
       "      <td>001000000000000000001001</td>\n",
       "      <td>001000000000000000001000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>17151</td>\n",
       "      <td>000010010000001001110111</td>\n",
       "      <td>000010010000001001010111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>17231</td>\n",
       "      <td>001000000000000001110001</td>\n",
       "      <td>001000000000000001010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>17458</td>\n",
       "      <td>001000000000000000010000</td>\n",
       "      <td>000000000000000000010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>17525</td>\n",
       "      <td>000010011001010000100110</td>\n",
       "      <td>000010011001010000100001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>17528</td>\n",
       "      <td>000010000001100001110111</td>\n",
       "      <td>000010000001100001110011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fecha_dato  ncodpers               targets_str  \\\n",
       "1     2016-05-28     15889  001000001000000000110000   \n",
       "139   2016-05-28     15988  001000000000000000100000   \n",
       "433   2016-05-28     16525  001010001000110100100111   \n",
       "589   2016-05-28     16680  000010000000000011000111   \n",
       "655   2016-05-28     16826  001000000000000000001001   \n",
       "811   2016-05-28     17151  000010010000001001110111   \n",
       "877   2016-05-28     17231  001000000000000001110001   \n",
       "1039  2016-05-28     17458  001000000000000000010000   \n",
       "1111  2016-05-28     17525  000010011001010000100110   \n",
       "1123  2016-05-28     17528  000010000001100001110111   \n",
       "\n",
       "                lc_targets_str  ind_ahor_fin_ult1_diff  \\\n",
       "1     001000001000000000010000                     0.0   \n",
       "139   001000000000000000000000                     0.0   \n",
       "433   001010000000110100100111                     0.0   \n",
       "589   000000000000000011000111                     0.0   \n",
       "655   001000000000000000001000                     0.0   \n",
       "811   000010010000001001010111                     0.0   \n",
       "877   001000000000000001010001                     0.0   \n",
       "1039  000000000000000000010000                     0.0   \n",
       "1111  000010011001010000100001                     0.0   \n",
       "1123  000010000001100001110011                     0.0   \n",
       "\n",
       "      ind_aval_fin_ult1_diff  ind_cco_fin_ult1_diff  ind_cder_fin_ult1_diff  \\\n",
       "1                        0.0                    0.0                     0.0   \n",
       "139                      0.0                    0.0                     0.0   \n",
       "433                      0.0                    0.0                     0.0   \n",
       "589                      0.0                    0.0                     0.0   \n",
       "655                      0.0                    0.0                     0.0   \n",
       "811                      0.0                    0.0                     0.0   \n",
       "877                      0.0                    0.0                     0.0   \n",
       "1039                     0.0                    1.0                     0.0   \n",
       "1111                     0.0                    0.0                     0.0   \n",
       "1123                     0.0                    0.0                     0.0   \n",
       "\n",
       "      ind_cno_fin_ult1_diff  ind_ctju_fin_ult1_diff          ...           \\\n",
       "1                       0.0                     0.0          ...            \n",
       "139                     0.0                     0.0          ...            \n",
       "433                     0.0                     0.0          ...            \n",
       "589                     1.0                     0.0          ...            \n",
       "655                     0.0                     0.0          ...            \n",
       "811                     0.0                     0.0          ...            \n",
       "877                     0.0                     0.0          ...            \n",
       "1039                    0.0                     0.0          ...            \n",
       "1111                    0.0                     0.0          ...            \n",
       "1123                    0.0                     0.0          ...            \n",
       "\n",
       "      ind_hip_fin_ult1_diff  ind_plan_fin_ult1_diff  ind_pres_fin_ult1_diff  \\\n",
       "1                       0.0                     0.0                     0.0   \n",
       "139                     0.0                     0.0                     0.0   \n",
       "433                     0.0                     0.0                     0.0   \n",
       "589                     0.0                     0.0                     0.0   \n",
       "655                     0.0                     0.0                     0.0   \n",
       "811                     0.0                     0.0                     0.0   \n",
       "877                     0.0                     0.0                     0.0   \n",
       "1039                    0.0                     0.0                     0.0   \n",
       "1111                    0.0                     0.0                     0.0   \n",
       "1123                    0.0                     0.0                     0.0   \n",
       "\n",
       "      ind_reca_fin_ult1_diff  ind_tjcr_fin_ult1_diff  ind_valo_fin_ult1_diff  \\\n",
       "1                        0.0                     1.0                     0.0   \n",
       "139                      0.0                     1.0                     0.0   \n",
       "433                      0.0                     0.0                     0.0   \n",
       "589                      0.0                     0.0                     0.0   \n",
       "655                      0.0                     0.0                     0.0   \n",
       "811                      0.0                     1.0                     0.0   \n",
       "877                      0.0                     1.0                     0.0   \n",
       "1039                     0.0                     0.0                     0.0   \n",
       "1111                     0.0                     0.0                     0.0   \n",
       "1123                     0.0                     0.0                     0.0   \n",
       "\n",
       "      ind_viv_fin_ult1_diff  ind_nomina_ult1_diff  ind_nom_pens_ult1_diff  \\\n",
       "1                       0.0                   0.0                     0.0   \n",
       "139                     0.0                   0.0                     0.0   \n",
       "433                     0.0                   0.0                     0.0   \n",
       "589                     0.0                   0.0                     0.0   \n",
       "655                     0.0                   0.0                     0.0   \n",
       "811                     0.0                   0.0                     0.0   \n",
       "877                     0.0                   0.0                     0.0   \n",
       "1039                    0.0                   0.0                     0.0   \n",
       "1111                    0.0                   1.0                     1.0   \n",
       "1123                    0.0                   1.0                     0.0   \n",
       "\n",
       "      ind_recibo_ult1_diff  \n",
       "1                      0.0  \n",
       "139                    0.0  \n",
       "433                    0.0  \n",
       "589                    0.0  \n",
       "655                    1.0  \n",
       "811                    0.0  \n",
       "877                    0.0  \n",
       "1039                   0.0  \n",
       "1111                   0.0  \n",
       "1123                   0.0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Y.shape\n",
    "Y[Y['targets_diff'] > 0][['fecha_dato', 'ncodpers', 'targets_str', 'lc_targets_str'] + TARGET_LABELS_DIFF.tolist() ].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149983, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ncodpers</th>\n",
       "      <th>fecha_dato</th>\n",
       "      <th>targets_str</th>\n",
       "      <th>lc_ind_ahor_fin_ult1</th>\n",
       "      <th>lc_ind_aval_fin_ult1</th>\n",
       "      <th>lc_ind_cco_fin_ult1</th>\n",
       "      <th>lc_ind_cder_fin_ult1</th>\n",
       "      <th>lc_ind_cno_fin_ult1</th>\n",
       "      <th>lc_ind_ctju_fin_ult1</th>\n",
       "      <th>lc_ind_ctma_fin_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>lc_ind_hip_fin_ult1</th>\n",
       "      <th>lc_ind_plan_fin_ult1</th>\n",
       "      <th>lc_ind_pres_fin_ult1</th>\n",
       "      <th>lc_ind_reca_fin_ult1</th>\n",
       "      <th>lc_ind_tjcr_fin_ult1</th>\n",
       "      <th>lc_ind_valo_fin_ult1</th>\n",
       "      <th>lc_ind_viv_fin_ult1</th>\n",
       "      <th>lc_ind_nomina_ult1</th>\n",
       "      <th>lc_ind_nom_pens_ult1</th>\n",
       "      <th>lc_ind_recibo_ult1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15889</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000001000000000110000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15893</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000000000000000000010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15895</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000000100101110001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15897</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010010000110101110011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>15900</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000000010000000001000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15916</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>000010001000100101110001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15919</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000000001000001000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15920</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010000000001010001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15921</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010001010100110001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>15922</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>001000010000000000001001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ncodpers  fecha_dato               targets_str  lc_ind_ahor_fin_ult1  \\\n",
       "5      15889  2016-05-28  001000001000000000110000                   0.0   \n",
       "11     15893  2016-05-28  000000000000000000010000                   0.0   \n",
       "17     15895  2016-05-28  001000000000100101110001                   0.0   \n",
       "23     15897  2016-05-28  000010010000110101110011                   0.0   \n",
       "29     15900  2016-05-28  000000010000000001000001                   0.0   \n",
       "35     15916  2016-05-28  000010001000100101110001                   0.0   \n",
       "41     15919  2016-05-28  001000000001000001000001                   0.0   \n",
       "47     15920  2016-05-28  001000010000000001010001                   0.0   \n",
       "53     15921  2016-05-28  001000010001010100110001                   0.0   \n",
       "59     15922  2016-05-28  001000010000000000001001                   0.0   \n",
       "\n",
       "    lc_ind_aval_fin_ult1  lc_ind_cco_fin_ult1  lc_ind_cder_fin_ult1  \\\n",
       "5                    0.0                  1.0                   0.0   \n",
       "11                   0.0                  0.0                   0.0   \n",
       "17                   0.0                  1.0                   0.0   \n",
       "23                   0.0                  0.0                   0.0   \n",
       "29                   0.0                  0.0                   0.0   \n",
       "35                   0.0                  0.0                   0.0   \n",
       "41                   0.0                  1.0                   0.0   \n",
       "47                   0.0                  1.0                   0.0   \n",
       "53                   0.0                  1.0                   0.0   \n",
       "59                   0.0                  1.0                   0.0   \n",
       "\n",
       "    lc_ind_cno_fin_ult1  lc_ind_ctju_fin_ult1  lc_ind_ctma_fin_ult1  \\\n",
       "5                   0.0                   0.0                   0.0   \n",
       "11                  0.0                   0.0                   0.0   \n",
       "17                  0.0                   0.0                   0.0   \n",
       "23                  1.0                   0.0                   0.0   \n",
       "29                  1.0                   0.0                   0.0   \n",
       "35                  1.0                   0.0                   0.0   \n",
       "41                  0.0                   0.0                   0.0   \n",
       "47                  0.0                   0.0                   0.0   \n",
       "53                  0.0                   0.0                   0.0   \n",
       "59                  0.0                   0.0                   0.0   \n",
       "\n",
       "           ...          lc_ind_hip_fin_ult1  lc_ind_plan_fin_ult1  \\\n",
       "5          ...                          0.0                   0.0   \n",
       "11         ...                          0.0                   0.0   \n",
       "17         ...                          0.0                   1.0   \n",
       "23         ...                          0.0                   1.0   \n",
       "29         ...                          0.0                   0.0   \n",
       "35         ...                          0.0                   1.0   \n",
       "41         ...                          0.0                   0.0   \n",
       "47         ...                          0.0                   0.0   \n",
       "53         ...                          0.0                   1.0   \n",
       "59         ...                          0.0                   0.0   \n",
       "\n",
       "    lc_ind_pres_fin_ult1  lc_ind_reca_fin_ult1  lc_ind_tjcr_fin_ult1  \\\n",
       "5                    0.0                   0.0                   0.0   \n",
       "11                   0.0                   0.0                   0.0   \n",
       "17                   0.0                   1.0                   1.0   \n",
       "23                   0.0                   1.0                   1.0   \n",
       "29                   0.0                   1.0                   0.0   \n",
       "35                   0.0                   1.0                   1.0   \n",
       "41                   0.0                   1.0                   0.0   \n",
       "47                   0.0                   1.0                   0.0   \n",
       "53                   0.0                   0.0                   1.0   \n",
       "59                   0.0                   0.0                   0.0   \n",
       "\n",
       "    lc_ind_valo_fin_ult1  lc_ind_viv_fin_ult1  lc_ind_nomina_ult1  \\\n",
       "5                    1.0                  0.0                 0.0   \n",
       "11                   1.0                  0.0                 0.0   \n",
       "17                   1.0                  0.0                 0.0   \n",
       "23                   1.0                  0.0                 0.0   \n",
       "29                   0.0                  0.0                 0.0   \n",
       "35                   1.0                  0.0                 0.0   \n",
       "41                   0.0                  0.0                 0.0   \n",
       "47                   1.0                  0.0                 0.0   \n",
       "53                   1.0                  0.0                 0.0   \n",
       "59                   0.0                  1.0                 0.0   \n",
       "\n",
       "    lc_ind_nom_pens_ult1  lc_ind_recibo_ult1  \n",
       "5                    0.0                 0.0  \n",
       "11                   0.0                 0.0  \n",
       "17                   0.0                 1.0  \n",
       "23                   1.0                 1.0  \n",
       "29                   0.0                 1.0  \n",
       "35                   0.0                 1.0  \n",
       "41                   0.0                 1.0  \n",
       "47                   0.0                 1.0  \n",
       "53                   0.0                 1.0  \n",
       "59                   0.0                 1.0  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print clients_last_choice.shape\n",
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another train/predict + CV implementation\n",
    "\n",
    "### Input\n",
    "\n",
    "- `X` : `[nb_samples, nb_features]` shaped pd.DataFrame\n",
    "    - `features_masks_list` : `{fm1_name: features_mask_1, fm2_name: features_mask_2, ...]` with `features_mask_i` is a list of feature column names. They can oversect.\n",
    "    \n",
    "- `Y` : `[nb_samples, nb_labels]` shaped pd.DataFrame\n",
    "    - `labels_masks_list` : `{lm1_name: labels_mask_1, lm2_name: labels_mask_2, ...}` with `labels_mask_i` is a list of labels column names. They can oversect.\n",
    "\n",
    "- `samples_masks_list` : `[samples_mask_1, samples_mask_2, ...]` with samples_mask_i is a function to produce a boolean pd.DataFrame . Used only for training. \n",
    "\n",
    "\n",
    "- Set of models `models` : list of functions to create a model, e.g. `[create_RF, create_NN, create_GBT]`\n",
    "\n",
    "\n",
    "### Training phase\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples_masks_list = [\n",
    "#     'all',\n",
    "#     lambda x:  ~(x['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  x['targets_diff'] > 0, \n",
    "#     lambda x, y:  x['targets_diff'] < 0, \n",
    "#     lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  ~(y['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  (x['targets_diff'] > 0) | (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  (x['targets_diff'] < 0) | (y['targets_diff'] < 0), \n",
    "    lambda x, y:  (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  y['targets_diff'] < 0, \n",
    "]\n",
    "\n",
    "features_masks_dict = {\n",
    "#     'fm_all': None,\n",
    "    'fm0': features + target_features + TARGET_LABELS_FRQ.tolist() + TARGET_LABELS_FRQ_PREV,\n",
    "    'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm2': target_features,\n",
    "#     'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "#     'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "#     'fm6': TARGET_LABELS_FRQ,\n",
    "#     'fm7': TARGET_LABELS_FRQ_PREV,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/\n",
    "\n",
    "def create_RF(input_shape, output_shape):        \n",
    "    # https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "    return RandomForestClassifier(n_estimators=100, \n",
    "#                                   min_samples_split=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "#                                   oob_score=True,\n",
    "#                                   bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "                                 )\n",
    "\n",
    "def create_ET(input_shape, output_shape):\n",
    "    return ExtraTreesClassifier(n_estimators=100,\n",
    "#                                   min_samples_leaf=25,\n",
    "#                                   max_depth=10\n",
    "                                  max_features=1.0, \n",
    "                                  oob_score=True,\n",
    "                                  bootstrap=True,\n",
    "                                  n_jobs=-1\n",
    "\n",
    "                               )\n",
    "\n",
    "def create_GB(input_shape, output_shape):\n",
    "    return GradientBoostingClassifier(n_estimators=75)\n",
    "\n",
    "models_dict = {\n",
    "    'rf': create_RF,\n",
    "#     'et': create_ET,\n",
    "#     'gb': create_GB,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lm_0  <=>  [2, 3, 4, 5, 16] <==> ['Current Accounts' 'Derivada Account' 'Payroll Account' 'Junior Account'\n",
      " 'Loans']\n",
      "lm_1  <=>  [2, 6, 7, 8, 11] <==> ['Current Accounts' 'Mas particular Account' 'particular Account'\n",
      " 'particular Plus Account' 'Long-term deposits']\n",
      "lm_2  <=>  [2, 8, 18, 23, 12] <==> ['Current Accounts' 'particular Plus Account' 'Credit Card' 'Direct Debit'\n",
      " 'e-account']\n",
      "lm_3  <=>  [7, 12, 18, 17] <==> ['particular Account' 'e-account' 'Credit Card' 'Taxes']\n",
      "lm_4  <=>  [12, 11, 23, 5] <==> ['e-account' 'Long-term deposits' 'Direct Debit' 'Junior Account']\n",
      "lm_5  <=>  [21, 23, 22, 4] <==> ['Payroll' 'Direct Debit' 'Pensions' 'Payroll Account']\n",
      "lm_6  <=>  [22, 7, 8, 17] <==> ['Pensions' 'particular Account' 'particular Plus Account' 'Taxes']\n",
      "lm_others <=> [0, 1, 9, 10, 13, 14, 15, 19, 20] <==> ['Saving Account' 'Guarantees' 'Short-term deposits' 'Medium-term deposits'\n",
      " 'Funds' 'Mortgage' 'Pensions (plan fin)' 'Securities' 'Home Account']\n"
     ]
    }
   ],
   "source": [
    "NP_TARGET_LABELS = np.array(TARGET_LABELS)\n",
    "target_labels = TARGET_LABELS_DIFF\n",
    "\n",
    "common_groups = [\n",
    "    [2, 3, 4, 5, 16],\n",
    "    [2, 6, 7, 8, 11],\n",
    "    [2, 8, 18, 23, 12], \n",
    "    [7, 12, 18, 17],\n",
    "    [12, 11, 23, 5],\n",
    "#     [2, 18, 23],\n",
    "#     [18, 23, 21, 22],\n",
    "    [21, 23, 22, 4],\n",
    "    [22, 7, 8, 17],\n",
    "#     [0, 1, 14, 15, 17]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def flatten(array):\n",
    "    out = []\n",
    "    for item in array:\n",
    "        out += item\n",
    "    return out\n",
    "\n",
    "others = list(set(range(24)) - set(flatten(common_groups)))\n",
    "\n",
    "# for i, a in enumerate(zip(TARGET_LABELS2, TARGET_LABELS)):\n",
    "#     print i, a\n",
    "    \n",
    "s = set({})\n",
    "labels_masks_dict = {}\n",
    "for i, g in enumerate(common_groups):\n",
    "    print 'lm_%i' % i, \" <=> \", g, \"<==>\", TARGET_LABELS2[g]\n",
    "    labels_masks_dict['lm_%i' % i] = target_labels[g]\n",
    "    s |= set(g)\n",
    "    \n",
    "print 'lm_others', \"<=>\", others, \"<==>\", TARGET_LABELS2[others]\n",
    "labels_masks_dict['lm_others'] = target_labels[others]\n",
    "s |= set(others)\n",
    "\n",
    "assert len(s) == len(target_labels), \"Sum is not equal 24, s=%i\" % s\n",
    "# print labels_masks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {model_name: [(samples_mask_code, features_mask_name, labels_mask_name), ...]}\n",
    "models_pipelines = {\n",
    "    #'gb' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "    #'rf' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "    #'et' : [(None, None, key) for key in labels_masks_dict if len(labels_masks_dict[key]) > 1],\n",
    "\n",
    "#    'et': [(0, None, 'lm_1')],\n",
    "#    'rf': [(0, None, 'lm_1')],\n",
    "}\n",
    "models_pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import train_all, predict_all, probas_to_indices, score_estimators\n",
    "from utils import map7_score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103316, 75) (103316, 53) (103316, 27)\n",
      "(46667, 75) (46667, 53) (46667, 27)\n"
     ]
    }
   ],
   "source": [
    "ll = 140000\n",
    "# ll = 1100\n",
    "\n",
    "mask = (X.index.isin((X.index[:ll//3]))) | (X.index.isin((X.index[2*ll//3:])))\n",
    "\n",
    "X1 = X[mask]\n",
    "Y1 = Y[mask]\n",
    "clc1 = clients_last_choice[mask]\n",
    "print X1.shape, Y1.shape, clc1.shape\n",
    "\n",
    "mask = X.index.isin(X.index[ll//3:2*ll//3])\n",
    "X2 = X[mask]\n",
    "Y2 = Y[mask]\n",
    "clc2 = clients_last_choice[mask]\n",
    "print X2.shape, Y2.shape, clc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import dummies_to_decimal\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def prepare_to_fit(X_train, Y_train):    \n",
    "    x_train = X_train.values\n",
    "    x_train = StandardScaler().fit_transform(x_train)\n",
    "    y_train = Y_train.apply(dummies_to_decimal, axis=1)\n",
    "    y_train = y_train.values    \n",
    "    return x_train, y_train\n",
    "\n",
    "\n",
    "def prepare_to_test(X_val, Y_val=None):\n",
    "    x_val = X_val.values\n",
    "    x_val = StandardScaler().fit_transform(x_val)\n",
    "    if Y_val is not None:\n",
    "        y_val = Y_val.apply(dummies_to_decimal, axis=1)\n",
    "        y_val = y_val.values \n",
    "    else:\n",
    "        y_val = None\n",
    "    return x_val, y_val\n",
    "\n",
    "\n",
    "def probas_to_labels_probas(y_probas, class_indices, labels):\n",
    "    l = len(labels)\n",
    "    out = np.zeros((len(y_probas), l))\n",
    "    i = 0\n",
    "    for probas in y_probas:\n",
    "        if np.sum(probas) > 0:\n",
    "            pr = np.zeros((l,))\n",
    "            for index, p in zip(class_indices, probas):\n",
    "                if index == 0:\n",
    "                    pr -= p*np.ones((l,))\n",
    "                else:\n",
    "                    dummies_str = decimal_to_dummies(index, l)\n",
    "                    pr += p * np.array([float(v) for v in dummies_str])\n",
    "            out[i, :] = pr    \n",
    "        i += 1\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #len(labels_masks_dict['lm_1'])\n",
    "# res = Y1[labels_masks_dict['lm_1']].apply(dummies_to_decimal, axis=1)\n",
    "# _uniques = res.unique()\n",
    "# print _uniques\n",
    "# print decimal_to_dummies(0, len(labels_masks_dict['lm_1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _y_probas = np.zeros((10, len(_uniques)))\n",
    "\n",
    "# _y_probas[0, 0] = 0.71\n",
    "# _y_probas[0, 5] = 0.15\n",
    "# _y_probas[0, 6] = 0.14\n",
    "# _y_probas[1, 1] = 1.0\n",
    "# _y_probas[2, 2] = 0.0\n",
    "# _y_probas[3, 3] = 1.0\n",
    "# _y_probas[4, 4] = 1.0\n",
    "# _y_probas[5, 5] = 0.0\n",
    "# _y_probas[6, 6] = 1.0\n",
    "# _y_probas[7, 4] = 1.0\n",
    "# _y_probas[8, 2] = 1.0\n",
    "# _y_probas[9, 0] = 0.35\n",
    "# _y_probas[9, 3] = 0.75\n",
    "\n",
    "# print \"Probas : \\n\", _y_probas\n",
    "\n",
    "# # print np.argsort(_y_probas, axis=1)[:, ::-1], np.argmax(_y_probas, axis=1)\n",
    "\n",
    "# # print \"Uniques  :\", _uniques, len(_uniques)\n",
    "# print \"Class indices: \", _uniques\n",
    "# print \"Max proba class indices: \\n\", _uniques[np.argsort(_y_probas, axis=1)[:, ::-1]]\n",
    "\n",
    "# # print _uniques[np.argmax(_y_probas, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _l = len(labels_masks_dict['lm_1'])\n",
    "# class_indices_ = _uniques[np.argsort(_y_probas, axis=1)[:, ::-1]]\n",
    "\n",
    "# i = 0\n",
    "# for probas in _y_probas:\n",
    "#     print \"----\"\n",
    "#     print np.sum(probas), np.sum(probas) == 0\n",
    "#     if np.sum(probas) == 0:\n",
    "#         continue\n",
    "#     pr = np.zeros((_l,))\n",
    "#     for index, p in zip(_uniques, probas):\n",
    "#         if index == 0:\n",
    "#             pr -= p * np.ones((_l,))\n",
    "#         else:\n",
    "#             dummies_str = decimal_to_dummies(index, _l)\n",
    "#             pr += p * np.array([float(v) for v in dummies_str])\n",
    "#             print index, dummies_str, p, pr\n",
    "#     i += 1\n",
    "# #     if i == 2:\n",
    "# #         break\n",
    "\n",
    "# # _y_labels_probas = probas_to_labels_probas(_y_probas, _uniques, labels_masks_dict['lm_0'])\n",
    "# # print _y_labels_probas.shape\n",
    "# # for _y in _y_labels_probas:\n",
    "# #     print _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _Y_probas = pd.DataFrame(index=np.arange(10), columns=labels_masks_dict['lm_0'])\n",
    "# _Y_probas = _Y_probas.fillna(0.0)\n",
    "\n",
    "# from trainval import merge_probas\n",
    "\n",
    "# _Y_probas = merge_probas(_Y_probas, _y_labels_probas, labels_masks_dict['lm_0'], mode='sum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# _Y_probas.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "_kwargs = {\n",
    "    'samples_masks_list': samples_masks_list, \n",
    "    'features_masks_dict': features_masks_dict, \n",
    "    'labels_masks_dict': labels_masks_dict, \n",
    "    'models_dict': models_dict,\n",
    "    'labels': target_labels,\n",
    "    'transform_proba_func': probas_to_indices,\n",
    "#     'prepare_to_fit_func': prepare_to_fit,\n",
    "#     'prepare_to_test_func': prepare_to_test,   \n",
    "#     'probas_to_labels_probas_func': probas_to_labels_probas,\n",
    "    'threshold': 0.4,\n",
    "    'n_highest': 7,\n",
    "    'mode': 'sum',\n",
    "    'verbose': False,\n",
    "    'models_pipelines': models_pipelines,\n",
    "    'return_probas': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999696\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999696\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999393\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_others\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.989675\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.843911\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.870635\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.313088\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.737625\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.592773\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.428788\n",
      "INFO:root:-- Process : sample_mask=3293/103316, features_mask=fm1, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.790768\n"
     ]
    }
   ],
   "source": [
    "estimators = train_all(X1, Y1, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rf': 0.84787807470391741}"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = defaultdict(list)\n",
    "for e in estimators:\n",
    "    accuracies[e[0][2]].append(e[2])\n",
    "\n",
    "mean_accuracy = {}\n",
    "for key in accuracies:\n",
    "    accuracy_list = accuracies[key]\n",
    "    mean_accuracy[key] = sum(accuracy_list)/len(accuracy_list)\n",
    "    \n",
    "mean_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_others -> 0.996614309898\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_0 -> 0.903743544689\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_1 -> 0.899565003107\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_2 -> 0.32952621767\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_3 -> 0.956928879079\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_4 -> 0.444403968543\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_5 -> 0.496882165127\n",
      "INFO:root:-- Score : model=rf, features_mask=fm0, labels_mask=lm_6 -> 0.972207341376\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_others -> 0.999657145306\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_0 -> 0.991042921122\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_1 -> 0.993292905051\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_2 -> 0.796172884479\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_3 -> 0.986092956479\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_4 -> 0.818115584889\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_5 -> 0.814579895858\n",
      "INFO:root:-- Score : model=rf, features_mask=fm1, labels_mask=lm_6 -> 0.985707244948\n"
     ]
    }
   ],
   "source": [
    "_ = score_estimators(estimators, X2, Y2, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Predict all --\n"
     ]
    }
   ],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "# _y_probas = predict_all(estimators, X2, **_kwargs)\n",
    "#print y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[] [2] [21] [23] [23]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ind_ahor_fin_ult1_diff</th>\n",
       "      <th>ind_aval_fin_ult1_diff</th>\n",
       "      <th>ind_cco_fin_ult1_diff</th>\n",
       "      <th>ind_cder_fin_ult1_diff</th>\n",
       "      <th>ind_cno_fin_ult1_diff</th>\n",
       "      <th>ind_ctju_fin_ult1_diff</th>\n",
       "      <th>ind_ctma_fin_ult1_diff</th>\n",
       "      <th>ind_ctop_fin_ult1_diff</th>\n",
       "      <th>ind_ctpp_fin_ult1_diff</th>\n",
       "      <th>ind_deco_fin_ult1_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>ind_hip_fin_ult1_diff</th>\n",
       "      <th>ind_plan_fin_ult1_diff</th>\n",
       "      <th>ind_pres_fin_ult1_diff</th>\n",
       "      <th>ind_reca_fin_ult1_diff</th>\n",
       "      <th>ind_tjcr_fin_ult1_diff</th>\n",
       "      <th>ind_valo_fin_ult1_diff</th>\n",
       "      <th>ind_viv_fin_ult1_diff</th>\n",
       "      <th>ind_nomina_ult1_diff</th>\n",
       "      <th>ind_nom_pens_ult1_diff</th>\n",
       "      <th>ind_recibo_ult1_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.999089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280021</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ind_ahor_fin_ult1_diff  ind_aval_fin_ult1_diff  ind_cco_fin_ult1_diff  \\\n",
       "279997                     0.0                     0.0               0.000000   \n",
       "280003                     0.0                     0.0               2.999089   \n",
       "280009                     0.0                     0.0               0.000000   \n",
       "280015                     0.0                     0.0               0.000000   \n",
       "280021                     0.0                     0.0               0.000000   \n",
       "\n",
       "        ind_cder_fin_ult1_diff  ind_cno_fin_ult1_diff  ind_ctju_fin_ult1_diff  \\\n",
       "279997                     0.0                    0.0                     0.0   \n",
       "280003                     0.0                    0.0                     0.0   \n",
       "280009                     0.0                    0.0                     0.0   \n",
       "280015                     0.0                    0.0                     0.0   \n",
       "280021                     0.0                    0.0                     0.0   \n",
       "\n",
       "        ind_ctma_fin_ult1_diff  ind_ctop_fin_ult1_diff  \\\n",
       "279997                     0.0                     0.0   \n",
       "280003                     0.0                     0.0   \n",
       "280009                     0.0                     0.0   \n",
       "280015                     0.0                     0.0   \n",
       "280021                     0.0                     0.0   \n",
       "\n",
       "        ind_ctpp_fin_ult1_diff  ind_deco_fin_ult1_diff          ...           \\\n",
       "279997                     0.0                     0.0          ...            \n",
       "280003                     0.0                     0.0          ...            \n",
       "280009                     0.0                     0.0          ...            \n",
       "280015                     0.0                     0.0          ...            \n",
       "280021                     0.0                     0.0          ...            \n",
       "\n",
       "        ind_hip_fin_ult1_diff  ind_plan_fin_ult1_diff  ind_pres_fin_ult1_diff  \\\n",
       "279997                    0.0                     0.0                     0.0   \n",
       "280003                    0.0                     0.0                     0.0   \n",
       "280009                    0.0                     0.0                     0.0   \n",
       "280015                    0.0                     0.0                     0.0   \n",
       "280021                    0.0                     0.0                     0.0   \n",
       "\n",
       "        ind_reca_fin_ult1_diff  ind_tjcr_fin_ult1_diff  \\\n",
       "279997                     0.0                     0.0   \n",
       "280003                     0.0                     0.0   \n",
       "280009                     0.0                     0.0   \n",
       "280015                     0.0                     0.0   \n",
       "280021                     0.0                     0.0   \n",
       "\n",
       "        ind_valo_fin_ult1_diff  ind_viv_fin_ult1_diff  ind_nomina_ult1_diff  \\\n",
       "279997                     0.0                    0.0                   0.0   \n",
       "280003                     0.0                    0.0                   0.0   \n",
       "280009                     0.0                    0.0                   1.0   \n",
       "280015                     0.0                    0.0                   0.0   \n",
       "280021                     0.0                    0.0                   0.0   \n",
       "\n",
       "        ind_nom_pens_ult1_diff  ind_recibo_ult1_diff  \n",
       "279997                     0.0                   0.0  \n",
       "280003                     0.0                   0.0  \n",
       "280009                     0.0                   0.0  \n",
       "280015                     0.0                   1.0  \n",
       "280021                     0.0                   2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print y_preds[:5]\n",
    "Y_probas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Y_probas_max = Y_probas.max(axis=1)\n",
    "# mask = Y_probas_max > 0\n",
    "# Y_probas.loc[mask, :] = Y_probas[mask].div(Y_probas_max[mask], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels_masks_dict['lm_0'], common_groups[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] []\n",
      " [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [21, 22] []\n",
      " [] [] [] [] [] [] [] [] [] [] [] [] [2, 23] [] [] [] [] [] [] [] [] [] []\n",
      " [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] [] []\n",
      " [] [] [] []]\n",
      "[[] [2] [21] [23] [23] [23] [] [2] [18] [2] [23] [] [2, 23] [] [23] [] []\n",
      " [18] [] [18] [23] [18] [] [2] [2] [2, 23] [] [2] [] [2] [2] [2] [18] [23]\n",
      " [] [] [18] [4, 19, 2] [] [] [23] [] [] [23] [2] [] [22, 21] [23] [] []\n",
      " [21, 22] [] [23] [] [18] [] [2, 23] [] [23] [] [18] [] [] [] [18] [23]\n",
      " [22, 21] [23] [22, 23, 21] [2] [23] [] [18] [] [23] [] [23] [] [23]\n",
      " [2, 23] [] [23] [] [23] [] [] [18, 19] [18] [] [23] [18] [] [] [4] [23]\n",
      " [2] [2, 23] [23, 19] [] [2, 23]]\n"
     ]
    }
   ],
   "source": [
    "y_val = targets_str_to_indices(Y2[target_labels].values)\n",
    "# y_val = targets_str_to_indices(Y2[labels].values)\n",
    "print y_val[:100]\n",
    "print y_preds[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# np.unique(y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Compute max map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0308569224506\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0191501608322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.019150160832184543"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.info(\"- Compute max map7 score\")\n",
    "map7_score(y_val, y_val, clc2[LC_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_val)\n",
    "logging.info(\"- Compute map7 score\")\n",
    "map7_score(y_val, y_preds, clc2[LC_TARGET_LABELS].values)\n",
    "# map7_score0(y_val, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On columns lm_0=['ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1','ind_ctju_fin_ult1']\n",
    "\n",
    "- Feature mask: all : 'fm6', 'fm4', 'fm5', 'fm2', 'fm3', 'fm0', 'fm1'\n",
    "- threshold = 0.0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "et | 0.007074370518592629 | 0.0075787893947 | lm_0 | all \n",
    "\n",
    "\n",
    "\n",
    "- Feature mask: fm0, fm1, fm3, fm4, fm5\n",
    "- threshold = 0.0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "rf + et + gb | 0.006920126730031681 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.0068805235951309 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.006936801734200433 | 0.0075787893947 | lm_0 | all \n",
    "gb | 0.0068805235951309 | 0.0075787893947 | lm_0 | all\n",
    "\n",
    "\n",
    "- Feature mask: fm0, fm1\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | ---\n",
    "rf + et + gb | 0.004627313656828414 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.004664832416208104 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.004952476238119059 | 0.0075787893947 | lm_0 | all \n",
    "gb | 0.004489744872436218 | 0.0075787893947 | lm_0 | all\n",
    "\n",
    "- Features mask: fm0\n",
    "\n",
    "Model | Map@7 | Max Map@7 | Labels mask | Samples mask\n",
    "--- | --- | --- | --- | ---\n",
    "rf + et + gb | 0.0021010505252626313 | 0.0075787893947 | lm_0 | all\n",
    "rf + et | 0.001950975487743872 | 0.0075787893947 | lm_0 | all\n",
    "rf | 0.001550775387693847 | 0.0075787893947 | lm_0 | all\n",
    "gb | 0.0013006503251625813 | 0.0075787893947 | lm_0 | all\n",
    "et | 0.0017008504252126063 | 0.0075787893947 | lm_0 | all\n",
    "et |  0.0014007003501750874 | 0.0075787893947 | lm_0 | x>0 or y>0\n",
    "rf |  0.0008254127063531766 | 0.0075787893947 | lm_0 | .\n",
    "\n",
    "--------------------------------------\n",
    "\n",
    "0.021295269099703414 (GB on 'all')\n",
    "\n",
    "0.021271936353906683 (RF tunning)\n",
    "\n",
    "0.021668245671284416 (RF tunning)\n",
    "\n",
    "0.02136609107928888\n",
    "\n",
    "0.0211362663776694"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print labels_masks_dict[estimators[0][0][1]]\n",
    "# print estimators[0][1].classes_\n",
    "# print estimators[0][1].n_classes_\n",
    "# print estimators[0][1].n_features_\n",
    "# print estimators[0][1].n_outputs_\n",
    "# print estimators[0][1].estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import targets_to_labels, targets_indices_to_labels, remove_last_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Count =  1\n",
      "['Current Accounts', 'Direct Debit']\n",
      "[] ['Credit Card']\n",
      "--- Count =  2\n",
      "['Payroll']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  3\n",
      "['e-account']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  4\n",
      "['Credit Card']\n",
      "[] []\n",
      "--- Count =  5\n",
      "['Payroll']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  6\n",
      "['Credit Card']\n",
      "[] []\n",
      "--- Count =  7\n",
      "['Securities']\n",
      "[] []\n",
      "--- Count =  8\n",
      "['Payroll', 'Pensions']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  9\n",
      "['Direct Debit']\n",
      "['Securities', 'Direct Debit'] ['Securities', 'Direct Debit']\n",
      "--- Count =  10\n",
      "['Payroll', 'Pensions']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  11\n",
      "['Payroll', 'Pensions']\n",
      "['Credit Card'] ['Credit Card']\n",
      "--- Count =  12\n",
      "['Credit Card']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  13\n",
      "['Credit Card']\n",
      "[] []\n",
      "--- Count =  14\n",
      "['Credit Card']\n",
      "['Payroll Account', 'Pensions', 'Payroll', 'Securities'] ['Payroll Account', 'Pensions', 'Direct Debit', 'Payroll', 'Securities']\n",
      "--- Count =  15\n",
      "['Payroll Account', 'Payroll', 'Pensions']\n",
      "['Credit Card'] ['Credit Card']\n",
      "--- Count =  16\n",
      "['Credit Card']\n",
      "[] []\n",
      "--- Count =  17\n",
      "['Credit Card']\n",
      "['Pensions', 'Payroll', 'Credit Card'] ['Pensions', 'Payroll', 'Credit Card']\n",
      "--- Count =  18\n",
      "['Credit Card']\n",
      "['Current Accounts', 'Credit Card'] ['Current Accounts', 'Credit Card']\n",
      "--- Count =  19\n",
      "['Credit Card']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  20\n",
      "['particular Account']\n",
      "[] []\n",
      "--- Count =  21\n",
      "['Credit Card']\n",
      "['Direct Debit'] ['Direct Debit']\n",
      "--- Count =  22\n",
      "['Direct Debit']\n",
      "[] []\n",
      "--- Count =  23\n",
      "['particular Plus Account']\n",
      "[] []\n",
      "--- Count =  24\n",
      "['Credit Card']\n",
      "['Pensions', 'Payroll', 'Credit Card'] ['Pensions', 'Payroll', 'Credit Card']\n"
     ]
    }
   ],
   "source": [
    "limit = 25\n",
    "count = 0\n",
    "\n",
    "not_predicted_predicted = defaultdict(int)\n",
    "for last_choice, targets, products, proba in zip(clc2[LC_TARGET_LABELS].values, y_val, y_preds, Y_probas.values):\n",
    "    added_products = remove_last_choice(targets, last_choice)\n",
    "    predictions = remove_last_choice(products, last_choice)\n",
    "#     print \"---\", count, last_choice\n",
    "#     print targets, '->', added_products\n",
    "#     print products, '->', predictions\n",
    "#     if count == 3:\n",
    "#         break\n",
    "    ll = len(added_products)\n",
    "    \n",
    "    if ll == 0:\n",
    "        continue\n",
    "        \n",
    "    if len(set(added_products) & set(predictions[:ll])) > 0:\n",
    "#         print \"Predicted : \", added_products, predictions\n",
    "#         print set(added_products) & set(predictions)\n",
    "        continue\n",
    "\n",
    "    count += 1\n",
    "    if count < limit:\n",
    "        print \"--- Count = \", count\n",
    "        print targets_indices_to_labels(added_products, TARGET_LABELS2)#, targets_indices_to_labels(targets, TARGET_LABELS2)\n",
    "        print targets_indices_to_labels(predictions, TARGET_LABELS2), targets_indices_to_labels(products, TARGET_LABELS2)#, proba\n",
    "    \n",
    "    for p in added_products:\n",
    "        not_predicted_predicted[TARGET_LABELS2[p]] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'Long-term deposits': 3, 'Direct Debit': 43, 'particular Account': 5, 'particular Plus Account': 14, 'e-account': 97, 'Payroll': 89, 'Pensions': 96, 'Taxes': 6, 'Payroll Account': 61, 'Securities': 11, 'Home Account': 1, 'Mas particular Account': 6, 'Funds': 3, 'Credit Card': 181, 'Current Accounts': 39, 'Junior Account': 2, 'Pensions (plan fin)': 1}) 46667\n"
     ]
    }
   ],
   "source": [
    "print not_predicted_predicted, y_val.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print y_probas[:10, target_groups[0]]\n",
    "#print Y[np.array(TARGET_LABELS)[target_groups[0]]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run KFold Cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from trainval import cross_val_score0, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Cross validation : \n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 1 / 3\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999814\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_3\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 1.000000\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_4\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999814\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_5\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999814\n",
      "INFO:root:-- Process : sample_mask=5384/99988, features_mask=fm0, labels_mask=lm_6\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999814\n",
      "INFO:root:-- Predict all --\n",
      "INFO:root:- Compute map7 score\n",
      "INFO:root:-- Predicted map7 score: 0.0326169839206\n",
      "INFO:root:\n",
      "\n",
      "\t\t-- Fold : 2 / 3\n",
      "\n",
      "INFO:root:-- Train all --\n",
      "INFO:root:-- Process : sample_mask=6814/99989, features_mask=fm0, labels_mask=lm_0\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999706\n",
      "INFO:root:-- Process : sample_mask=6814/99989, features_mask=fm0, labels_mask=lm_1\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999853\n",
      "INFO:root:-- Process : sample_mask=6814/99989, features_mask=fm0, labels_mask=lm_2\n",
      "INFO:root:--- Score : model='rf', fit accuracy : 0.999853\n",
      "INFO:root:-- Process : sample_mask=6814/99989, features_mask=fm0, labels_mask=lm_3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-b640f7249693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Unitary run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnb_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclients_last_choice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLC_TARGET_LABELS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/TDS/SPR/trees/trainval.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(data, nb_folds, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0mclc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclients_last_choice\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mestimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'return_probas'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_probas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vfomin/Documents/TDS/SPR/trees/trainval.py\u001b[0m in \u001b[0;36mtrain_all\u001b[0;34m(X_train, Y_train, samples_masks_list, features_masks_dict, labels_masks_dict, models_dict, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Fit the model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Score : model='%s', fit accuracy : %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    324\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 326\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Unitary run\n",
    "nb_folds = 3\n",
    "results = cross_val_score((X, Y, clients_last_choice[LC_TARGET_LABELS].values), nb_folds=nb_folds, **_kwargs)\n",
    "\n",
    "print \"Cross-Validation \\n %i | %f | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), np.median(results), results.max(), results.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "lm_0 + lm_1\n",
    "3 | 0.004194 | 0.004768 | 0.004746 | 0.005365 | 0.00048 \n",
    "\n",
    "\n",
    "\n",
    "Samples mask : 'all'\n",
    "Cross-Validation \n",
    " 3 | 0.004092 | 0.004696 | 0.004920 | 0.005077 | 0.00043 \n",
    "\n",
    "Samples mask : `lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0]))`\n",
    "Cross-Validation \n",
    " 3 | 0.003892 | 0.004593 | 0.004859 | 0.005028 | 0.00050 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ind_cco_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1',\n",
       "       'ind_ctpp_fin_ult1'], \n",
       "      dtype='|S17')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_masks_dict['lm_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "# CV on various combinations :\n",
    "\n",
    "_samples_masks_list = [\n",
    "#     'all',\n",
    "#     lambda x, y:  ~(x['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  x['targets_diff'] > 0, \n",
    "#     lambda x, y:  x['targets_diff'] < 0, \n",
    "    lambda x, y:  ~(x['targets_diff'].isin([0])) | ~(y['targets_diff'].isin([0])), \n",
    "#     lambda x, y:  (x['targets_diff'] > 0) | (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  (x['targets_diff'] < 0) | (y['targets_diff'] < 0), \n",
    "#     lambda x, y:  (y['targets_diff'] > 0), \n",
    "#     lambda x, y:  y['targets_diff'] < 0, \n",
    "]\n",
    "\n",
    "_features_masks_dict = {\n",
    "    'fm0': features + target_features + TARGET_LABELS_FRQ.tolist() + TARGET_LABELS_FRQ_PREV,\n",
    "    'fm1': ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "#     'fm2': target_features,\n",
    "    'fm3': ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#     'fm4': ['pais_residencia', 'sexo', 'age', 'renta', 'targets_logdiff', 'targets_logcount2_diff','targets_logcount2','targets_logcount1'],\n",
    "    'fm5': ['nomprov', 'ind_nuevo', 'renta', 'ind_actividad_cliente', 'canal_entrada'],\n",
    "#     'fm6': TARGET_LABELS_FRQ,\n",
    "}\n",
    "\n",
    "_models_dict = {\n",
    "    'rf': create_RF,\n",
    "    'et': create_ET,\n",
    "#     'gb': create_GB,\n",
    "}\n",
    "\n",
    "_labels_masks_dict = {\n",
    "#     'lm_0': labels_masks_dict['lm_0'],\n",
    "    'lm_1': labels_masks_dict['lm_1'],\n",
    "}\n",
    "\n",
    "nb_folds = 5\n",
    "\n",
    "def BruteForceSearchCV():\n",
    "    \n",
    "    def get_models_combinations(items):\n",
    "        combins = list(combinations(items, 1))\n",
    "        combins += list(combinations(items, len(items)))\n",
    "        return combins\n",
    "    \n",
    "    def get_combinations(items):\n",
    "        combins = list(combinations(items, 1))\n",
    "        for i in range(2, len(items)+1):\n",
    "            combins += list(combinations(items, i))\n",
    "        return combins\n",
    "    \n",
    "    def get_items(items):\n",
    "        out = [[items[0],], ]\n",
    "        for i in items[1:]:\n",
    "            tmp = list(out[-1])\n",
    "            tmp.append(i)\n",
    "            out.append(tmp)        \n",
    "        return out\n",
    "\n",
    "    \n",
    "    _labels_masks_combinations = get_items(sorted(_labels_masks_dict.keys()))\n",
    "    _features_masks_combinations = get_items(sorted(_features_masks_dict.keys()))\n",
    "    _models_combinations = get_models_combinations(_models_dict.keys())\n",
    "\n",
    "    # Very big loop:\n",
    "    for lm_keys in _labels_masks_combinations:\n",
    "        __labels_masks_dict = {}\n",
    "        for lm_key in lm_keys:\n",
    "            __labels_masks_dict[lm_key] = _labels_masks_dict[lm_key]\n",
    "\n",
    "        for i, sm in enumerate(_samples_masks_list):\n",
    "            __samples_masks_list = [sm]\n",
    "              \n",
    "            for fm_keys in _features_masks_combinations:\n",
    "                __features_masks_dict = {}\n",
    "                for fm_key in fm_keys:\n",
    "                    __features_masks_dict[fm_key] = _features_masks_dict[fm_key]\n",
    "                    \n",
    "                for m_keys in _models_combinations:\n",
    "                    __models_dict = {}\n",
    "                    for m_key in m_keys:\n",
    "                        __models_dict[m_key] = _models_dict[m_key]\n",
    "                    \n",
    "                    print \"\\n\\n---------------------------------------------------------------\" \n",
    "                    print \"--- PROCESS : \", __labels_masks_dict.keys(), i, __features_masks_dict.keys(), __models_dict.keys()\n",
    "                    print \"---------------------------------------------------------------\\n\" \n",
    "                    \n",
    "                    __kwargs = {\n",
    "                        'samples_masks_list': __samples_masks_list, \n",
    "                        'features_masks_dict': __features_masks_dict, \n",
    "                        'labels_masks_dict': __labels_masks_dict, \n",
    "                        'models_dict': __models_dict,\n",
    "                        'labels': target_labels,\n",
    "                        'transform_proba_func': probas_to_indices,\n",
    "                        'prepare_to_fit_func': prepare_to_fit,\n",
    "                        'prepare_to_test_func': prepare_to_test,   \n",
    "                        'probas_to_labels_probas_func': probas_to_labels_probas,\n",
    "                        'threshold': 0.0,\n",
    "                        'n_highest': 7,\n",
    "                        'mode': 'sum',\n",
    "                        'verbose': False,\n",
    "                        'return_probas': True\n",
    "                    }\n",
    "                    #  DEBUG : results = cross_val_score((X1, Y1, clc1[LC_TARGET_LABELS].values), nb_folds=nb_folds, **__kwargs)\n",
    "                    results = cross_val_score((X, Y, clients_last_choice[LC_TARGET_LABELS].values), nb_folds=nb_folds, **__kwargs)\n",
    "                    print \"=> CV : \", results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "--- PROCESS :  ['lm_1'] 0 ['fm0'] ['et']\n",
      "---------------------------------------------------------------\n",
      "\n",
      "=> CV :  [ 0.00400873  0.0040004   0.002228    0.00153632  0.00202851]\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "--- PROCESS :  ['lm_1'] 0 ['fm0'] ['rf']\n",
      "---------------------------------------------------------------\n",
      "\n",
      "=> CV :  [ 0.00387261  0.00366148  0.00220578  0.00153076  0.00205166]\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "--- PROCESS :  ['lm_1'] 0 ['fm0'] ['gb']\n",
      "---------------------------------------------------------------\n",
      "\n",
      "=> CV :  [ 0.00441526  0.00433469  0.00249747  0.0016141   0.00210723]\n",
      "\n",
      "\n",
      "---------------------------------------------------------------\n",
      "--- PROCESS :  ['lm_1'] 0 ['fm0'] ['et', 'rf', 'gb']\n",
      "---------------------------------------------------------------\n",
      "\n",
      "=> CV :  [ 0.00435044  0.00421153  0.00238913  0.00157521  0.00205537]\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.WARNING)\n",
    "BruteForceSearchCV()\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0'] ['et']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00530748  0.0037476   0.00342951  0.00471158  0.00654436]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0'] ['rf']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00528664  0.00354452  0.00316559  0.004406    0.0059906 ]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0'] ['gb']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00453656  0.00385566  0.0035573   0.00474492  0.00669623]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0'] ['et', 'rf', 'gb']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00556167  0.00380288  0.00356286  0.00480048  0.00664622]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0', 'fm1'] ['et']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.0051144   0.00350424  0.00357119  0.00466713  0.00656788]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0', 'fm1'] ['rf']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00530609  0.00353341  0.00353785  0.00450045  0.0064512 ]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0', 'fm1'] ['gb']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00541721  0.00355563  0.00356563  0.00464769  0.006654  ]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm0', 'fm1'] ['et', 'rf', 'gb']\n",
    "---------------------------------------------------------------\n",
    "\n",
    "=> CV :  [ 0.00528247  0.00358064  0.00356563  0.00457824  0.00661233]\n",
    "\n",
    "\n",
    "---------------------------------------------------------------\n",
    "--- PROCESS :  ['lm_0'] 0 ['fm2', 'fm0', 'fm1'] ['et']\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute cross-validation across several months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_folds = 3\n",
    "yms = [201504, 201505]\n",
    "#yms = [201505]\n",
    "\n",
    "for ym in yms:\n",
    "    logging.info(\"\\n-------------------------\")\n",
    "    logging.info(\"- Process month : %s\" % ym)\n",
    "    logging.info(\"-------------------------\\n\")\n",
    "    \n",
    "    ym1 = ym + 100    \n",
    "    df1 = train_df if months_ym_map[ym] in train_months else val_df\n",
    "    df2 = train_df if months_ym_map[ym1] in train_months else val_df\n",
    "    X, Y, clients_last_choice = get_XY(ym, df1, ym1, df2) \n",
    "    results = cross_val_score2((X, Y, clients_last_choice[LC_TARGET_LABELS].values), \n",
    "                                profiles=profiles,\n",
    "                                nb_folds=nb_folds)\n",
    "    print \"Cross-Validation \\n %i | %f | %f | %f | %.5f \" % (nb_folds, results.min(), results.mean(), results.max(), results.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201505\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = train_df\n",
    "#df1 = val_df\n",
    "df2 = train_df #if months_ym_map[next_year_month] in train_months else val_df\n",
    "#df2 = val_df\n",
    "\n",
    "X, Y, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "estimators = train_all(X, Y, **_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check score on the data 2016/05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.info(\"- Compute map7 score\")\n",
    "print map7_score(y_val, y_preds, clients_last_choice[LC_TARGET_LABELS].values)\n",
    "logging.info(\"- Compute max map7 score\")\n",
    "print map7_score(y_val, y_val, clients_last_choice[LC_TARGET_LABELS].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction for 2016/06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dataset import load_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "full_train_df, test_df = load_train_test([201506])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "months_ym_map = {}\n",
    "months = list(set(full_train_df['fecha_dato'].unique()) | set(test_df['fecha_dato'].unique()))\n",
    "for m in months:\n",
    "    months_ym_map[to_yearmonth(m)] = m\n",
    "    \n",
    "full_train_months = full_train_df['fecha_dato'].unique()\n",
    "test_months = test_df['fecha_dato'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_month = 201506\n",
    "next_year_month = current_month + 100\n",
    "\n",
    "df1 = full_train_df\n",
    "df2 = test_df\n",
    "X, _, clients_last_choice = get_XY(current_month, df1, next_year_month, df2, months_ym_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_submission(predicted_added_products, clients, clc, target_labels):\n",
    "    added_products_col = []\n",
    "    count = 0 \n",
    "    for products, last_choice in zip(predicted_added_products, clc):\n",
    "        predictions = remove_last_choice(products, last_choice)\n",
    "        added_products_col.append(' '.join([target_labels[i] for i in predictions]))\n",
    "        count+=1\n",
    "        if count % 100000 == 0:\n",
    "            logging.info(\"Elapsed : %i\", count)\n",
    "            \n",
    "    out = pd.DataFrame(data={'ncodpers': clients, 'added_products': added_products_col}, columns=['ncodpers', 'added_products'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_preds, Y_probas = predict_all(estimators, X, **_kwargs)\n",
    "\n",
    "logging.info(\"- Get submission dataframe:\")\n",
    "clients = X['ncodpers'].values\n",
    "submission = get_submission(y_pred, clients, clients_last_choice[TARGET_LABELS].values, TARGET_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_estimators = []\n",
    "for e in estimators:\n",
    "    # estimators = [([features_mask_name, labels_mask_name, model_name], estimator_object, accuracy), ...]\n",
    "    features_mask_name, labels_mask_name, model_name = e[0]\n",
    "#     if features_masks_dict[features_mask_name]\n",
    "#     if e[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_masks_dict[features_mask_name] in test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_clients = set(submission['ncodpers'].unique())\n",
    "test_clients = set(test_df['ncodpers'].unique())\n",
    "if submission_clients != test_clients:\n",
    "    missing_clients = list(test_clients - submission_clients)\n",
    "    missing_clients_mask = test_df['ncodpers'].isin(missing_clients)\n",
    "    \n",
    "    X1 = test_df[missing_clients_mask]\n",
    "    \n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    missing_added_products = np.zeros((len(missing_clients)))\n",
    "    submission = pd.concat([submission, \n",
    "                            pd.DataFrame(data={\n",
    "                                'ncodpers': missing_clients, \n",
    "                                'added_products': missing_added_products\n",
    "                            }, columns=['ncodpers', 'added_products'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get submission DataFrame and write csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print submission.shape\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "logging.info('- Generate submission')\n",
    "submission_file = '../results/submission_' + \\\n",
    "                  str(datetime.now().strftime(\"%Y-%m-%d-%H-%M\")) + \\\n",
    "                  '.csv'\n",
    "\n",
    "submission.to_csv(submission_file, index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../results/submission_2016-11-17-16-37.csv', 'r') as r:\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    print r.readline()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
