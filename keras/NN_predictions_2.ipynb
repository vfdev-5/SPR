{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN tryouts on SPR data, inspired by Kaggle Forum \"When less is more\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Load m month of data\n",
    "- Minimal data cleaning\n",
    "- Feature engineering\n",
    "\n",
    "- Setup model\n",
    "\n",
    "TRAIN : 201505, 201506\n",
    "\n",
    "- FEATURES <- get_profile(ALL_FEATURES) : Select some profiles\n",
    "\n",
    "- Train on all users\n",
    "- Select only users that added products in 201506 comparing to 201505\n",
    "\n",
    "\n",
    "month data is like [FEATURES|TARGETS]\n",
    "\n",
    "X_train = [FEATURES] of the training part\n",
    "Y_train = [TARGETS]  of the training part\n",
    "\n",
    "X_val = [FEATURES] of the validation part\n",
    "Y_val = [TARGETS]  of the validation part\n",
    "\n",
    "TEST :\n",
    "201606\n",
    "- All users\n",
    "[FEATURES]\n",
    "X_test = [FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "logging.getLogger().handlers = []\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from common import load_data2, minimal_clean_data_inplace, preprocess_data_inplace, TARGET_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_FILE_PATH = os.path.join(\"..\", \"data\", \"train_ver2.csv\")\n",
    "TEST_FILE_PATH = os.path.join(\"..\", \"data\", \"test_ver2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data + minimal cleaning + preprocessing\n",
    "\n",
    "* 201505 - to get the clients last choice \n",
    "* 201506 - to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yearmonth_list = [201505, 201506] \n",
    "nb_months = len(yearmonth_list)\n",
    "nb_clients = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:-- Select 100000 clients\n",
      "INFO:root:- Number of lines with unknown data : 568\n",
      "INFO:root:- Number of columns with nan : 9\n"
     ]
    }
   ],
   "source": [
    "data_df = load_data2(TRAIN_FILE_PATH, yearmonth_list, nb_clients)\n",
    "minimal_clean_data_inplace(data_df)\n",
    "preprocess_data_inplace(data_df)\n",
    "\n",
    "months = data_df['fecha_dato'].unique()\n",
    "clients = data_df['ncodpers'].unique()\n",
    "assert len(clients) == (data_df['ncodpers'].value_counts() == nb_months).sum()\n",
    "ll = len(clients)\n",
    "for m in months:\n",
    "    l = len(data_df[data_df['fecha_dato'] == m]['ncodpers'].unique())\n",
    "    assert l == ll, \"Number of clients should be identical for all monthes. (%s, %s, %s)\" % (m, l, ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    u'ind_empleado', u'pais_residencia',\n",
    "    u'sexo', u'age', u'ind_nuevo', u'antiguedad', u'indrel',\n",
    "    u'ult_fec_cli_1t', u'indrel_1mes', u'tiprel_1mes', u'indresi',\n",
    "    u'indext', u'conyuemp', u'canal_entrada', u'indfall', u'nomprov',\n",
    "    u'ind_actividad_cliente', u'renta', u'segmento'    \n",
    "]\n",
    "\n",
    "last_choice_mask = data_df['fecha_dato'] == months[-2]\n",
    "train_month_mask = data_df['fecha_dato'] == months[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "profiles = {\n",
    "     0: ['pais_residencia', 'sexo', 'age', 'ind_nuevo', 'segmento', 'ind_empleado', 'ind_actividad_cliente', 'indresi'],\n",
    "     1: ['pais_residencia', 'sexo', 'age', 'segmento', 'nomprov'],\n",
    "#      2: ['pais_residencia', 'sexo', 'age', 'segmento', 'antiguedad'],\n",
    "#      3: ['pais_residencia', 'sexo', 'age', 'segmento', 'ind_nuevo'],\n",
    "#      4: ['pais_residencia', 'sexo', 'age', 'segmento', 'ind_actividad_cliente'],\n",
    "#      5: ['pais_residencia', 'sexo', 'age', 'segmento', 'canal_entrada'],\n",
    "#      6: ['pais_residencia', 'sexo', 'age', 'segmento', 'ind_nuevo', 'canal_entrada'],\n",
    "#      7: ['pais_residencia', 'sexo', 'age', 'segmento', 'ind_empleado'],\n",
    "#      8: ['pais_residencia', 'sexo', 'age', 'segmento', 'renta'],\n",
    "#      9: ['sexo', 'age', 'segmento'],    \n",
    "#      10: ['sexo', 'age', 'segmento', 'ind_actividad_cliente']\n",
    "#      11: ['nomprov', 'ind_nuevo', 'antiguedad', 'renta', 'ind_actividad_cliente', 'canal_entrada']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models for profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Merge\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    ll = len(TARGET_LABELS)\n",
    "    final_model = Sequential()\n",
    "    models = []\n",
    "    for key in profiles:\n",
    "        length = len(profiles[key])\n",
    "        model = Sequential()\n",
    "        model.add(Dense(2*length + 15, init='uniform', input_shape=(length,), activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(10 + length, activation='relu'))\n",
    "        model.add(Dropout(0.15))\n",
    "        model.add(Dense(ll, activation='sigmoid'))\n",
    "        models.append(model)\n",
    "\n",
    "    merged = Merge(models, mode='ave')\n",
    "    final_model.add(merged)\n",
    "    final_model.compile(loss='mae', optimizer='nadam', metrics=['accuracy'])\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and score models on X_train, Y_train, X_val, Y_val for each profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice = data_df[last_choice_mask][['ncodpers'] + TARGET_LABELS]\n",
    "X = data_df[train_month_mask][['ncodpers'] + features]\n",
    "Y = data_df[train_month_mask][TARGET_LABELS].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69801, 20) (29915, 20)  |  (69801, 24) (29915, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, train_size=0.70)\n",
    "print X_train.shape, X_val.shape, \" | \", Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:- Create the model\n",
      "INFO:root:- Fit the model\n",
      "INFO:root:- Evaluate the model\n",
      "INFO:root:-- Model Accuracy : 78.74%\n",
      "INFO:root:- Predict using trained model\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "x_val = []\n",
    "\n",
    "for key in profiles:\n",
    "    x_train_ = X_train[profiles[key]].values\n",
    "    x_val_ = X_val[profiles[key]].values    \n",
    "    x_train_ = StandardScaler().fit_transform(x_train_)\n",
    "    x_val_ = StandardScaler().fit_transform(x_val_)  \n",
    "\n",
    "    x_train.append(x_train_)\n",
    "    x_val.append(x_val_)\n",
    "\n",
    "logging.info(\"- Create the model\")\n",
    "model = create_model()\n",
    "logging.info(\"- Fit the model\")\n",
    "model.fit(x_train, Y_train, nb_epoch=100, batch_size=10000, verbose=0)\n",
    "logging.info(\"- Evaluate the model\")\n",
    "scores = model.evaluate(x_val, Y_val, verbose=0)\n",
    "logging.info(\"-- Model Accuracy : %.2f%%\" % (scores[1]*100))        \n",
    "logging.info(\"- Predict using trained model\")\n",
    "Y_pred = model.predict(x_val, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score with MAP@7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_added_products(current_choice, last_choice):\n",
    "    \"\"\"\n",
    "    current_choice is e.g. [0, 0, 1, 0, ..., 1], of length 24\n",
    "    \"\"\"\n",
    "    real = []\n",
    "    for i, c in enumerate(current_choice):\n",
    "        if c == 1:\n",
    "            if last_choice[i] == 0:\n",
    "                real.append(i)\n",
    "    return real\n",
    "\n",
    "def remove_last_choice(predictions, last_choice):\n",
    "    \"\"\"\n",
    "    predictions is a list of product indices\n",
    "    \"\"\"\n",
    "    out = list(predictions)\n",
    "    for i, c in enumerate(last_choice):\n",
    "        if c == 1 and i in out:\n",
    "            out.remove(i)\n",
    "    return out\n",
    "    \n",
    "\n",
    "def apk(actual, predicted, k=7):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    \n",
    "    return score / min(len(actual), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structure `Y_pred` is a dictionary with predictions :\n",
    "```\n",
    "Y_pred = {\n",
    "   [24 target probas], # client 1\n",
    "   [24 target probas], # client 2\n",
    "   ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge predictions from profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted score: 0.012727217858\n"
     ]
    }
   ],
   "source": [
    "n_highest = 5\n",
    "predicted_added_products = np.argsort(Y_pred, axis=1)\n",
    "predicted_added_products = predicted_added_products[:,::-1][:,:n_highest]\n",
    "\n",
    "gb = clients_last_choice.groupby('ncodpers')\n",
    "\n",
    "map7 = 0.0\n",
    "\n",
    "for i, client, targets in zip(range(len(Y_val)), X_val['ncodpers'], Y_val):\n",
    "    last_choice = gb.get_group(client)[TARGET_LABELS].values[0].astype(np.uint)\n",
    "    added_products = get_added_products(targets, last_choice)\n",
    "    predictions = remove_last_choice(predicted_added_products[i], last_choice)\n",
    "    score = apk(added_products, predictions)    \n",
    "    map7 += score    \n",
    "    \n",
    "map7 /= len(Y_val)\n",
    "print('Predicted score: {}'.format(map7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "On 10000 client, 5 profiles -> map7 = 0.028\n",
    "\n",
    "On 100000 client, 5 profiles -> map7 = 0.0190395538682, 0.0220090653677\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train_val dataset :\n",
    "- Select only clients that choose new products in 201506 comparing with 201505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainval_df = data_df.sort_values(['fecha_dato', 'ncodpers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates1 = months[:-1]\n",
    "dates2 = months[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print dates1, dates2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp_df = trainval_df[['fecha_dato','ncodpers']]\n",
    "tmp_df.loc[:,'target'] = trainval_df[TARGET_LABELS].sum(axis=1)\n",
    "v1 = tmp_df[tmp_df['fecha_dato'].isin(dates2)]['target'].values\n",
    "v2 = tmp_df[tmp_df['fecha_dato'].isin(dates1)]['target'].values\n",
    "ll = min(len(v1), len(v2))\n",
    "indices = tmp_df.index[ll:]\n",
    "trainval_df.loc[indices,'diff'] = pd.Series(v1 - v2, index=indices)\n",
    "del tmp_df, v1, v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainval_df.sort_values(['ncodpers', 'fecha_dato']).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = trainval_df[(trainval_df['fecha_dato'].isin(dates2)) & (trainval_df['diff'] > 0)][features]\n",
    "Y = trainval_df[(trainval_df['fecha_dato'].isin(dates2)) & (trainval_df['diff'] > 0)][TARGET_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X.values, Y.values, train_size=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_val = StandardScaler().fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape, X_val.shape\n",
    "print Y_train.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Keras model :\n",
    "\n",
    "Sequential\n",
    "- Dense\n",
    "- Activation\n",
    "- Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(43, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(Y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=1500, batch_size=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize performance of the model\n",
    "scores = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(43, init='uniform', input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(Y_train.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=1000, batch_size=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize performance of the model\n",
    "scores = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, init='uniform', input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(Dense(Y_train.shape[1], activation='softmax'))\n",
    "model.compile(loss='mae', optimizer='nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, nb_epoch=1000, batch_size=10000, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize performance of the model\n",
    "scores = model.evaluate(X_val, Y_val, verbose=0)\n",
    "print(\"Model Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Prediction part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del X, Y, X_train, X_val, Y_train, Y_val, trainval_df, data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the last month from the training dataset to get user last choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yearmonth_list = [201605]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lastmonth_df = load_data2(TRAIN_FILE_PATH, yearmonth_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minimal_clean_data_inplace(lastmonth_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clients_last_choice = lastmonth_df[['ncodpers'] + TARGET_LABELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = load_data2(TEST_FILE_PATH, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "minimal_clean_data_inplace(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_df.shape\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode non-numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preprocess_data_inplace(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_df.shape\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check multiple models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.randn(100,10)\n",
    "_x_train_1 = data[:, (1,3,5,7,9)]\n",
    "_x_train_2 = data[:, (0,2,4,6,8)]\n",
    "_y_train = np.random.randint(10, size=100)\n",
    "\n",
    "_x_val = np.random.randn(30,5) \n",
    "_y_val = np.random.randint(10, size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_models = {}\n",
    "\n",
    "for i in range(2):\n",
    "#     model1 = Sequential()\n",
    "#     model1.add(Dense(15, input_shape=(5,), activation='relu'))\n",
    "#     model1.add(Dense(1, activation='relu'))\n",
    "#     model1.compile(loss='mae', optimizer='nadam', metrics=['accuracy'])\n",
    "    length = 5\n",
    "    model = Sequential()\n",
    "    model.add(Dense(2*length + 15, init='uniform', input_shape=(length,), activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(10 + length, activation='relu'))\n",
    "    model.add(Dropout(0.15))\n",
    "    model.add(Dense(ll, activation='softmax'))\n",
    "    model.compile(loss='mae', optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    _models[i] = model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, _x_train in zip(range(2), [_x_train_1, _x_train_2]):\n",
    "    model = _models[i]\n",
    "    model.fit(_x_train, _y_train, nb_epoch=1000, batch_size=100, verbose=0)\n",
    "    score = model.evaluate(_x_val, _y_val, verbose=0)\n",
    "    print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
